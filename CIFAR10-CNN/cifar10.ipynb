{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d1a42aa",
   "metadata": {},
   "source": [
    "## Importing libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ff1a618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb73e7b",
   "metadata": {},
   "source": [
    "## Device configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fbf826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07df8d63",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1ac9c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 8\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8b1db5",
   "metadata": {},
   "source": [
    "## Transforms\n",
    "\n",
    "Torchvision datasets have PIL images of range [0,1], so we convert them to Tensors of normalized range of [-1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e22579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473c35ae",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24d15f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab5c24f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a06c526",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a6dff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)  # 3 input color channels, to 6 output color channels, & kernel of size 5\n",
    "        self.pool = nn.MaxPool2d(2, 2)   # kernel size 2, stride 2\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*5*5)  # flatten operation\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ba3a7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2649aa",
   "metadata": {},
   "source": [
    "## Loss fn & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9db9bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4567d3a3",
   "metadata": {},
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7abeff96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100], Step: [100/6250], Loss: 2.2842 \n",
      "\n",
      "Epoch: [1/100], Step: [200/6250], Loss: 2.2692 \n",
      "\n",
      "Epoch: [1/100], Step: [300/6250], Loss: 2.3286 \n",
      "\n",
      "Epoch: [1/100], Step: [400/6250], Loss: 2.3310 \n",
      "\n",
      "Epoch: [1/100], Step: [500/6250], Loss: 2.3180 \n",
      "\n",
      "Epoch: [1/100], Step: [600/6250], Loss: 2.2972 \n",
      "\n",
      "Epoch: [1/100], Step: [700/6250], Loss: 2.2729 \n",
      "\n",
      "Epoch: [1/100], Step: [800/6250], Loss: 2.3054 \n",
      "\n",
      "Epoch: [1/100], Step: [900/6250], Loss: 2.3231 \n",
      "\n",
      "Epoch: [1/100], Step: [1000/6250], Loss: 2.2914 \n",
      "\n",
      "Epoch: [1/100], Step: [1100/6250], Loss: 2.2806 \n",
      "\n",
      "Epoch: [1/100], Step: [1200/6250], Loss: 2.2967 \n",
      "\n",
      "Epoch: [1/100], Step: [1300/6250], Loss: 2.2840 \n",
      "\n",
      "Epoch: [1/100], Step: [1400/6250], Loss: 2.3500 \n",
      "\n",
      "Epoch: [1/100], Step: [1500/6250], Loss: 2.2695 \n",
      "\n",
      "Epoch: [1/100], Step: [1600/6250], Loss: 2.2844 \n",
      "\n",
      "Epoch: [1/100], Step: [1700/6250], Loss: 2.3048 \n",
      "\n",
      "Epoch: [1/100], Step: [1800/6250], Loss: 2.3124 \n",
      "\n",
      "Epoch: [1/100], Step: [1900/6250], Loss: 2.3148 \n",
      "\n",
      "Epoch: [1/100], Step: [2000/6250], Loss: 2.3302 \n",
      "\n",
      "Epoch: [1/100], Step: [2100/6250], Loss: 2.3115 \n",
      "\n",
      "Epoch: [1/100], Step: [2200/6250], Loss: 2.3099 \n",
      "\n",
      "Epoch: [1/100], Step: [2300/6250], Loss: 2.2715 \n",
      "\n",
      "Epoch: [1/100], Step: [2400/6250], Loss: 2.2944 \n",
      "\n",
      "Epoch: [1/100], Step: [2500/6250], Loss: 2.2924 \n",
      "\n",
      "Epoch: [1/100], Step: [2600/6250], Loss: 2.3166 \n",
      "\n",
      "Epoch: [1/100], Step: [2700/6250], Loss: 2.3099 \n",
      "\n",
      "Epoch: [1/100], Step: [2800/6250], Loss: 2.3114 \n",
      "\n",
      "Epoch: [1/100], Step: [2900/6250], Loss: 2.3014 \n",
      "\n",
      "Epoch: [1/100], Step: [3000/6250], Loss: 2.3299 \n",
      "\n",
      "Epoch: [1/100], Step: [3100/6250], Loss: 2.3315 \n",
      "\n",
      "Epoch: [1/100], Step: [3200/6250], Loss: 2.3093 \n",
      "\n",
      "Epoch: [1/100], Step: [3300/6250], Loss: 2.2985 \n",
      "\n",
      "Epoch: [1/100], Step: [3400/6250], Loss: 2.3184 \n",
      "\n",
      "Epoch: [1/100], Step: [3500/6250], Loss: 2.2834 \n",
      "\n",
      "Epoch: [1/100], Step: [3600/6250], Loss: 2.2707 \n",
      "\n",
      "Epoch: [1/100], Step: [3700/6250], Loss: 2.2714 \n",
      "\n",
      "Epoch: [1/100], Step: [3800/6250], Loss: 2.2925 \n",
      "\n",
      "Epoch: [1/100], Step: [3900/6250], Loss: 2.2794 \n",
      "\n",
      "Epoch: [1/100], Step: [4000/6250], Loss: 2.3001 \n",
      "\n",
      "Epoch: [1/100], Step: [4100/6250], Loss: 2.3241 \n",
      "\n",
      "Epoch: [1/100], Step: [4200/6250], Loss: 2.3179 \n",
      "\n",
      "Epoch: [1/100], Step: [4300/6250], Loss: 2.2987 \n",
      "\n",
      "Epoch: [1/100], Step: [4400/6250], Loss: 2.3047 \n",
      "\n",
      "Epoch: [1/100], Step: [4500/6250], Loss: 2.3096 \n",
      "\n",
      "Epoch: [1/100], Step: [4600/6250], Loss: 2.3253 \n",
      "\n",
      "Epoch: [1/100], Step: [4700/6250], Loss: 2.3318 \n",
      "\n",
      "Epoch: [1/100], Step: [4800/6250], Loss: 2.2933 \n",
      "\n",
      "Epoch: [1/100], Step: [4900/6250], Loss: 2.2872 \n",
      "\n",
      "Epoch: [1/100], Step: [5000/6250], Loss: 2.3127 \n",
      "\n",
      "Epoch: [1/100], Step: [5100/6250], Loss: 2.3100 \n",
      "\n",
      "Epoch: [1/100], Step: [5200/6250], Loss: 2.3200 \n",
      "\n",
      "Epoch: [1/100], Step: [5300/6250], Loss: 2.2787 \n",
      "\n",
      "Epoch: [1/100], Step: [5400/6250], Loss: 2.3086 \n",
      "\n",
      "Epoch: [1/100], Step: [5500/6250], Loss: 2.2831 \n",
      "\n",
      "Epoch: [1/100], Step: [5600/6250], Loss: 2.2844 \n",
      "\n",
      "Epoch: [1/100], Step: [5700/6250], Loss: 2.2898 \n",
      "\n",
      "Epoch: [1/100], Step: [5800/6250], Loss: 2.2857 \n",
      "\n",
      "Epoch: [1/100], Step: [5900/6250], Loss: 2.2849 \n",
      "\n",
      "Epoch: [1/100], Step: [6000/6250], Loss: 2.3117 \n",
      "\n",
      "Epoch: [1/100], Step: [6100/6250], Loss: 2.3145 \n",
      "\n",
      "Epoch: [1/100], Step: [6200/6250], Loss: 2.2945 \n",
      "\n",
      "Epoch: [2/100], Step: [100/6250], Loss: 2.2812 \n",
      "\n",
      "Epoch: [2/100], Step: [200/6250], Loss: 2.2951 \n",
      "\n",
      "Epoch: [2/100], Step: [300/6250], Loss: 2.2821 \n",
      "\n",
      "Epoch: [2/100], Step: [400/6250], Loss: 2.2972 \n",
      "\n",
      "Epoch: [2/100], Step: [500/6250], Loss: 2.3177 \n",
      "\n",
      "Epoch: [2/100], Step: [600/6250], Loss: 2.3128 \n",
      "\n",
      "Epoch: [2/100], Step: [700/6250], Loss: 2.3094 \n",
      "\n",
      "Epoch: [2/100], Step: [800/6250], Loss: 2.2843 \n",
      "\n",
      "Epoch: [2/100], Step: [900/6250], Loss: 2.2899 \n",
      "\n",
      "Epoch: [2/100], Step: [1000/6250], Loss: 2.2727 \n",
      "\n",
      "Epoch: [2/100], Step: [1100/6250], Loss: 2.2716 \n",
      "\n",
      "Epoch: [2/100], Step: [1200/6250], Loss: 2.2734 \n",
      "\n",
      "Epoch: [2/100], Step: [1300/6250], Loss: 2.2855 \n",
      "\n",
      "Epoch: [2/100], Step: [1400/6250], Loss: 2.2909 \n",
      "\n",
      "Epoch: [2/100], Step: [1500/6250], Loss: 2.2565 \n",
      "\n",
      "Epoch: [2/100], Step: [1600/6250], Loss: 2.2835 \n",
      "\n",
      "Epoch: [2/100], Step: [1700/6250], Loss: 2.3243 \n",
      "\n",
      "Epoch: [2/100], Step: [1800/6250], Loss: 2.2840 \n",
      "\n",
      "Epoch: [2/100], Step: [1900/6250], Loss: 2.2602 \n",
      "\n",
      "Epoch: [2/100], Step: [2000/6250], Loss: 2.2692 \n",
      "\n",
      "Epoch: [2/100], Step: [2100/6250], Loss: 2.2719 \n",
      "\n",
      "Epoch: [2/100], Step: [2200/6250], Loss: 2.2704 \n",
      "\n",
      "Epoch: [2/100], Step: [2300/6250], Loss: 2.3053 \n",
      "\n",
      "Epoch: [2/100], Step: [2400/6250], Loss: 2.2886 \n",
      "\n",
      "Epoch: [2/100], Step: [2500/6250], Loss: 2.2228 \n",
      "\n",
      "Epoch: [2/100], Step: [2600/6250], Loss: 2.2682 \n",
      "\n",
      "Epoch: [2/100], Step: [2700/6250], Loss: 2.2817 \n",
      "\n",
      "Epoch: [2/100], Step: [2800/6250], Loss: 2.2560 \n",
      "\n",
      "Epoch: [2/100], Step: [2900/6250], Loss: 2.3101 \n",
      "\n",
      "Epoch: [2/100], Step: [3000/6250], Loss: 2.2986 \n",
      "\n",
      "Epoch: [2/100], Step: [3100/6250], Loss: 2.2125 \n",
      "\n",
      "Epoch: [2/100], Step: [3200/6250], Loss: 2.2886 \n",
      "\n",
      "Epoch: [2/100], Step: [3300/6250], Loss: 2.2344 \n",
      "\n",
      "Epoch: [2/100], Step: [3400/6250], Loss: 2.2193 \n",
      "\n",
      "Epoch: [2/100], Step: [3500/6250], Loss: 2.2365 \n",
      "\n",
      "Epoch: [2/100], Step: [3600/6250], Loss: 2.2807 \n",
      "\n",
      "Epoch: [2/100], Step: [3700/6250], Loss: 2.2540 \n",
      "\n",
      "Epoch: [2/100], Step: [3800/6250], Loss: 2.2103 \n",
      "\n",
      "Epoch: [2/100], Step: [3900/6250], Loss: 2.1909 \n",
      "\n",
      "Epoch: [2/100], Step: [4000/6250], Loss: 2.1318 \n",
      "\n",
      "Epoch: [2/100], Step: [4100/6250], Loss: 2.2836 \n",
      "\n",
      "Epoch: [2/100], Step: [4200/6250], Loss: 2.2896 \n",
      "\n",
      "Epoch: [2/100], Step: [4300/6250], Loss: 2.2238 \n",
      "\n",
      "Epoch: [2/100], Step: [4400/6250], Loss: 2.1178 \n",
      "\n",
      "Epoch: [2/100], Step: [4500/6250], Loss: 2.1732 \n",
      "\n",
      "Epoch: [2/100], Step: [4600/6250], Loss: 2.0165 \n",
      "\n",
      "Epoch: [2/100], Step: [4700/6250], Loss: 2.1089 \n",
      "\n",
      "Epoch: [2/100], Step: [4800/6250], Loss: 2.3137 \n",
      "\n",
      "Epoch: [2/100], Step: [4900/6250], Loss: 2.1777 \n",
      "\n",
      "Epoch: [2/100], Step: [5000/6250], Loss: 2.1744 \n",
      "\n",
      "Epoch: [2/100], Step: [5100/6250], Loss: 2.0343 \n",
      "\n",
      "Epoch: [2/100], Step: [5200/6250], Loss: 2.1009 \n",
      "\n",
      "Epoch: [2/100], Step: [5300/6250], Loss: 2.1368 \n",
      "\n",
      "Epoch: [2/100], Step: [5400/6250], Loss: 2.1493 \n",
      "\n",
      "Epoch: [2/100], Step: [5500/6250], Loss: 2.1268 \n",
      "\n",
      "Epoch: [2/100], Step: [5600/6250], Loss: 2.1417 \n",
      "\n",
      "Epoch: [2/100], Step: [5700/6250], Loss: 2.0625 \n",
      "\n",
      "Epoch: [2/100], Step: [5800/6250], Loss: 2.1474 \n",
      "\n",
      "Epoch: [2/100], Step: [5900/6250], Loss: 2.0883 \n",
      "\n",
      "Epoch: [2/100], Step: [6000/6250], Loss: 2.3575 \n",
      "\n",
      "Epoch: [2/100], Step: [6100/6250], Loss: 2.1087 \n",
      "\n",
      "Epoch: [2/100], Step: [6200/6250], Loss: 2.0831 \n",
      "\n",
      "Epoch: [3/100], Step: [100/6250], Loss: 2.2867 \n",
      "\n",
      "Epoch: [3/100], Step: [200/6250], Loss: 1.9100 \n",
      "\n",
      "Epoch: [3/100], Step: [300/6250], Loss: 2.0909 \n",
      "\n",
      "Epoch: [3/100], Step: [400/6250], Loss: 1.8427 \n",
      "\n",
      "Epoch: [3/100], Step: [500/6250], Loss: 1.8361 \n",
      "\n",
      "Epoch: [3/100], Step: [600/6250], Loss: 2.1863 \n",
      "\n",
      "Epoch: [3/100], Step: [700/6250], Loss: 2.5237 \n",
      "\n",
      "Epoch: [3/100], Step: [800/6250], Loss: 2.1637 \n",
      "\n",
      "Epoch: [3/100], Step: [900/6250], Loss: 1.9845 \n",
      "\n",
      "Epoch: [3/100], Step: [1000/6250], Loss: 1.9821 \n",
      "\n",
      "Epoch: [3/100], Step: [1100/6250], Loss: 2.2315 \n",
      "\n",
      "Epoch: [3/100], Step: [1200/6250], Loss: 2.2873 \n",
      "\n",
      "Epoch: [3/100], Step: [1300/6250], Loss: 2.4242 \n",
      "\n",
      "Epoch: [3/100], Step: [1400/6250], Loss: 1.8488 \n",
      "\n",
      "Epoch: [3/100], Step: [1500/6250], Loss: 1.8773 \n",
      "\n",
      "Epoch: [3/100], Step: [1600/6250], Loss: 2.2141 \n",
      "\n",
      "Epoch: [3/100], Step: [1700/6250], Loss: 2.0997 \n",
      "\n",
      "Epoch: [3/100], Step: [1800/6250], Loss: 2.0315 \n",
      "\n",
      "Epoch: [3/100], Step: [1900/6250], Loss: 1.9796 \n",
      "\n",
      "Epoch: [3/100], Step: [2000/6250], Loss: 2.2079 \n",
      "\n",
      "Epoch: [3/100], Step: [2100/6250], Loss: 1.9140 \n",
      "\n",
      "Epoch: [3/100], Step: [2200/6250], Loss: 2.2346 \n",
      "\n",
      "Epoch: [3/100], Step: [2300/6250], Loss: 2.0559 \n",
      "\n",
      "Epoch: [3/100], Step: [2400/6250], Loss: 1.9650 \n",
      "\n",
      "Epoch: [3/100], Step: [2500/6250], Loss: 1.9194 \n",
      "\n",
      "Epoch: [3/100], Step: [2600/6250], Loss: 1.9398 \n",
      "\n",
      "Epoch: [3/100], Step: [2700/6250], Loss: 2.2020 \n",
      "\n",
      "Epoch: [3/100], Step: [2800/6250], Loss: 2.0256 \n",
      "\n",
      "Epoch: [3/100], Step: [2900/6250], Loss: 2.0619 \n",
      "\n",
      "Epoch: [3/100], Step: [3000/6250], Loss: 2.2113 \n",
      "\n",
      "Epoch: [3/100], Step: [3100/6250], Loss: 2.1054 \n",
      "\n",
      "Epoch: [3/100], Step: [3200/6250], Loss: 2.1835 \n",
      "\n",
      "Epoch: [3/100], Step: [3300/6250], Loss: 2.3210 \n",
      "\n",
      "Epoch: [3/100], Step: [3400/6250], Loss: 2.2712 \n",
      "\n",
      "Epoch: [3/100], Step: [3500/6250], Loss: 1.8631 \n",
      "\n",
      "Epoch: [3/100], Step: [3600/6250], Loss: 1.7011 \n",
      "\n",
      "Epoch: [3/100], Step: [3700/6250], Loss: 2.0389 \n",
      "\n",
      "Epoch: [3/100], Step: [3800/6250], Loss: 2.1785 \n",
      "\n",
      "Epoch: [3/100], Step: [3900/6250], Loss: 2.3319 \n",
      "\n",
      "Epoch: [3/100], Step: [4000/6250], Loss: 1.9917 \n",
      "\n",
      "Epoch: [3/100], Step: [4100/6250], Loss: 1.8406 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3/100], Step: [4200/6250], Loss: 2.2603 \n",
      "\n",
      "Epoch: [3/100], Step: [4300/6250], Loss: 2.5835 \n",
      "\n",
      "Epoch: [3/100], Step: [4400/6250], Loss: 1.9075 \n",
      "\n",
      "Epoch: [3/100], Step: [4500/6250], Loss: 1.8748 \n",
      "\n",
      "Epoch: [3/100], Step: [4600/6250], Loss: 1.9601 \n",
      "\n",
      "Epoch: [3/100], Step: [4700/6250], Loss: 1.9154 \n",
      "\n",
      "Epoch: [3/100], Step: [4800/6250], Loss: 1.6538 \n",
      "\n",
      "Epoch: [3/100], Step: [4900/6250], Loss: 1.6210 \n",
      "\n",
      "Epoch: [3/100], Step: [5000/6250], Loss: 2.2587 \n",
      "\n",
      "Epoch: [3/100], Step: [5100/6250], Loss: 1.7977 \n",
      "\n",
      "Epoch: [3/100], Step: [5200/6250], Loss: 1.5824 \n",
      "\n",
      "Epoch: [3/100], Step: [5300/6250], Loss: 1.8531 \n",
      "\n",
      "Epoch: [3/100], Step: [5400/6250], Loss: 2.1899 \n",
      "\n",
      "Epoch: [3/100], Step: [5500/6250], Loss: 1.7047 \n",
      "\n",
      "Epoch: [3/100], Step: [5600/6250], Loss: 1.9538 \n",
      "\n",
      "Epoch: [3/100], Step: [5700/6250], Loss: 2.0062 \n",
      "\n",
      "Epoch: [3/100], Step: [5800/6250], Loss: 1.9183 \n",
      "\n",
      "Epoch: [3/100], Step: [5900/6250], Loss: 1.5790 \n",
      "\n",
      "Epoch: [3/100], Step: [6000/6250], Loss: 2.3672 \n",
      "\n",
      "Epoch: [3/100], Step: [6100/6250], Loss: 1.7891 \n",
      "\n",
      "Epoch: [3/100], Step: [6200/6250], Loss: 1.6852 \n",
      "\n",
      "Epoch: [4/100], Step: [100/6250], Loss: 1.4754 \n",
      "\n",
      "Epoch: [4/100], Step: [200/6250], Loss: 1.8221 \n",
      "\n",
      "Epoch: [4/100], Step: [300/6250], Loss: 1.9566 \n",
      "\n",
      "Epoch: [4/100], Step: [400/6250], Loss: 1.8472 \n",
      "\n",
      "Epoch: [4/100], Step: [500/6250], Loss: 1.8194 \n",
      "\n",
      "Epoch: [4/100], Step: [600/6250], Loss: 1.8353 \n",
      "\n",
      "Epoch: [4/100], Step: [700/6250], Loss: 2.0310 \n",
      "\n",
      "Epoch: [4/100], Step: [800/6250], Loss: 1.5433 \n",
      "\n",
      "Epoch: [4/100], Step: [900/6250], Loss: 1.7164 \n",
      "\n",
      "Epoch: [4/100], Step: [1000/6250], Loss: 1.7875 \n",
      "\n",
      "Epoch: [4/100], Step: [1100/6250], Loss: 1.7928 \n",
      "\n",
      "Epoch: [4/100], Step: [1200/6250], Loss: 1.6130 \n",
      "\n",
      "Epoch: [4/100], Step: [1300/6250], Loss: 1.6351 \n",
      "\n",
      "Epoch: [4/100], Step: [1400/6250], Loss: 2.3707 \n",
      "\n",
      "Epoch: [4/100], Step: [1500/6250], Loss: 1.5714 \n",
      "\n",
      "Epoch: [4/100], Step: [1600/6250], Loss: 1.9261 \n",
      "\n",
      "Epoch: [4/100], Step: [1700/6250], Loss: 1.6778 \n",
      "\n",
      "Epoch: [4/100], Step: [1800/6250], Loss: 1.4034 \n",
      "\n",
      "Epoch: [4/100], Step: [1900/6250], Loss: 1.4233 \n",
      "\n",
      "Epoch: [4/100], Step: [2000/6250], Loss: 1.6388 \n",
      "\n",
      "Epoch: [4/100], Step: [2100/6250], Loss: 1.7889 \n",
      "\n",
      "Epoch: [4/100], Step: [2200/6250], Loss: 1.3316 \n",
      "\n",
      "Epoch: [4/100], Step: [2300/6250], Loss: 1.6089 \n",
      "\n",
      "Epoch: [4/100], Step: [2400/6250], Loss: 1.7220 \n",
      "\n",
      "Epoch: [4/100], Step: [2500/6250], Loss: 1.5756 \n",
      "\n",
      "Epoch: [4/100], Step: [2600/6250], Loss: 1.8454 \n",
      "\n",
      "Epoch: [4/100], Step: [2700/6250], Loss: 2.0707 \n",
      "\n",
      "Epoch: [4/100], Step: [2800/6250], Loss: 1.3956 \n",
      "\n",
      "Epoch: [4/100], Step: [2900/6250], Loss: 1.4873 \n",
      "\n",
      "Epoch: [4/100], Step: [3000/6250], Loss: 1.5458 \n",
      "\n",
      "Epoch: [4/100], Step: [3100/6250], Loss: 2.0443 \n",
      "\n",
      "Epoch: [4/100], Step: [3200/6250], Loss: 1.6045 \n",
      "\n",
      "Epoch: [4/100], Step: [3300/6250], Loss: 1.3155 \n",
      "\n",
      "Epoch: [4/100], Step: [3400/6250], Loss: 2.0267 \n",
      "\n",
      "Epoch: [4/100], Step: [3500/6250], Loss: 1.3539 \n",
      "\n",
      "Epoch: [4/100], Step: [3600/6250], Loss: 1.4948 \n",
      "\n",
      "Epoch: [4/100], Step: [3700/6250], Loss: 1.3888 \n",
      "\n",
      "Epoch: [4/100], Step: [3800/6250], Loss: 1.9726 \n",
      "\n",
      "Epoch: [4/100], Step: [3900/6250], Loss: 1.5493 \n",
      "\n",
      "Epoch: [4/100], Step: [4000/6250], Loss: 2.0143 \n",
      "\n",
      "Epoch: [4/100], Step: [4100/6250], Loss: 1.7470 \n",
      "\n",
      "Epoch: [4/100], Step: [4200/6250], Loss: 1.6432 \n",
      "\n",
      "Epoch: [4/100], Step: [4300/6250], Loss: 1.5542 \n",
      "\n",
      "Epoch: [4/100], Step: [4400/6250], Loss: 1.7148 \n",
      "\n",
      "Epoch: [4/100], Step: [4500/6250], Loss: 1.6932 \n",
      "\n",
      "Epoch: [4/100], Step: [4600/6250], Loss: 1.6248 \n",
      "\n",
      "Epoch: [4/100], Step: [4700/6250], Loss: 1.7481 \n",
      "\n",
      "Epoch: [4/100], Step: [4800/6250], Loss: 1.5811 \n",
      "\n",
      "Epoch: [4/100], Step: [4900/6250], Loss: 1.5423 \n",
      "\n",
      "Epoch: [4/100], Step: [5000/6250], Loss: 1.4464 \n",
      "\n",
      "Epoch: [4/100], Step: [5100/6250], Loss: 1.7791 \n",
      "\n",
      "Epoch: [4/100], Step: [5200/6250], Loss: 1.6949 \n",
      "\n",
      "Epoch: [4/100], Step: [5300/6250], Loss: 1.1248 \n",
      "\n",
      "Epoch: [4/100], Step: [5400/6250], Loss: 1.7266 \n",
      "\n",
      "Epoch: [4/100], Step: [5500/6250], Loss: 1.5776 \n",
      "\n",
      "Epoch: [4/100], Step: [5600/6250], Loss: 1.8545 \n",
      "\n",
      "Epoch: [4/100], Step: [5700/6250], Loss: 1.5763 \n",
      "\n",
      "Epoch: [4/100], Step: [5800/6250], Loss: 1.5120 \n",
      "\n",
      "Epoch: [4/100], Step: [5900/6250], Loss: 1.7767 \n",
      "\n",
      "Epoch: [4/100], Step: [6000/6250], Loss: 2.3596 \n",
      "\n",
      "Epoch: [4/100], Step: [6100/6250], Loss: 1.8038 \n",
      "\n",
      "Epoch: [4/100], Step: [6200/6250], Loss: 2.1259 \n",
      "\n",
      "Epoch: [5/100], Step: [100/6250], Loss: 1.3005 \n",
      "\n",
      "Epoch: [5/100], Step: [200/6250], Loss: 2.1406 \n",
      "\n",
      "Epoch: [5/100], Step: [300/6250], Loss: 2.1112 \n",
      "\n",
      "Epoch: [5/100], Step: [400/6250], Loss: 1.5140 \n",
      "\n",
      "Epoch: [5/100], Step: [500/6250], Loss: 1.4805 \n",
      "\n",
      "Epoch: [5/100], Step: [600/6250], Loss: 1.9103 \n",
      "\n",
      "Epoch: [5/100], Step: [700/6250], Loss: 1.7006 \n",
      "\n",
      "Epoch: [5/100], Step: [800/6250], Loss: 1.1618 \n",
      "\n",
      "Epoch: [5/100], Step: [900/6250], Loss: 1.4483 \n",
      "\n",
      "Epoch: [5/100], Step: [1000/6250], Loss: 1.8243 \n",
      "\n",
      "Epoch: [5/100], Step: [1100/6250], Loss: 1.8949 \n",
      "\n",
      "Epoch: [5/100], Step: [1200/6250], Loss: 1.7520 \n",
      "\n",
      "Epoch: [5/100], Step: [1300/6250], Loss: 1.7183 \n",
      "\n",
      "Epoch: [5/100], Step: [1400/6250], Loss: 2.0699 \n",
      "\n",
      "Epoch: [5/100], Step: [1500/6250], Loss: 1.7290 \n",
      "\n",
      "Epoch: [5/100], Step: [1600/6250], Loss: 1.8991 \n",
      "\n",
      "Epoch: [5/100], Step: [1700/6250], Loss: 1.8067 \n",
      "\n",
      "Epoch: [5/100], Step: [1800/6250], Loss: 1.3011 \n",
      "\n",
      "Epoch: [5/100], Step: [1900/6250], Loss: 2.0226 \n",
      "\n",
      "Epoch: [5/100], Step: [2000/6250], Loss: 1.4747 \n",
      "\n",
      "Epoch: [5/100], Step: [2100/6250], Loss: 1.7998 \n",
      "\n",
      "Epoch: [5/100], Step: [2200/6250], Loss: 1.6482 \n",
      "\n",
      "Epoch: [5/100], Step: [2300/6250], Loss: 1.6027 \n",
      "\n",
      "Epoch: [5/100], Step: [2400/6250], Loss: 1.2167 \n",
      "\n",
      "Epoch: [5/100], Step: [2500/6250], Loss: 1.6094 \n",
      "\n",
      "Epoch: [5/100], Step: [2600/6250], Loss: 2.1297 \n",
      "\n",
      "Epoch: [5/100], Step: [2700/6250], Loss: 1.9184 \n",
      "\n",
      "Epoch: [5/100], Step: [2800/6250], Loss: 1.9649 \n",
      "\n",
      "Epoch: [5/100], Step: [2900/6250], Loss: 1.8087 \n",
      "\n",
      "Epoch: [5/100], Step: [3000/6250], Loss: 2.2444 \n",
      "\n",
      "Epoch: [5/100], Step: [3100/6250], Loss: 1.4451 \n",
      "\n",
      "Epoch: [5/100], Step: [3200/6250], Loss: 1.6064 \n",
      "\n",
      "Epoch: [5/100], Step: [3300/6250], Loss: 1.3998 \n",
      "\n",
      "Epoch: [5/100], Step: [3400/6250], Loss: 1.4162 \n",
      "\n",
      "Epoch: [5/100], Step: [3500/6250], Loss: 2.2164 \n",
      "\n",
      "Epoch: [5/100], Step: [3600/6250], Loss: 1.7462 \n",
      "\n",
      "Epoch: [5/100], Step: [3700/6250], Loss: 1.7186 \n",
      "\n",
      "Epoch: [5/100], Step: [3800/6250], Loss: 1.6243 \n",
      "\n",
      "Epoch: [5/100], Step: [3900/6250], Loss: 1.4042 \n",
      "\n",
      "Epoch: [5/100], Step: [4000/6250], Loss: 1.1009 \n",
      "\n",
      "Epoch: [5/100], Step: [4100/6250], Loss: 2.0587 \n",
      "\n",
      "Epoch: [5/100], Step: [4200/6250], Loss: 1.9765 \n",
      "\n",
      "Epoch: [5/100], Step: [4300/6250], Loss: 1.8151 \n",
      "\n",
      "Epoch: [5/100], Step: [4400/6250], Loss: 1.9491 \n",
      "\n",
      "Epoch: [5/100], Step: [4500/6250], Loss: 1.4622 \n",
      "\n",
      "Epoch: [5/100], Step: [4600/6250], Loss: 1.9097 \n",
      "\n",
      "Epoch: [5/100], Step: [4700/6250], Loss: 1.5604 \n",
      "\n",
      "Epoch: [5/100], Step: [4800/6250], Loss: 1.3825 \n",
      "\n",
      "Epoch: [5/100], Step: [4900/6250], Loss: 1.1433 \n",
      "\n",
      "Epoch: [5/100], Step: [5000/6250], Loss: 2.4260 \n",
      "\n",
      "Epoch: [5/100], Step: [5100/6250], Loss: 1.8433 \n",
      "\n",
      "Epoch: [5/100], Step: [5200/6250], Loss: 1.8033 \n",
      "\n",
      "Epoch: [5/100], Step: [5300/6250], Loss: 2.1956 \n",
      "\n",
      "Epoch: [5/100], Step: [5400/6250], Loss: 2.1133 \n",
      "\n",
      "Epoch: [5/100], Step: [5500/6250], Loss: 1.5392 \n",
      "\n",
      "Epoch: [5/100], Step: [5600/6250], Loss: 1.6514 \n",
      "\n",
      "Epoch: [5/100], Step: [5700/6250], Loss: 1.3622 \n",
      "\n",
      "Epoch: [5/100], Step: [5800/6250], Loss: 2.0369 \n",
      "\n",
      "Epoch: [5/100], Step: [5900/6250], Loss: 1.2990 \n",
      "\n",
      "Epoch: [5/100], Step: [6000/6250], Loss: 1.5423 \n",
      "\n",
      "Epoch: [5/100], Step: [6100/6250], Loss: 1.7406 \n",
      "\n",
      "Epoch: [5/100], Step: [6200/6250], Loss: 1.2432 \n",
      "\n",
      "Epoch: [6/100], Step: [100/6250], Loss: 1.3989 \n",
      "\n",
      "Epoch: [6/100], Step: [200/6250], Loss: 1.4001 \n",
      "\n",
      "Epoch: [6/100], Step: [300/6250], Loss: 1.9922 \n",
      "\n",
      "Epoch: [6/100], Step: [400/6250], Loss: 1.9137 \n",
      "\n",
      "Epoch: [6/100], Step: [500/6250], Loss: 1.6920 \n",
      "\n",
      "Epoch: [6/100], Step: [600/6250], Loss: 1.8130 \n",
      "\n",
      "Epoch: [6/100], Step: [700/6250], Loss: 1.5327 \n",
      "\n",
      "Epoch: [6/100], Step: [800/6250], Loss: 1.6229 \n",
      "\n",
      "Epoch: [6/100], Step: [900/6250], Loss: 1.4147 \n",
      "\n",
      "Epoch: [6/100], Step: [1000/6250], Loss: 1.8937 \n",
      "\n",
      "Epoch: [6/100], Step: [1100/6250], Loss: 1.5028 \n",
      "\n",
      "Epoch: [6/100], Step: [1200/6250], Loss: 1.7447 \n",
      "\n",
      "Epoch: [6/100], Step: [1300/6250], Loss: 1.5270 \n",
      "\n",
      "Epoch: [6/100], Step: [1400/6250], Loss: 1.9391 \n",
      "\n",
      "Epoch: [6/100], Step: [1500/6250], Loss: 1.0729 \n",
      "\n",
      "Epoch: [6/100], Step: [1600/6250], Loss: 1.3709 \n",
      "\n",
      "Epoch: [6/100], Step: [1700/6250], Loss: 1.5291 \n",
      "\n",
      "Epoch: [6/100], Step: [1800/6250], Loss: 2.0446 \n",
      "\n",
      "Epoch: [6/100], Step: [1900/6250], Loss: 1.5145 \n",
      "\n",
      "Epoch: [6/100], Step: [2000/6250], Loss: 1.6899 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6/100], Step: [2100/6250], Loss: 1.3156 \n",
      "\n",
      "Epoch: [6/100], Step: [2200/6250], Loss: 1.8242 \n",
      "\n",
      "Epoch: [6/100], Step: [2300/6250], Loss: 1.6054 \n",
      "\n",
      "Epoch: [6/100], Step: [2400/6250], Loss: 1.3499 \n",
      "\n",
      "Epoch: [6/100], Step: [2500/6250], Loss: 1.5155 \n",
      "\n",
      "Epoch: [6/100], Step: [2600/6250], Loss: 2.2614 \n",
      "\n",
      "Epoch: [6/100], Step: [2700/6250], Loss: 1.0268 \n",
      "\n",
      "Epoch: [6/100], Step: [2800/6250], Loss: 1.9313 \n",
      "\n",
      "Epoch: [6/100], Step: [2900/6250], Loss: 1.7215 \n",
      "\n",
      "Epoch: [6/100], Step: [3000/6250], Loss: 1.6442 \n",
      "\n",
      "Epoch: [6/100], Step: [3100/6250], Loss: 1.2418 \n",
      "\n",
      "Epoch: [6/100], Step: [3200/6250], Loss: 1.1939 \n",
      "\n",
      "Epoch: [6/100], Step: [3300/6250], Loss: 1.2772 \n",
      "\n",
      "Epoch: [6/100], Step: [3400/6250], Loss: 1.3428 \n",
      "\n",
      "Epoch: [6/100], Step: [3500/6250], Loss: 1.2866 \n",
      "\n",
      "Epoch: [6/100], Step: [3600/6250], Loss: 1.4600 \n",
      "\n",
      "Epoch: [6/100], Step: [3700/6250], Loss: 2.0075 \n",
      "\n",
      "Epoch: [6/100], Step: [3800/6250], Loss: 1.6804 \n",
      "\n",
      "Epoch: [6/100], Step: [3900/6250], Loss: 1.2689 \n",
      "\n",
      "Epoch: [6/100], Step: [4000/6250], Loss: 1.4882 \n",
      "\n",
      "Epoch: [6/100], Step: [4100/6250], Loss: 1.6168 \n",
      "\n",
      "Epoch: [6/100], Step: [4200/6250], Loss: 1.5934 \n",
      "\n",
      "Epoch: [6/100], Step: [4300/6250], Loss: 1.7987 \n",
      "\n",
      "Epoch: [6/100], Step: [4400/6250], Loss: 1.7984 \n",
      "\n",
      "Epoch: [6/100], Step: [4500/6250], Loss: 1.4311 \n",
      "\n",
      "Epoch: [6/100], Step: [4600/6250], Loss: 1.9883 \n",
      "\n",
      "Epoch: [6/100], Step: [4700/6250], Loss: 1.1356 \n",
      "\n",
      "Epoch: [6/100], Step: [4800/6250], Loss: 1.7696 \n",
      "\n",
      "Epoch: [6/100], Step: [4900/6250], Loss: 1.3924 \n",
      "\n",
      "Epoch: [6/100], Step: [5000/6250], Loss: 1.4719 \n",
      "\n",
      "Epoch: [6/100], Step: [5100/6250], Loss: 1.3769 \n",
      "\n",
      "Epoch: [6/100], Step: [5200/6250], Loss: 1.0329 \n",
      "\n",
      "Epoch: [6/100], Step: [5300/6250], Loss: 1.2121 \n",
      "\n",
      "Epoch: [6/100], Step: [5400/6250], Loss: 1.6979 \n",
      "\n",
      "Epoch: [6/100], Step: [5500/6250], Loss: 1.3193 \n",
      "\n",
      "Epoch: [6/100], Step: [5600/6250], Loss: 1.4710 \n",
      "\n",
      "Epoch: [6/100], Step: [5700/6250], Loss: 1.2977 \n",
      "\n",
      "Epoch: [6/100], Step: [5800/6250], Loss: 1.9087 \n",
      "\n",
      "Epoch: [6/100], Step: [5900/6250], Loss: 1.5061 \n",
      "\n",
      "Epoch: [6/100], Step: [6000/6250], Loss: 1.7188 \n",
      "\n",
      "Epoch: [6/100], Step: [6100/6250], Loss: 2.0860 \n",
      "\n",
      "Epoch: [6/100], Step: [6200/6250], Loss: 0.9315 \n",
      "\n",
      "Epoch: [7/100], Step: [100/6250], Loss: 1.7129 \n",
      "\n",
      "Epoch: [7/100], Step: [200/6250], Loss: 2.4755 \n",
      "\n",
      "Epoch: [7/100], Step: [300/6250], Loss: 1.9294 \n",
      "\n",
      "Epoch: [7/100], Step: [400/6250], Loss: 1.2250 \n",
      "\n",
      "Epoch: [7/100], Step: [500/6250], Loss: 1.3515 \n",
      "\n",
      "Epoch: [7/100], Step: [600/6250], Loss: 1.4287 \n",
      "\n",
      "Epoch: [7/100], Step: [700/6250], Loss: 1.4175 \n",
      "\n",
      "Epoch: [7/100], Step: [800/6250], Loss: 1.2215 \n",
      "\n",
      "Epoch: [7/100], Step: [900/6250], Loss: 1.2869 \n",
      "\n",
      "Epoch: [7/100], Step: [1000/6250], Loss: 1.5086 \n",
      "\n",
      "Epoch: [7/100], Step: [1100/6250], Loss: 1.6062 \n",
      "\n",
      "Epoch: [7/100], Step: [1200/6250], Loss: 1.5709 \n",
      "\n",
      "Epoch: [7/100], Step: [1300/6250], Loss: 1.4239 \n",
      "\n",
      "Epoch: [7/100], Step: [1400/6250], Loss: 1.6412 \n",
      "\n",
      "Epoch: [7/100], Step: [1500/6250], Loss: 1.7471 \n",
      "\n",
      "Epoch: [7/100], Step: [1600/6250], Loss: 1.6571 \n",
      "\n",
      "Epoch: [7/100], Step: [1700/6250], Loss: 1.2660 \n",
      "\n",
      "Epoch: [7/100], Step: [1800/6250], Loss: 1.6420 \n",
      "\n",
      "Epoch: [7/100], Step: [1900/6250], Loss: 1.6661 \n",
      "\n",
      "Epoch: [7/100], Step: [2000/6250], Loss: 0.8847 \n",
      "\n",
      "Epoch: [7/100], Step: [2100/6250], Loss: 1.7047 \n",
      "\n",
      "Epoch: [7/100], Step: [2200/6250], Loss: 1.0895 \n",
      "\n",
      "Epoch: [7/100], Step: [2300/6250], Loss: 1.5174 \n",
      "\n",
      "Epoch: [7/100], Step: [2400/6250], Loss: 1.5595 \n",
      "\n",
      "Epoch: [7/100], Step: [2500/6250], Loss: 1.6319 \n",
      "\n",
      "Epoch: [7/100], Step: [2600/6250], Loss: 1.3429 \n",
      "\n",
      "Epoch: [7/100], Step: [2700/6250], Loss: 1.5765 \n",
      "\n",
      "Epoch: [7/100], Step: [2800/6250], Loss: 1.5899 \n",
      "\n",
      "Epoch: [7/100], Step: [2900/6250], Loss: 1.4376 \n",
      "\n",
      "Epoch: [7/100], Step: [3000/6250], Loss: 1.2073 \n",
      "\n",
      "Epoch: [7/100], Step: [3100/6250], Loss: 1.4684 \n",
      "\n",
      "Epoch: [7/100], Step: [3200/6250], Loss: 1.4960 \n",
      "\n",
      "Epoch: [7/100], Step: [3300/6250], Loss: 1.3472 \n",
      "\n",
      "Epoch: [7/100], Step: [3400/6250], Loss: 0.8767 \n",
      "\n",
      "Epoch: [7/100], Step: [3500/6250], Loss: 1.6947 \n",
      "\n",
      "Epoch: [7/100], Step: [3600/6250], Loss: 1.3783 \n",
      "\n",
      "Epoch: [7/100], Step: [3700/6250], Loss: 1.1215 \n",
      "\n",
      "Epoch: [7/100], Step: [3800/6250], Loss: 1.1083 \n",
      "\n",
      "Epoch: [7/100], Step: [3900/6250], Loss: 1.8735 \n",
      "\n",
      "Epoch: [7/100], Step: [4000/6250], Loss: 2.4204 \n",
      "\n",
      "Epoch: [7/100], Step: [4100/6250], Loss: 1.8596 \n",
      "\n",
      "Epoch: [7/100], Step: [4200/6250], Loss: 1.1331 \n",
      "\n",
      "Epoch: [7/100], Step: [4300/6250], Loss: 1.5735 \n",
      "\n",
      "Epoch: [7/100], Step: [4400/6250], Loss: 1.4497 \n",
      "\n",
      "Epoch: [7/100], Step: [4500/6250], Loss: 1.5225 \n",
      "\n",
      "Epoch: [7/100], Step: [4600/6250], Loss: 1.3100 \n",
      "\n",
      "Epoch: [7/100], Step: [4700/6250], Loss: 1.1764 \n",
      "\n",
      "Epoch: [7/100], Step: [4800/6250], Loss: 1.1329 \n",
      "\n",
      "Epoch: [7/100], Step: [4900/6250], Loss: 1.9411 \n",
      "\n",
      "Epoch: [7/100], Step: [5000/6250], Loss: 1.8786 \n",
      "\n",
      "Epoch: [7/100], Step: [5100/6250], Loss: 1.4209 \n",
      "\n",
      "Epoch: [7/100], Step: [5200/6250], Loss: 1.7333 \n",
      "\n",
      "Epoch: [7/100], Step: [5300/6250], Loss: 1.1040 \n",
      "\n",
      "Epoch: [7/100], Step: [5400/6250], Loss: 1.7056 \n",
      "\n",
      "Epoch: [7/100], Step: [5500/6250], Loss: 1.3623 \n",
      "\n",
      "Epoch: [7/100], Step: [5600/6250], Loss: 1.1572 \n",
      "\n",
      "Epoch: [7/100], Step: [5700/6250], Loss: 1.7254 \n",
      "\n",
      "Epoch: [7/100], Step: [5800/6250], Loss: 1.7930 \n",
      "\n",
      "Epoch: [7/100], Step: [5900/6250], Loss: 1.2898 \n",
      "\n",
      "Epoch: [7/100], Step: [6000/6250], Loss: 1.2142 \n",
      "\n",
      "Epoch: [7/100], Step: [6100/6250], Loss: 1.6180 \n",
      "\n",
      "Epoch: [7/100], Step: [6200/6250], Loss: 1.3373 \n",
      "\n",
      "Epoch: [8/100], Step: [100/6250], Loss: 1.4403 \n",
      "\n",
      "Epoch: [8/100], Step: [200/6250], Loss: 1.7785 \n",
      "\n",
      "Epoch: [8/100], Step: [300/6250], Loss: 1.2327 \n",
      "\n",
      "Epoch: [8/100], Step: [400/6250], Loss: 1.0940 \n",
      "\n",
      "Epoch: [8/100], Step: [500/6250], Loss: 1.0998 \n",
      "\n",
      "Epoch: [8/100], Step: [600/6250], Loss: 1.1235 \n",
      "\n",
      "Epoch: [8/100], Step: [700/6250], Loss: 1.5502 \n",
      "\n",
      "Epoch: [8/100], Step: [800/6250], Loss: 2.1920 \n",
      "\n",
      "Epoch: [8/100], Step: [900/6250], Loss: 1.3812 \n",
      "\n",
      "Epoch: [8/100], Step: [1000/6250], Loss: 1.5064 \n",
      "\n",
      "Epoch: [8/100], Step: [1100/6250], Loss: 2.0014 \n",
      "\n",
      "Epoch: [8/100], Step: [1200/6250], Loss: 1.4181 \n",
      "\n",
      "Epoch: [8/100], Step: [1300/6250], Loss: 1.7627 \n",
      "\n",
      "Epoch: [8/100], Step: [1400/6250], Loss: 1.4571 \n",
      "\n",
      "Epoch: [8/100], Step: [1500/6250], Loss: 1.8052 \n",
      "\n",
      "Epoch: [8/100], Step: [1600/6250], Loss: 1.6209 \n",
      "\n",
      "Epoch: [8/100], Step: [1700/6250], Loss: 1.4761 \n",
      "\n",
      "Epoch: [8/100], Step: [1800/6250], Loss: 2.1194 \n",
      "\n",
      "Epoch: [8/100], Step: [1900/6250], Loss: 1.5852 \n",
      "\n",
      "Epoch: [8/100], Step: [2000/6250], Loss: 1.1286 \n",
      "\n",
      "Epoch: [8/100], Step: [2100/6250], Loss: 1.3526 \n",
      "\n",
      "Epoch: [8/100], Step: [2200/6250], Loss: 1.7579 \n",
      "\n",
      "Epoch: [8/100], Step: [2300/6250], Loss: 1.5188 \n",
      "\n",
      "Epoch: [8/100], Step: [2400/6250], Loss: 1.4197 \n",
      "\n",
      "Epoch: [8/100], Step: [2500/6250], Loss: 1.3881 \n",
      "\n",
      "Epoch: [8/100], Step: [2600/6250], Loss: 1.1204 \n",
      "\n",
      "Epoch: [8/100], Step: [2700/6250], Loss: 1.4397 \n",
      "\n",
      "Epoch: [8/100], Step: [2800/6250], Loss: 1.6410 \n",
      "\n",
      "Epoch: [8/100], Step: [2900/6250], Loss: 1.2236 \n",
      "\n",
      "Epoch: [8/100], Step: [3000/6250], Loss: 1.2134 \n",
      "\n",
      "Epoch: [8/100], Step: [3100/6250], Loss: 1.4169 \n",
      "\n",
      "Epoch: [8/100], Step: [3200/6250], Loss: 0.8144 \n",
      "\n",
      "Epoch: [8/100], Step: [3300/6250], Loss: 1.0246 \n",
      "\n",
      "Epoch: [8/100], Step: [3400/6250], Loss: 1.4409 \n",
      "\n",
      "Epoch: [8/100], Step: [3500/6250], Loss: 1.1899 \n",
      "\n",
      "Epoch: [8/100], Step: [3600/6250], Loss: 1.1099 \n",
      "\n",
      "Epoch: [8/100], Step: [3700/6250], Loss: 1.7757 \n",
      "\n",
      "Epoch: [8/100], Step: [3800/6250], Loss: 1.1568 \n",
      "\n",
      "Epoch: [8/100], Step: [3900/6250], Loss: 1.5367 \n",
      "\n",
      "Epoch: [8/100], Step: [4000/6250], Loss: 0.8601 \n",
      "\n",
      "Epoch: [8/100], Step: [4100/6250], Loss: 1.7946 \n",
      "\n",
      "Epoch: [8/100], Step: [4200/6250], Loss: 2.2772 \n",
      "\n",
      "Epoch: [8/100], Step: [4300/6250], Loss: 0.9454 \n",
      "\n",
      "Epoch: [8/100], Step: [4400/6250], Loss: 1.2816 \n",
      "\n",
      "Epoch: [8/100], Step: [4500/6250], Loss: 2.0406 \n",
      "\n",
      "Epoch: [8/100], Step: [4600/6250], Loss: 1.5896 \n",
      "\n",
      "Epoch: [8/100], Step: [4700/6250], Loss: 0.9293 \n",
      "\n",
      "Epoch: [8/100], Step: [4800/6250], Loss: 1.5012 \n",
      "\n",
      "Epoch: [8/100], Step: [4900/6250], Loss: 1.4969 \n",
      "\n",
      "Epoch: [8/100], Step: [5000/6250], Loss: 1.0954 \n",
      "\n",
      "Epoch: [8/100], Step: [5100/6250], Loss: 2.0665 \n",
      "\n",
      "Epoch: [8/100], Step: [5200/6250], Loss: 1.0755 \n",
      "\n",
      "Epoch: [8/100], Step: [5300/6250], Loss: 1.4023 \n",
      "\n",
      "Epoch: [8/100], Step: [5400/6250], Loss: 1.6066 \n",
      "\n",
      "Epoch: [8/100], Step: [5500/6250], Loss: 1.3068 \n",
      "\n",
      "Epoch: [8/100], Step: [5600/6250], Loss: 1.4730 \n",
      "\n",
      "Epoch: [8/100], Step: [5700/6250], Loss: 1.3802 \n",
      "\n",
      "Epoch: [8/100], Step: [5800/6250], Loss: 1.2332 \n",
      "\n",
      "Epoch: [8/100], Step: [5900/6250], Loss: 2.2018 \n",
      "\n",
      "Epoch: [8/100], Step: [6000/6250], Loss: 1.3767 \n",
      "\n",
      "Epoch: [8/100], Step: [6100/6250], Loss: 1.6648 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8/100], Step: [6200/6250], Loss: 1.6321 \n",
      "\n",
      "Epoch: [9/100], Step: [100/6250], Loss: 1.4687 \n",
      "\n",
      "Epoch: [9/100], Step: [200/6250], Loss: 1.8464 \n",
      "\n",
      "Epoch: [9/100], Step: [300/6250], Loss: 0.9534 \n",
      "\n",
      "Epoch: [9/100], Step: [400/6250], Loss: 1.5679 \n",
      "\n",
      "Epoch: [9/100], Step: [500/6250], Loss: 1.5265 \n",
      "\n",
      "Epoch: [9/100], Step: [600/6250], Loss: 1.2680 \n",
      "\n",
      "Epoch: [9/100], Step: [700/6250], Loss: 0.8878 \n",
      "\n",
      "Epoch: [9/100], Step: [800/6250], Loss: 1.4634 \n",
      "\n",
      "Epoch: [9/100], Step: [900/6250], Loss: 1.2692 \n",
      "\n",
      "Epoch: [9/100], Step: [1000/6250], Loss: 1.6023 \n",
      "\n",
      "Epoch: [9/100], Step: [1100/6250], Loss: 1.1672 \n",
      "\n",
      "Epoch: [9/100], Step: [1200/6250], Loss: 1.3738 \n",
      "\n",
      "Epoch: [9/100], Step: [1300/6250], Loss: 1.2882 \n",
      "\n",
      "Epoch: [9/100], Step: [1400/6250], Loss: 1.7553 \n",
      "\n",
      "Epoch: [9/100], Step: [1500/6250], Loss: 1.4641 \n",
      "\n",
      "Epoch: [9/100], Step: [1600/6250], Loss: 1.7228 \n",
      "\n",
      "Epoch: [9/100], Step: [1700/6250], Loss: 1.4067 \n",
      "\n",
      "Epoch: [9/100], Step: [1800/6250], Loss: 0.9890 \n",
      "\n",
      "Epoch: [9/100], Step: [1900/6250], Loss: 1.6606 \n",
      "\n",
      "Epoch: [9/100], Step: [2000/6250], Loss: 1.0431 \n",
      "\n",
      "Epoch: [9/100], Step: [2100/6250], Loss: 1.3702 \n",
      "\n",
      "Epoch: [9/100], Step: [2200/6250], Loss: 1.1169 \n",
      "\n",
      "Epoch: [9/100], Step: [2300/6250], Loss: 1.6864 \n",
      "\n",
      "Epoch: [9/100], Step: [2400/6250], Loss: 1.2553 \n",
      "\n",
      "Epoch: [9/100], Step: [2500/6250], Loss: 2.0427 \n",
      "\n",
      "Epoch: [9/100], Step: [2600/6250], Loss: 1.3491 \n",
      "\n",
      "Epoch: [9/100], Step: [2700/6250], Loss: 1.5884 \n",
      "\n",
      "Epoch: [9/100], Step: [2800/6250], Loss: 0.8970 \n",
      "\n",
      "Epoch: [9/100], Step: [2900/6250], Loss: 1.4274 \n",
      "\n",
      "Epoch: [9/100], Step: [3000/6250], Loss: 0.9620 \n",
      "\n",
      "Epoch: [9/100], Step: [3100/6250], Loss: 1.5489 \n",
      "\n",
      "Epoch: [9/100], Step: [3200/6250], Loss: 1.4786 \n",
      "\n",
      "Epoch: [9/100], Step: [3300/6250], Loss: 1.4384 \n",
      "\n",
      "Epoch: [9/100], Step: [3400/6250], Loss: 1.4855 \n",
      "\n",
      "Epoch: [9/100], Step: [3500/6250], Loss: 1.0635 \n",
      "\n",
      "Epoch: [9/100], Step: [3600/6250], Loss: 1.3678 \n",
      "\n",
      "Epoch: [9/100], Step: [3700/6250], Loss: 1.3818 \n",
      "\n",
      "Epoch: [9/100], Step: [3800/6250], Loss: 1.4705 \n",
      "\n",
      "Epoch: [9/100], Step: [3900/6250], Loss: 1.4178 \n",
      "\n",
      "Epoch: [9/100], Step: [4000/6250], Loss: 1.1698 \n",
      "\n",
      "Epoch: [9/100], Step: [4100/6250], Loss: 1.0980 \n",
      "\n",
      "Epoch: [9/100], Step: [4200/6250], Loss: 1.5284 \n",
      "\n",
      "Epoch: [9/100], Step: [4300/6250], Loss: 1.3614 \n",
      "\n",
      "Epoch: [9/100], Step: [4400/6250], Loss: 1.1874 \n",
      "\n",
      "Epoch: [9/100], Step: [4500/6250], Loss: 1.1195 \n",
      "\n",
      "Epoch: [9/100], Step: [4600/6250], Loss: 1.0515 \n",
      "\n",
      "Epoch: [9/100], Step: [4700/6250], Loss: 1.4079 \n",
      "\n",
      "Epoch: [9/100], Step: [4800/6250], Loss: 1.1964 \n",
      "\n",
      "Epoch: [9/100], Step: [4900/6250], Loss: 1.6606 \n",
      "\n",
      "Epoch: [9/100], Step: [5000/6250], Loss: 1.4569 \n",
      "\n",
      "Epoch: [9/100], Step: [5100/6250], Loss: 1.3814 \n",
      "\n",
      "Epoch: [9/100], Step: [5200/6250], Loss: 1.8551 \n",
      "\n",
      "Epoch: [9/100], Step: [5300/6250], Loss: 2.3742 \n",
      "\n",
      "Epoch: [9/100], Step: [5400/6250], Loss: 1.1222 \n",
      "\n",
      "Epoch: [9/100], Step: [5500/6250], Loss: 2.2670 \n",
      "\n",
      "Epoch: [9/100], Step: [5600/6250], Loss: 0.9487 \n",
      "\n",
      "Epoch: [9/100], Step: [5700/6250], Loss: 1.2094 \n",
      "\n",
      "Epoch: [9/100], Step: [5800/6250], Loss: 1.5191 \n",
      "\n",
      "Epoch: [9/100], Step: [5900/6250], Loss: 1.5799 \n",
      "\n",
      "Epoch: [9/100], Step: [6000/6250], Loss: 1.2423 \n",
      "\n",
      "Epoch: [9/100], Step: [6100/6250], Loss: 1.1436 \n",
      "\n",
      "Epoch: [9/100], Step: [6200/6250], Loss: 1.5225 \n",
      "\n",
      "Epoch: [10/100], Step: [100/6250], Loss: 1.7225 \n",
      "\n",
      "Epoch: [10/100], Step: [200/6250], Loss: 1.2159 \n",
      "\n",
      "Epoch: [10/100], Step: [300/6250], Loss: 1.3299 \n",
      "\n",
      "Epoch: [10/100], Step: [400/6250], Loss: 1.4257 \n",
      "\n",
      "Epoch: [10/100], Step: [500/6250], Loss: 1.5591 \n",
      "\n",
      "Epoch: [10/100], Step: [600/6250], Loss: 1.3455 \n",
      "\n",
      "Epoch: [10/100], Step: [700/6250], Loss: 1.5911 \n",
      "\n",
      "Epoch: [10/100], Step: [800/6250], Loss: 1.0645 \n",
      "\n",
      "Epoch: [10/100], Step: [900/6250], Loss: 1.5420 \n",
      "\n",
      "Epoch: [10/100], Step: [1000/6250], Loss: 1.4761 \n",
      "\n",
      "Epoch: [10/100], Step: [1100/6250], Loss: 1.2104 \n",
      "\n",
      "Epoch: [10/100], Step: [1200/6250], Loss: 1.1205 \n",
      "\n",
      "Epoch: [10/100], Step: [1300/6250], Loss: 1.5716 \n",
      "\n",
      "Epoch: [10/100], Step: [1400/6250], Loss: 1.2998 \n",
      "\n",
      "Epoch: [10/100], Step: [1500/6250], Loss: 1.3432 \n",
      "\n",
      "Epoch: [10/100], Step: [1600/6250], Loss: 1.1941 \n",
      "\n",
      "Epoch: [10/100], Step: [1700/6250], Loss: 1.4783 \n",
      "\n",
      "Epoch: [10/100], Step: [1800/6250], Loss: 1.4328 \n",
      "\n",
      "Epoch: [10/100], Step: [1900/6250], Loss: 1.3851 \n",
      "\n",
      "Epoch: [10/100], Step: [2000/6250], Loss: 1.2089 \n",
      "\n",
      "Epoch: [10/100], Step: [2100/6250], Loss: 1.3565 \n",
      "\n",
      "Epoch: [10/100], Step: [2200/6250], Loss: 1.0105 \n",
      "\n",
      "Epoch: [10/100], Step: [2300/6250], Loss: 1.2722 \n",
      "\n",
      "Epoch: [10/100], Step: [2400/6250], Loss: 0.9356 \n",
      "\n",
      "Epoch: [10/100], Step: [2500/6250], Loss: 1.6939 \n",
      "\n",
      "Epoch: [10/100], Step: [2600/6250], Loss: 1.0354 \n",
      "\n",
      "Epoch: [10/100], Step: [2700/6250], Loss: 1.6121 \n",
      "\n",
      "Epoch: [10/100], Step: [2800/6250], Loss: 1.6500 \n",
      "\n",
      "Epoch: [10/100], Step: [2900/6250], Loss: 1.4124 \n",
      "\n",
      "Epoch: [10/100], Step: [3000/6250], Loss: 0.7566 \n",
      "\n",
      "Epoch: [10/100], Step: [3100/6250], Loss: 1.1837 \n",
      "\n",
      "Epoch: [10/100], Step: [3200/6250], Loss: 1.2411 \n",
      "\n",
      "Epoch: [10/100], Step: [3300/6250], Loss: 1.4097 \n",
      "\n",
      "Epoch: [10/100], Step: [3400/6250], Loss: 1.5745 \n",
      "\n",
      "Epoch: [10/100], Step: [3500/6250], Loss: 1.1179 \n",
      "\n",
      "Epoch: [10/100], Step: [3600/6250], Loss: 0.9001 \n",
      "\n",
      "Epoch: [10/100], Step: [3700/6250], Loss: 2.0226 \n",
      "\n",
      "Epoch: [10/100], Step: [3800/6250], Loss: 1.3427 \n",
      "\n",
      "Epoch: [10/100], Step: [3900/6250], Loss: 1.3267 \n",
      "\n",
      "Epoch: [10/100], Step: [4000/6250], Loss: 1.9116 \n",
      "\n",
      "Epoch: [10/100], Step: [4100/6250], Loss: 1.4175 \n",
      "\n",
      "Epoch: [10/100], Step: [4200/6250], Loss: 1.3703 \n",
      "\n",
      "Epoch: [10/100], Step: [4300/6250], Loss: 0.9362 \n",
      "\n",
      "Epoch: [10/100], Step: [4400/6250], Loss: 0.9223 \n",
      "\n",
      "Epoch: [10/100], Step: [4500/6250], Loss: 1.0093 \n",
      "\n",
      "Epoch: [10/100], Step: [4600/6250], Loss: 0.8184 \n",
      "\n",
      "Epoch: [10/100], Step: [4700/6250], Loss: 1.0382 \n",
      "\n",
      "Epoch: [10/100], Step: [4800/6250], Loss: 1.3242 \n",
      "\n",
      "Epoch: [10/100], Step: [4900/6250], Loss: 1.1160 \n",
      "\n",
      "Epoch: [10/100], Step: [5000/6250], Loss: 0.9956 \n",
      "\n",
      "Epoch: [10/100], Step: [5100/6250], Loss: 1.2886 \n",
      "\n",
      "Epoch: [10/100], Step: [5200/6250], Loss: 1.6901 \n",
      "\n",
      "Epoch: [10/100], Step: [5300/6250], Loss: 0.7416 \n",
      "\n",
      "Epoch: [10/100], Step: [5400/6250], Loss: 1.2754 \n",
      "\n",
      "Epoch: [10/100], Step: [5500/6250], Loss: 2.0870 \n",
      "\n",
      "Epoch: [10/100], Step: [5600/6250], Loss: 1.4439 \n",
      "\n",
      "Epoch: [10/100], Step: [5700/6250], Loss: 2.1130 \n",
      "\n",
      "Epoch: [10/100], Step: [5800/6250], Loss: 1.4784 \n",
      "\n",
      "Epoch: [10/100], Step: [5900/6250], Loss: 1.2042 \n",
      "\n",
      "Epoch: [10/100], Step: [6000/6250], Loss: 1.9976 \n",
      "\n",
      "Epoch: [10/100], Step: [6100/6250], Loss: 0.9324 \n",
      "\n",
      "Epoch: [10/100], Step: [6200/6250], Loss: 1.5595 \n",
      "\n",
      "Epoch: [11/100], Step: [100/6250], Loss: 1.4040 \n",
      "\n",
      "Epoch: [11/100], Step: [200/6250], Loss: 1.6617 \n",
      "\n",
      "Epoch: [11/100], Step: [300/6250], Loss: 1.0333 \n",
      "\n",
      "Epoch: [11/100], Step: [400/6250], Loss: 0.8934 \n",
      "\n",
      "Epoch: [11/100], Step: [500/6250], Loss: 1.4423 \n",
      "\n",
      "Epoch: [11/100], Step: [600/6250], Loss: 1.0019 \n",
      "\n",
      "Epoch: [11/100], Step: [700/6250], Loss: 1.8313 \n",
      "\n",
      "Epoch: [11/100], Step: [800/6250], Loss: 1.1261 \n",
      "\n",
      "Epoch: [11/100], Step: [900/6250], Loss: 0.8173 \n",
      "\n",
      "Epoch: [11/100], Step: [1000/6250], Loss: 1.9435 \n",
      "\n",
      "Epoch: [11/100], Step: [1100/6250], Loss: 1.3088 \n",
      "\n",
      "Epoch: [11/100], Step: [1200/6250], Loss: 1.4858 \n",
      "\n",
      "Epoch: [11/100], Step: [1300/6250], Loss: 1.4556 \n",
      "\n",
      "Epoch: [11/100], Step: [1400/6250], Loss: 1.5494 \n",
      "\n",
      "Epoch: [11/100], Step: [1500/6250], Loss: 1.9514 \n",
      "\n",
      "Epoch: [11/100], Step: [1600/6250], Loss: 1.2532 \n",
      "\n",
      "Epoch: [11/100], Step: [1700/6250], Loss: 1.1806 \n",
      "\n",
      "Epoch: [11/100], Step: [1800/6250], Loss: 1.2026 \n",
      "\n",
      "Epoch: [11/100], Step: [1900/6250], Loss: 1.4585 \n",
      "\n",
      "Epoch: [11/100], Step: [2000/6250], Loss: 1.0965 \n",
      "\n",
      "Epoch: [11/100], Step: [2100/6250], Loss: 1.1420 \n",
      "\n",
      "Epoch: [11/100], Step: [2200/6250], Loss: 1.5589 \n",
      "\n",
      "Epoch: [11/100], Step: [2300/6250], Loss: 1.5225 \n",
      "\n",
      "Epoch: [11/100], Step: [2400/6250], Loss: 2.0665 \n",
      "\n",
      "Epoch: [11/100], Step: [2500/6250], Loss: 1.4228 \n",
      "\n",
      "Epoch: [11/100], Step: [2600/6250], Loss: 1.3047 \n",
      "\n",
      "Epoch: [11/100], Step: [2700/6250], Loss: 1.7424 \n",
      "\n",
      "Epoch: [11/100], Step: [2800/6250], Loss: 1.0815 \n",
      "\n",
      "Epoch: [11/100], Step: [2900/6250], Loss: 1.7340 \n",
      "\n",
      "Epoch: [11/100], Step: [3000/6250], Loss: 2.1236 \n",
      "\n",
      "Epoch: [11/100], Step: [3100/6250], Loss: 0.8458 \n",
      "\n",
      "Epoch: [11/100], Step: [3200/6250], Loss: 1.3696 \n",
      "\n",
      "Epoch: [11/100], Step: [3300/6250], Loss: 1.4572 \n",
      "\n",
      "Epoch: [11/100], Step: [3400/6250], Loss: 1.6612 \n",
      "\n",
      "Epoch: [11/100], Step: [3500/6250], Loss: 1.2168 \n",
      "\n",
      "Epoch: [11/100], Step: [3600/6250], Loss: 1.7550 \n",
      "\n",
      "Epoch: [11/100], Step: [3700/6250], Loss: 1.5139 \n",
      "\n",
      "Epoch: [11/100], Step: [3800/6250], Loss: 1.2319 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [11/100], Step: [3900/6250], Loss: 2.3364 \n",
      "\n",
      "Epoch: [11/100], Step: [4000/6250], Loss: 1.7613 \n",
      "\n",
      "Epoch: [11/100], Step: [4100/6250], Loss: 1.3421 \n",
      "\n",
      "Epoch: [11/100], Step: [4200/6250], Loss: 1.6393 \n",
      "\n",
      "Epoch: [11/100], Step: [4300/6250], Loss: 1.3783 \n",
      "\n",
      "Epoch: [11/100], Step: [4400/6250], Loss: 1.2233 \n",
      "\n",
      "Epoch: [11/100], Step: [4500/6250], Loss: 0.8252 \n",
      "\n",
      "Epoch: [11/100], Step: [4600/6250], Loss: 1.4839 \n",
      "\n",
      "Epoch: [11/100], Step: [4700/6250], Loss: 1.3768 \n",
      "\n",
      "Epoch: [11/100], Step: [4800/6250], Loss: 1.0280 \n",
      "\n",
      "Epoch: [11/100], Step: [4900/6250], Loss: 1.3415 \n",
      "\n",
      "Epoch: [11/100], Step: [5000/6250], Loss: 2.4373 \n",
      "\n",
      "Epoch: [11/100], Step: [5100/6250], Loss: 0.6368 \n",
      "\n",
      "Epoch: [11/100], Step: [5200/6250], Loss: 1.1373 \n",
      "\n",
      "Epoch: [11/100], Step: [5300/6250], Loss: 1.7960 \n",
      "\n",
      "Epoch: [11/100], Step: [5400/6250], Loss: 1.4309 \n",
      "\n",
      "Epoch: [11/100], Step: [5500/6250], Loss: 0.8635 \n",
      "\n",
      "Epoch: [11/100], Step: [5600/6250], Loss: 1.3215 \n",
      "\n",
      "Epoch: [11/100], Step: [5700/6250], Loss: 1.7137 \n",
      "\n",
      "Epoch: [11/100], Step: [5800/6250], Loss: 1.7428 \n",
      "\n",
      "Epoch: [11/100], Step: [5900/6250], Loss: 1.5593 \n",
      "\n",
      "Epoch: [11/100], Step: [6000/6250], Loss: 1.8113 \n",
      "\n",
      "Epoch: [11/100], Step: [6100/6250], Loss: 0.9000 \n",
      "\n",
      "Epoch: [11/100], Step: [6200/6250], Loss: 1.8421 \n",
      "\n",
      "Epoch: [12/100], Step: [100/6250], Loss: 1.7374 \n",
      "\n",
      "Epoch: [12/100], Step: [200/6250], Loss: 1.5891 \n",
      "\n",
      "Epoch: [12/100], Step: [300/6250], Loss: 1.1068 \n",
      "\n",
      "Epoch: [12/100], Step: [400/6250], Loss: 1.1599 \n",
      "\n",
      "Epoch: [12/100], Step: [500/6250], Loss: 0.9786 \n",
      "\n",
      "Epoch: [12/100], Step: [600/6250], Loss: 1.0669 \n",
      "\n",
      "Epoch: [12/100], Step: [700/6250], Loss: 0.9675 \n",
      "\n",
      "Epoch: [12/100], Step: [800/6250], Loss: 2.2668 \n",
      "\n",
      "Epoch: [12/100], Step: [900/6250], Loss: 2.1472 \n",
      "\n",
      "Epoch: [12/100], Step: [1000/6250], Loss: 1.4205 \n",
      "\n",
      "Epoch: [12/100], Step: [1100/6250], Loss: 1.2981 \n",
      "\n",
      "Epoch: [12/100], Step: [1200/6250], Loss: 1.5575 \n",
      "\n",
      "Epoch: [12/100], Step: [1300/6250], Loss: 1.7210 \n",
      "\n",
      "Epoch: [12/100], Step: [1400/6250], Loss: 1.1756 \n",
      "\n",
      "Epoch: [12/100], Step: [1500/6250], Loss: 1.6926 \n",
      "\n",
      "Epoch: [12/100], Step: [1600/6250], Loss: 1.1379 \n",
      "\n",
      "Epoch: [12/100], Step: [1700/6250], Loss: 1.0436 \n",
      "\n",
      "Epoch: [12/100], Step: [1800/6250], Loss: 1.7006 \n",
      "\n",
      "Epoch: [12/100], Step: [1900/6250], Loss: 1.4368 \n",
      "\n",
      "Epoch: [12/100], Step: [2000/6250], Loss: 1.3009 \n",
      "\n",
      "Epoch: [12/100], Step: [2100/6250], Loss: 1.4397 \n",
      "\n",
      "Epoch: [12/100], Step: [2200/6250], Loss: 1.0539 \n",
      "\n",
      "Epoch: [12/100], Step: [2300/6250], Loss: 1.4481 \n",
      "\n",
      "Epoch: [12/100], Step: [2400/6250], Loss: 0.6340 \n",
      "\n",
      "Epoch: [12/100], Step: [2500/6250], Loss: 1.4668 \n",
      "\n",
      "Epoch: [12/100], Step: [2600/6250], Loss: 1.3599 \n",
      "\n",
      "Epoch: [12/100], Step: [2700/6250], Loss: 1.6306 \n",
      "\n",
      "Epoch: [12/100], Step: [2800/6250], Loss: 0.8796 \n",
      "\n",
      "Epoch: [12/100], Step: [2900/6250], Loss: 2.0087 \n",
      "\n",
      "Epoch: [12/100], Step: [3000/6250], Loss: 1.1631 \n",
      "\n",
      "Epoch: [12/100], Step: [3100/6250], Loss: 1.2072 \n",
      "\n",
      "Epoch: [12/100], Step: [3200/6250], Loss: 0.9080 \n",
      "\n",
      "Epoch: [12/100], Step: [3300/6250], Loss: 1.2532 \n",
      "\n",
      "Epoch: [12/100], Step: [3400/6250], Loss: 1.5031 \n",
      "\n",
      "Epoch: [12/100], Step: [3500/6250], Loss: 1.9448 \n",
      "\n",
      "Epoch: [12/100], Step: [3600/6250], Loss: 1.6161 \n",
      "\n",
      "Epoch: [12/100], Step: [3700/6250], Loss: 1.0025 \n",
      "\n",
      "Epoch: [12/100], Step: [3800/6250], Loss: 1.0189 \n",
      "\n",
      "Epoch: [12/100], Step: [3900/6250], Loss: 0.7218 \n",
      "\n",
      "Epoch: [12/100], Step: [4000/6250], Loss: 1.3239 \n",
      "\n",
      "Epoch: [12/100], Step: [4100/6250], Loss: 1.2526 \n",
      "\n",
      "Epoch: [12/100], Step: [4200/6250], Loss: 0.9476 \n",
      "\n",
      "Epoch: [12/100], Step: [4300/6250], Loss: 1.3642 \n",
      "\n",
      "Epoch: [12/100], Step: [4400/6250], Loss: 1.1574 \n",
      "\n",
      "Epoch: [12/100], Step: [4500/6250], Loss: 0.8571 \n",
      "\n",
      "Epoch: [12/100], Step: [4600/6250], Loss: 1.3347 \n",
      "\n",
      "Epoch: [12/100], Step: [4700/6250], Loss: 1.1860 \n",
      "\n",
      "Epoch: [12/100], Step: [4800/6250], Loss: 1.1451 \n",
      "\n",
      "Epoch: [12/100], Step: [4900/6250], Loss: 1.5978 \n",
      "\n",
      "Epoch: [12/100], Step: [5000/6250], Loss: 1.2185 \n",
      "\n",
      "Epoch: [12/100], Step: [5100/6250], Loss: 1.1357 \n",
      "\n",
      "Epoch: [12/100], Step: [5200/6250], Loss: 1.6534 \n",
      "\n",
      "Epoch: [12/100], Step: [5300/6250], Loss: 2.2569 \n",
      "\n",
      "Epoch: [12/100], Step: [5400/6250], Loss: 1.2574 \n",
      "\n",
      "Epoch: [12/100], Step: [5500/6250], Loss: 2.1884 \n",
      "\n",
      "Epoch: [12/100], Step: [5600/6250], Loss: 1.4412 \n",
      "\n",
      "Epoch: [12/100], Step: [5700/6250], Loss: 1.2848 \n",
      "\n",
      "Epoch: [12/100], Step: [5800/6250], Loss: 0.8579 \n",
      "\n",
      "Epoch: [12/100], Step: [5900/6250], Loss: 1.4005 \n",
      "\n",
      "Epoch: [12/100], Step: [6000/6250], Loss: 1.3268 \n",
      "\n",
      "Epoch: [12/100], Step: [6100/6250], Loss: 1.4367 \n",
      "\n",
      "Epoch: [12/100], Step: [6200/6250], Loss: 1.5430 \n",
      "\n",
      "Epoch: [13/100], Step: [100/6250], Loss: 1.0325 \n",
      "\n",
      "Epoch: [13/100], Step: [200/6250], Loss: 1.5086 \n",
      "\n",
      "Epoch: [13/100], Step: [300/6250], Loss: 1.3769 \n",
      "\n",
      "Epoch: [13/100], Step: [400/6250], Loss: 1.5907 \n",
      "\n",
      "Epoch: [13/100], Step: [500/6250], Loss: 0.7278 \n",
      "\n",
      "Epoch: [13/100], Step: [600/6250], Loss: 1.3271 \n",
      "\n",
      "Epoch: [13/100], Step: [700/6250], Loss: 0.8041 \n",
      "\n",
      "Epoch: [13/100], Step: [800/6250], Loss: 1.0862 \n",
      "\n",
      "Epoch: [13/100], Step: [900/6250], Loss: 1.5214 \n",
      "\n",
      "Epoch: [13/100], Step: [1000/6250], Loss: 0.9518 \n",
      "\n",
      "Epoch: [13/100], Step: [1100/6250], Loss: 1.2081 \n",
      "\n",
      "Epoch: [13/100], Step: [1200/6250], Loss: 1.2457 \n",
      "\n",
      "Epoch: [13/100], Step: [1300/6250], Loss: 1.4555 \n",
      "\n",
      "Epoch: [13/100], Step: [1400/6250], Loss: 0.9557 \n",
      "\n",
      "Epoch: [13/100], Step: [1500/6250], Loss: 1.2466 \n",
      "\n",
      "Epoch: [13/100], Step: [1600/6250], Loss: 0.9928 \n",
      "\n",
      "Epoch: [13/100], Step: [1700/6250], Loss: 0.7082 \n",
      "\n",
      "Epoch: [13/100], Step: [1800/6250], Loss: 0.9424 \n",
      "\n",
      "Epoch: [13/100], Step: [1900/6250], Loss: 1.4239 \n",
      "\n",
      "Epoch: [13/100], Step: [2000/6250], Loss: 1.0333 \n",
      "\n",
      "Epoch: [13/100], Step: [2100/6250], Loss: 0.9405 \n",
      "\n",
      "Epoch: [13/100], Step: [2200/6250], Loss: 1.9834 \n",
      "\n",
      "Epoch: [13/100], Step: [2300/6250], Loss: 1.5696 \n",
      "\n",
      "Epoch: [13/100], Step: [2400/6250], Loss: 1.7353 \n",
      "\n",
      "Epoch: [13/100], Step: [2500/6250], Loss: 1.3347 \n",
      "\n",
      "Epoch: [13/100], Step: [2600/6250], Loss: 1.1499 \n",
      "\n",
      "Epoch: [13/100], Step: [2700/6250], Loss: 1.3325 \n",
      "\n",
      "Epoch: [13/100], Step: [2800/6250], Loss: 0.8600 \n",
      "\n",
      "Epoch: [13/100], Step: [2900/6250], Loss: 2.0460 \n",
      "\n",
      "Epoch: [13/100], Step: [3000/6250], Loss: 1.7426 \n",
      "\n",
      "Epoch: [13/100], Step: [3100/6250], Loss: 1.1969 \n",
      "\n",
      "Epoch: [13/100], Step: [3200/6250], Loss: 1.1298 \n",
      "\n",
      "Epoch: [13/100], Step: [3300/6250], Loss: 0.8158 \n",
      "\n",
      "Epoch: [13/100], Step: [3400/6250], Loss: 1.7045 \n",
      "\n",
      "Epoch: [13/100], Step: [3500/6250], Loss: 1.0564 \n",
      "\n",
      "Epoch: [13/100], Step: [3600/6250], Loss: 1.9424 \n",
      "\n",
      "Epoch: [13/100], Step: [3700/6250], Loss: 1.9734 \n",
      "\n",
      "Epoch: [13/100], Step: [3800/6250], Loss: 1.4848 \n",
      "\n",
      "Epoch: [13/100], Step: [3900/6250], Loss: 1.3323 \n",
      "\n",
      "Epoch: [13/100], Step: [4000/6250], Loss: 1.0509 \n",
      "\n",
      "Epoch: [13/100], Step: [4100/6250], Loss: 1.7788 \n",
      "\n",
      "Epoch: [13/100], Step: [4200/6250], Loss: 1.2167 \n",
      "\n",
      "Epoch: [13/100], Step: [4300/6250], Loss: 1.6243 \n",
      "\n",
      "Epoch: [13/100], Step: [4400/6250], Loss: 0.7559 \n",
      "\n",
      "Epoch: [13/100], Step: [4500/6250], Loss: 1.4419 \n",
      "\n",
      "Epoch: [13/100], Step: [4600/6250], Loss: 1.0855 \n",
      "\n",
      "Epoch: [13/100], Step: [4700/6250], Loss: 0.8630 \n",
      "\n",
      "Epoch: [13/100], Step: [4800/6250], Loss: 0.9450 \n",
      "\n",
      "Epoch: [13/100], Step: [4900/6250], Loss: 1.4142 \n",
      "\n",
      "Epoch: [13/100], Step: [5000/6250], Loss: 1.5469 \n",
      "\n",
      "Epoch: [13/100], Step: [5100/6250], Loss: 0.7776 \n",
      "\n",
      "Epoch: [13/100], Step: [5200/6250], Loss: 1.0121 \n",
      "\n",
      "Epoch: [13/100], Step: [5300/6250], Loss: 1.0014 \n",
      "\n",
      "Epoch: [13/100], Step: [5400/6250], Loss: 1.9956 \n",
      "\n",
      "Epoch: [13/100], Step: [5500/6250], Loss: 1.0370 \n",
      "\n",
      "Epoch: [13/100], Step: [5600/6250], Loss: 0.8401 \n",
      "\n",
      "Epoch: [13/100], Step: [5700/6250], Loss: 1.1741 \n",
      "\n",
      "Epoch: [13/100], Step: [5800/6250], Loss: 1.5402 \n",
      "\n",
      "Epoch: [13/100], Step: [5900/6250], Loss: 1.1895 \n",
      "\n",
      "Epoch: [13/100], Step: [6000/6250], Loss: 1.1435 \n",
      "\n",
      "Epoch: [13/100], Step: [6100/6250], Loss: 2.4700 \n",
      "\n",
      "Epoch: [13/100], Step: [6200/6250], Loss: 1.0824 \n",
      "\n",
      "Epoch: [14/100], Step: [100/6250], Loss: 1.4237 \n",
      "\n",
      "Epoch: [14/100], Step: [200/6250], Loss: 1.5556 \n",
      "\n",
      "Epoch: [14/100], Step: [300/6250], Loss: 1.6211 \n",
      "\n",
      "Epoch: [14/100], Step: [400/6250], Loss: 1.2437 \n",
      "\n",
      "Epoch: [14/100], Step: [500/6250], Loss: 1.1482 \n",
      "\n",
      "Epoch: [14/100], Step: [600/6250], Loss: 1.1201 \n",
      "\n",
      "Epoch: [14/100], Step: [700/6250], Loss: 1.3696 \n",
      "\n",
      "Epoch: [14/100], Step: [800/6250], Loss: 0.9341 \n",
      "\n",
      "Epoch: [14/100], Step: [900/6250], Loss: 1.3410 \n",
      "\n",
      "Epoch: [14/100], Step: [1000/6250], Loss: 1.1471 \n",
      "\n",
      "Epoch: [14/100], Step: [1100/6250], Loss: 1.3715 \n",
      "\n",
      "Epoch: [14/100], Step: [1200/6250], Loss: 1.8559 \n",
      "\n",
      "Epoch: [14/100], Step: [1300/6250], Loss: 0.9730 \n",
      "\n",
      "Epoch: [14/100], Step: [1400/6250], Loss: 1.3769 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [14/100], Step: [1500/6250], Loss: 1.1700 \n",
      "\n",
      "Epoch: [14/100], Step: [1600/6250], Loss: 0.9702 \n",
      "\n",
      "Epoch: [14/100], Step: [1700/6250], Loss: 1.3761 \n",
      "\n",
      "Epoch: [14/100], Step: [1800/6250], Loss: 0.7376 \n",
      "\n",
      "Epoch: [14/100], Step: [1900/6250], Loss: 1.0692 \n",
      "\n",
      "Epoch: [14/100], Step: [2000/6250], Loss: 1.2349 \n",
      "\n",
      "Epoch: [14/100], Step: [2100/6250], Loss: 0.7242 \n",
      "\n",
      "Epoch: [14/100], Step: [2200/6250], Loss: 1.8052 \n",
      "\n",
      "Epoch: [14/100], Step: [2300/6250], Loss: 0.8522 \n",
      "\n",
      "Epoch: [14/100], Step: [2400/6250], Loss: 1.2527 \n",
      "\n",
      "Epoch: [14/100], Step: [2500/6250], Loss: 1.1436 \n",
      "\n",
      "Epoch: [14/100], Step: [2600/6250], Loss: 1.1114 \n",
      "\n",
      "Epoch: [14/100], Step: [2700/6250], Loss: 1.4083 \n",
      "\n",
      "Epoch: [14/100], Step: [2800/6250], Loss: 1.0515 \n",
      "\n",
      "Epoch: [14/100], Step: [2900/6250], Loss: 1.4360 \n",
      "\n",
      "Epoch: [14/100], Step: [3000/6250], Loss: 1.1079 \n",
      "\n",
      "Epoch: [14/100], Step: [3100/6250], Loss: 1.5919 \n",
      "\n",
      "Epoch: [14/100], Step: [3200/6250], Loss: 0.8691 \n",
      "\n",
      "Epoch: [14/100], Step: [3300/6250], Loss: 1.1641 \n",
      "\n",
      "Epoch: [14/100], Step: [3400/6250], Loss: 1.6720 \n",
      "\n",
      "Epoch: [14/100], Step: [3500/6250], Loss: 1.1226 \n",
      "\n",
      "Epoch: [14/100], Step: [3600/6250], Loss: 1.4903 \n",
      "\n",
      "Epoch: [14/100], Step: [3700/6250], Loss: 1.2340 \n",
      "\n",
      "Epoch: [14/100], Step: [3800/6250], Loss: 1.2259 \n",
      "\n",
      "Epoch: [14/100], Step: [3900/6250], Loss: 1.4009 \n",
      "\n",
      "Epoch: [14/100], Step: [4000/6250], Loss: 1.7141 \n",
      "\n",
      "Epoch: [14/100], Step: [4100/6250], Loss: 0.7228 \n",
      "\n",
      "Epoch: [14/100], Step: [4200/6250], Loss: 1.1495 \n",
      "\n",
      "Epoch: [14/100], Step: [4300/6250], Loss: 1.9135 \n",
      "\n",
      "Epoch: [14/100], Step: [4400/6250], Loss: 1.3101 \n",
      "\n",
      "Epoch: [14/100], Step: [4500/6250], Loss: 1.4995 \n",
      "\n",
      "Epoch: [14/100], Step: [4600/6250], Loss: 0.9523 \n",
      "\n",
      "Epoch: [14/100], Step: [4700/6250], Loss: 1.4202 \n",
      "\n",
      "Epoch: [14/100], Step: [4800/6250], Loss: 1.4473 \n",
      "\n",
      "Epoch: [14/100], Step: [4900/6250], Loss: 1.4721 \n",
      "\n",
      "Epoch: [14/100], Step: [5000/6250], Loss: 1.0699 \n",
      "\n",
      "Epoch: [14/100], Step: [5100/6250], Loss: 1.8566 \n",
      "\n",
      "Epoch: [14/100], Step: [5200/6250], Loss: 1.2939 \n",
      "\n",
      "Epoch: [14/100], Step: [5300/6250], Loss: 1.5544 \n",
      "\n",
      "Epoch: [14/100], Step: [5400/6250], Loss: 1.0419 \n",
      "\n",
      "Epoch: [14/100], Step: [5500/6250], Loss: 1.0459 \n",
      "\n",
      "Epoch: [14/100], Step: [5600/6250], Loss: 1.2736 \n",
      "\n",
      "Epoch: [14/100], Step: [5700/6250], Loss: 1.3951 \n",
      "\n",
      "Epoch: [14/100], Step: [5800/6250], Loss: 0.8684 \n",
      "\n",
      "Epoch: [14/100], Step: [5900/6250], Loss: 0.9899 \n",
      "\n",
      "Epoch: [14/100], Step: [6000/6250], Loss: 1.3671 \n",
      "\n",
      "Epoch: [14/100], Step: [6100/6250], Loss: 0.7656 \n",
      "\n",
      "Epoch: [14/100], Step: [6200/6250], Loss: 1.7992 \n",
      "\n",
      "Epoch: [15/100], Step: [100/6250], Loss: 0.9778 \n",
      "\n",
      "Epoch: [15/100], Step: [200/6250], Loss: 1.2885 \n",
      "\n",
      "Epoch: [15/100], Step: [300/6250], Loss: 1.5975 \n",
      "\n",
      "Epoch: [15/100], Step: [400/6250], Loss: 1.3952 \n",
      "\n",
      "Epoch: [15/100], Step: [500/6250], Loss: 1.0213 \n",
      "\n",
      "Epoch: [15/100], Step: [600/6250], Loss: 0.9309 \n",
      "\n",
      "Epoch: [15/100], Step: [700/6250], Loss: 0.8921 \n",
      "\n",
      "Epoch: [15/100], Step: [800/6250], Loss: 1.7160 \n",
      "\n",
      "Epoch: [15/100], Step: [900/6250], Loss: 1.5543 \n",
      "\n",
      "Epoch: [15/100], Step: [1000/6250], Loss: 1.0850 \n",
      "\n",
      "Epoch: [15/100], Step: [1100/6250], Loss: 0.6852 \n",
      "\n",
      "Epoch: [15/100], Step: [1200/6250], Loss: 1.0683 \n",
      "\n",
      "Epoch: [15/100], Step: [1300/6250], Loss: 1.1288 \n",
      "\n",
      "Epoch: [15/100], Step: [1400/6250], Loss: 1.2799 \n",
      "\n",
      "Epoch: [15/100], Step: [1500/6250], Loss: 0.7441 \n",
      "\n",
      "Epoch: [15/100], Step: [1600/6250], Loss: 1.0755 \n",
      "\n",
      "Epoch: [15/100], Step: [1700/6250], Loss: 0.9159 \n",
      "\n",
      "Epoch: [15/100], Step: [1800/6250], Loss: 1.6521 \n",
      "\n",
      "Epoch: [15/100], Step: [1900/6250], Loss: 1.1087 \n",
      "\n",
      "Epoch: [15/100], Step: [2000/6250], Loss: 0.8303 \n",
      "\n",
      "Epoch: [15/100], Step: [2100/6250], Loss: 1.7964 \n",
      "\n",
      "Epoch: [15/100], Step: [2200/6250], Loss: 1.2185 \n",
      "\n",
      "Epoch: [15/100], Step: [2300/6250], Loss: 1.2221 \n",
      "\n",
      "Epoch: [15/100], Step: [2400/6250], Loss: 0.7437 \n",
      "\n",
      "Epoch: [15/100], Step: [2500/6250], Loss: 1.3195 \n",
      "\n",
      "Epoch: [15/100], Step: [2600/6250], Loss: 1.0912 \n",
      "\n",
      "Epoch: [15/100], Step: [2700/6250], Loss: 1.2488 \n",
      "\n",
      "Epoch: [15/100], Step: [2800/6250], Loss: 1.4652 \n",
      "\n",
      "Epoch: [15/100], Step: [2900/6250], Loss: 1.1589 \n",
      "\n",
      "Epoch: [15/100], Step: [3000/6250], Loss: 1.0982 \n",
      "\n",
      "Epoch: [15/100], Step: [3100/6250], Loss: 1.4322 \n",
      "\n",
      "Epoch: [15/100], Step: [3200/6250], Loss: 1.0089 \n",
      "\n",
      "Epoch: [15/100], Step: [3300/6250], Loss: 1.2716 \n",
      "\n",
      "Epoch: [15/100], Step: [3400/6250], Loss: 0.5757 \n",
      "\n",
      "Epoch: [15/100], Step: [3500/6250], Loss: 0.9125 \n",
      "\n",
      "Epoch: [15/100], Step: [3600/6250], Loss: 1.2568 \n",
      "\n",
      "Epoch: [15/100], Step: [3700/6250], Loss: 1.2483 \n",
      "\n",
      "Epoch: [15/100], Step: [3800/6250], Loss: 1.9643 \n",
      "\n",
      "Epoch: [15/100], Step: [3900/6250], Loss: 0.8168 \n",
      "\n",
      "Epoch: [15/100], Step: [4000/6250], Loss: 1.1593 \n",
      "\n",
      "Epoch: [15/100], Step: [4100/6250], Loss: 1.7099 \n",
      "\n",
      "Epoch: [15/100], Step: [4200/6250], Loss: 1.0316 \n",
      "\n",
      "Epoch: [15/100], Step: [4300/6250], Loss: 1.5728 \n",
      "\n",
      "Epoch: [15/100], Step: [4400/6250], Loss: 1.4208 \n",
      "\n",
      "Epoch: [15/100], Step: [4500/6250], Loss: 0.8965 \n",
      "\n",
      "Epoch: [15/100], Step: [4600/6250], Loss: 1.6172 \n",
      "\n",
      "Epoch: [15/100], Step: [4700/6250], Loss: 1.4689 \n",
      "\n",
      "Epoch: [15/100], Step: [4800/6250], Loss: 1.0222 \n",
      "\n",
      "Epoch: [15/100], Step: [4900/6250], Loss: 1.3394 \n",
      "\n",
      "Epoch: [15/100], Step: [5000/6250], Loss: 1.3301 \n",
      "\n",
      "Epoch: [15/100], Step: [5100/6250], Loss: 1.1556 \n",
      "\n",
      "Epoch: [15/100], Step: [5200/6250], Loss: 0.8566 \n",
      "\n",
      "Epoch: [15/100], Step: [5300/6250], Loss: 1.3129 \n",
      "\n",
      "Epoch: [15/100], Step: [5400/6250], Loss: 0.7335 \n",
      "\n",
      "Epoch: [15/100], Step: [5500/6250], Loss: 1.3753 \n",
      "\n",
      "Epoch: [15/100], Step: [5600/6250], Loss: 0.5323 \n",
      "\n",
      "Epoch: [15/100], Step: [5700/6250], Loss: 1.2893 \n",
      "\n",
      "Epoch: [15/100], Step: [5800/6250], Loss: 1.2712 \n",
      "\n",
      "Epoch: [15/100], Step: [5900/6250], Loss: 0.9908 \n",
      "\n",
      "Epoch: [15/100], Step: [6000/6250], Loss: 1.6447 \n",
      "\n",
      "Epoch: [15/100], Step: [6100/6250], Loss: 0.7675 \n",
      "\n",
      "Epoch: [15/100], Step: [6200/6250], Loss: 1.3702 \n",
      "\n",
      "Epoch: [16/100], Step: [100/6250], Loss: 1.0854 \n",
      "\n",
      "Epoch: [16/100], Step: [200/6250], Loss: 1.1072 \n",
      "\n",
      "Epoch: [16/100], Step: [300/6250], Loss: 1.2360 \n",
      "\n",
      "Epoch: [16/100], Step: [400/6250], Loss: 1.4029 \n",
      "\n",
      "Epoch: [16/100], Step: [500/6250], Loss: 1.1464 \n",
      "\n",
      "Epoch: [16/100], Step: [600/6250], Loss: 1.3625 \n",
      "\n",
      "Epoch: [16/100], Step: [700/6250], Loss: 0.8623 \n",
      "\n",
      "Epoch: [16/100], Step: [800/6250], Loss: 1.1252 \n",
      "\n",
      "Epoch: [16/100], Step: [900/6250], Loss: 1.1947 \n",
      "\n",
      "Epoch: [16/100], Step: [1000/6250], Loss: 1.3209 \n",
      "\n",
      "Epoch: [16/100], Step: [1100/6250], Loss: 1.2519 \n",
      "\n",
      "Epoch: [16/100], Step: [1200/6250], Loss: 0.8084 \n",
      "\n",
      "Epoch: [16/100], Step: [1300/6250], Loss: 1.0069 \n",
      "\n",
      "Epoch: [16/100], Step: [1400/6250], Loss: 1.7597 \n",
      "\n",
      "Epoch: [16/100], Step: [1500/6250], Loss: 1.4779 \n",
      "\n",
      "Epoch: [16/100], Step: [1600/6250], Loss: 1.2011 \n",
      "\n",
      "Epoch: [16/100], Step: [1700/6250], Loss: 1.3849 \n",
      "\n",
      "Epoch: [16/100], Step: [1800/6250], Loss: 1.6658 \n",
      "\n",
      "Epoch: [16/100], Step: [1900/6250], Loss: 1.4137 \n",
      "\n",
      "Epoch: [16/100], Step: [2000/6250], Loss: 1.5374 \n",
      "\n",
      "Epoch: [16/100], Step: [2100/6250], Loss: 0.9044 \n",
      "\n",
      "Epoch: [16/100], Step: [2200/6250], Loss: 1.6081 \n",
      "\n",
      "Epoch: [16/100], Step: [2300/6250], Loss: 1.1936 \n",
      "\n",
      "Epoch: [16/100], Step: [2400/6250], Loss: 1.3575 \n",
      "\n",
      "Epoch: [16/100], Step: [2500/6250], Loss: 0.9333 \n",
      "\n",
      "Epoch: [16/100], Step: [2600/6250], Loss: 1.5195 \n",
      "\n",
      "Epoch: [16/100], Step: [2700/6250], Loss: 2.0313 \n",
      "\n",
      "Epoch: [16/100], Step: [2800/6250], Loss: 0.9722 \n",
      "\n",
      "Epoch: [16/100], Step: [2900/6250], Loss: 1.0174 \n",
      "\n",
      "Epoch: [16/100], Step: [3000/6250], Loss: 0.9191 \n",
      "\n",
      "Epoch: [16/100], Step: [3100/6250], Loss: 0.9628 \n",
      "\n",
      "Epoch: [16/100], Step: [3200/6250], Loss: 1.3251 \n",
      "\n",
      "Epoch: [16/100], Step: [3300/6250], Loss: 0.9747 \n",
      "\n",
      "Epoch: [16/100], Step: [3400/6250], Loss: 1.8134 \n",
      "\n",
      "Epoch: [16/100], Step: [3500/6250], Loss: 1.3752 \n",
      "\n",
      "Epoch: [16/100], Step: [3600/6250], Loss: 1.5793 \n",
      "\n",
      "Epoch: [16/100], Step: [3700/6250], Loss: 1.1799 \n",
      "\n",
      "Epoch: [16/100], Step: [3800/6250], Loss: 0.4809 \n",
      "\n",
      "Epoch: [16/100], Step: [3900/6250], Loss: 0.8034 \n",
      "\n",
      "Epoch: [16/100], Step: [4000/6250], Loss: 1.3429 \n",
      "\n",
      "Epoch: [16/100], Step: [4100/6250], Loss: 0.9124 \n",
      "\n",
      "Epoch: [16/100], Step: [4200/6250], Loss: 0.8830 \n",
      "\n",
      "Epoch: [16/100], Step: [4300/6250], Loss: 1.9508 \n",
      "\n",
      "Epoch: [16/100], Step: [4400/6250], Loss: 1.2788 \n",
      "\n",
      "Epoch: [16/100], Step: [4500/6250], Loss: 0.5845 \n",
      "\n",
      "Epoch: [16/100], Step: [4600/6250], Loss: 2.0106 \n",
      "\n",
      "Epoch: [16/100], Step: [4700/6250], Loss: 1.3942 \n",
      "\n",
      "Epoch: [16/100], Step: [4800/6250], Loss: 1.2209 \n",
      "\n",
      "Epoch: [16/100], Step: [4900/6250], Loss: 1.1309 \n",
      "\n",
      "Epoch: [16/100], Step: [5000/6250], Loss: 0.9717 \n",
      "\n",
      "Epoch: [16/100], Step: [5100/6250], Loss: 1.5021 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [16/100], Step: [5200/6250], Loss: 1.3064 \n",
      "\n",
      "Epoch: [16/100], Step: [5300/6250], Loss: 1.5285 \n",
      "\n",
      "Epoch: [16/100], Step: [5400/6250], Loss: 0.5265 \n",
      "\n",
      "Epoch: [16/100], Step: [5500/6250], Loss: 1.3044 \n",
      "\n",
      "Epoch: [16/100], Step: [5600/6250], Loss: 1.0091 \n",
      "\n",
      "Epoch: [16/100], Step: [5700/6250], Loss: 0.8480 \n",
      "\n",
      "Epoch: [16/100], Step: [5800/6250], Loss: 1.2277 \n",
      "\n",
      "Epoch: [16/100], Step: [5900/6250], Loss: 1.4785 \n",
      "\n",
      "Epoch: [16/100], Step: [6000/6250], Loss: 0.9549 \n",
      "\n",
      "Epoch: [16/100], Step: [6100/6250], Loss: 0.8078 \n",
      "\n",
      "Epoch: [16/100], Step: [6200/6250], Loss: 1.0142 \n",
      "\n",
      "Epoch: [17/100], Step: [100/6250], Loss: 1.0545 \n",
      "\n",
      "Epoch: [17/100], Step: [200/6250], Loss: 0.8831 \n",
      "\n",
      "Epoch: [17/100], Step: [300/6250], Loss: 1.0669 \n",
      "\n",
      "Epoch: [17/100], Step: [400/6250], Loss: 0.9530 \n",
      "\n",
      "Epoch: [17/100], Step: [500/6250], Loss: 1.5193 \n",
      "\n",
      "Epoch: [17/100], Step: [600/6250], Loss: 1.1689 \n",
      "\n",
      "Epoch: [17/100], Step: [700/6250], Loss: 0.9572 \n",
      "\n",
      "Epoch: [17/100], Step: [800/6250], Loss: 1.3815 \n",
      "\n",
      "Epoch: [17/100], Step: [900/6250], Loss: 1.2940 \n",
      "\n",
      "Epoch: [17/100], Step: [1000/6250], Loss: 0.9697 \n",
      "\n",
      "Epoch: [17/100], Step: [1100/6250], Loss: 0.5572 \n",
      "\n",
      "Epoch: [17/100], Step: [1200/6250], Loss: 0.8402 \n",
      "\n",
      "Epoch: [17/100], Step: [1300/6250], Loss: 0.5409 \n",
      "\n",
      "Epoch: [17/100], Step: [1400/6250], Loss: 1.5820 \n",
      "\n",
      "Epoch: [17/100], Step: [1500/6250], Loss: 1.1063 \n",
      "\n",
      "Epoch: [17/100], Step: [1600/6250], Loss: 1.4940 \n",
      "\n",
      "Epoch: [17/100], Step: [1700/6250], Loss: 1.2754 \n",
      "\n",
      "Epoch: [17/100], Step: [1800/6250], Loss: 1.1684 \n",
      "\n",
      "Epoch: [17/100], Step: [1900/6250], Loss: 1.1896 \n",
      "\n",
      "Epoch: [17/100], Step: [2000/6250], Loss: 1.1021 \n",
      "\n",
      "Epoch: [17/100], Step: [2100/6250], Loss: 1.2304 \n",
      "\n",
      "Epoch: [17/100], Step: [2200/6250], Loss: 0.9757 \n",
      "\n",
      "Epoch: [17/100], Step: [2300/6250], Loss: 0.6640 \n",
      "\n",
      "Epoch: [17/100], Step: [2400/6250], Loss: 1.0782 \n",
      "\n",
      "Epoch: [17/100], Step: [2500/6250], Loss: 1.3416 \n",
      "\n",
      "Epoch: [17/100], Step: [2600/6250], Loss: 1.7550 \n",
      "\n",
      "Epoch: [17/100], Step: [2700/6250], Loss: 1.3016 \n",
      "\n",
      "Epoch: [17/100], Step: [2800/6250], Loss: 1.1450 \n",
      "\n",
      "Epoch: [17/100], Step: [2900/6250], Loss: 1.1326 \n",
      "\n",
      "Epoch: [17/100], Step: [3000/6250], Loss: 1.6033 \n",
      "\n",
      "Epoch: [17/100], Step: [3100/6250], Loss: 0.7586 \n",
      "\n",
      "Epoch: [17/100], Step: [3200/6250], Loss: 0.8112 \n",
      "\n",
      "Epoch: [17/100], Step: [3300/6250], Loss: 1.5810 \n",
      "\n",
      "Epoch: [17/100], Step: [3400/6250], Loss: 0.9743 \n",
      "\n",
      "Epoch: [17/100], Step: [3500/6250], Loss: 1.0464 \n",
      "\n",
      "Epoch: [17/100], Step: [3600/6250], Loss: 0.9568 \n",
      "\n",
      "Epoch: [17/100], Step: [3700/6250], Loss: 1.8959 \n",
      "\n",
      "Epoch: [17/100], Step: [3800/6250], Loss: 2.2619 \n",
      "\n",
      "Epoch: [17/100], Step: [3900/6250], Loss: 1.3410 \n",
      "\n",
      "Epoch: [17/100], Step: [4000/6250], Loss: 1.1044 \n",
      "\n",
      "Epoch: [17/100], Step: [4100/6250], Loss: 1.2162 \n",
      "\n",
      "Epoch: [17/100], Step: [4200/6250], Loss: 0.9319 \n",
      "\n",
      "Epoch: [17/100], Step: [4300/6250], Loss: 1.0551 \n",
      "\n",
      "Epoch: [17/100], Step: [4400/6250], Loss: 1.1500 \n",
      "\n",
      "Epoch: [17/100], Step: [4500/6250], Loss: 2.3010 \n",
      "\n",
      "Epoch: [17/100], Step: [4600/6250], Loss: 0.5854 \n",
      "\n",
      "Epoch: [17/100], Step: [4700/6250], Loss: 0.9159 \n",
      "\n",
      "Epoch: [17/100], Step: [4800/6250], Loss: 1.1524 \n",
      "\n",
      "Epoch: [17/100], Step: [4900/6250], Loss: 1.2200 \n",
      "\n",
      "Epoch: [17/100], Step: [5000/6250], Loss: 1.0972 \n",
      "\n",
      "Epoch: [17/100], Step: [5100/6250], Loss: 0.4635 \n",
      "\n",
      "Epoch: [17/100], Step: [5200/6250], Loss: 0.8998 \n",
      "\n",
      "Epoch: [17/100], Step: [5300/6250], Loss: 0.9896 \n",
      "\n",
      "Epoch: [17/100], Step: [5400/6250], Loss: 0.5817 \n",
      "\n",
      "Epoch: [17/100], Step: [5500/6250], Loss: 1.8876 \n",
      "\n",
      "Epoch: [17/100], Step: [5600/6250], Loss: 1.5239 \n",
      "\n",
      "Epoch: [17/100], Step: [5700/6250], Loss: 0.8690 \n",
      "\n",
      "Epoch: [17/100], Step: [5800/6250], Loss: 1.7495 \n",
      "\n",
      "Epoch: [17/100], Step: [5900/6250], Loss: 0.8566 \n",
      "\n",
      "Epoch: [17/100], Step: [6000/6250], Loss: 1.3342 \n",
      "\n",
      "Epoch: [17/100], Step: [6100/6250], Loss: 0.8710 \n",
      "\n",
      "Epoch: [17/100], Step: [6200/6250], Loss: 0.8089 \n",
      "\n",
      "Epoch: [18/100], Step: [100/6250], Loss: 1.1651 \n",
      "\n",
      "Epoch: [18/100], Step: [200/6250], Loss: 0.7802 \n",
      "\n",
      "Epoch: [18/100], Step: [300/6250], Loss: 1.8094 \n",
      "\n",
      "Epoch: [18/100], Step: [400/6250], Loss: 1.2028 \n",
      "\n",
      "Epoch: [18/100], Step: [500/6250], Loss: 0.6339 \n",
      "\n",
      "Epoch: [18/100], Step: [600/6250], Loss: 1.0711 \n",
      "\n",
      "Epoch: [18/100], Step: [700/6250], Loss: 0.5983 \n",
      "\n",
      "Epoch: [18/100], Step: [800/6250], Loss: 0.9307 \n",
      "\n",
      "Epoch: [18/100], Step: [900/6250], Loss: 1.2762 \n",
      "\n",
      "Epoch: [18/100], Step: [1000/6250], Loss: 1.2108 \n",
      "\n",
      "Epoch: [18/100], Step: [1100/6250], Loss: 0.7373 \n",
      "\n",
      "Epoch: [18/100], Step: [1200/6250], Loss: 1.0572 \n",
      "\n",
      "Epoch: [18/100], Step: [1300/6250], Loss: 1.0128 \n",
      "\n",
      "Epoch: [18/100], Step: [1400/6250], Loss: 1.7618 \n",
      "\n",
      "Epoch: [18/100], Step: [1500/6250], Loss: 1.2150 \n",
      "\n",
      "Epoch: [18/100], Step: [1600/6250], Loss: 0.7314 \n",
      "\n",
      "Epoch: [18/100], Step: [1700/6250], Loss: 1.1333 \n",
      "\n",
      "Epoch: [18/100], Step: [1800/6250], Loss: 1.0031 \n",
      "\n",
      "Epoch: [18/100], Step: [1900/6250], Loss: 1.2433 \n",
      "\n",
      "Epoch: [18/100], Step: [2000/6250], Loss: 1.0813 \n",
      "\n",
      "Epoch: [18/100], Step: [2100/6250], Loss: 1.2528 \n",
      "\n",
      "Epoch: [18/100], Step: [2200/6250], Loss: 1.0044 \n",
      "\n",
      "Epoch: [18/100], Step: [2300/6250], Loss: 1.1101 \n",
      "\n",
      "Epoch: [18/100], Step: [2400/6250], Loss: 1.5701 \n",
      "\n",
      "Epoch: [18/100], Step: [2500/6250], Loss: 1.2585 \n",
      "\n",
      "Epoch: [18/100], Step: [2600/6250], Loss: 1.6302 \n",
      "\n",
      "Epoch: [18/100], Step: [2700/6250], Loss: 1.1136 \n",
      "\n",
      "Epoch: [18/100], Step: [2800/6250], Loss: 0.8733 \n",
      "\n",
      "Epoch: [18/100], Step: [2900/6250], Loss: 0.7659 \n",
      "\n",
      "Epoch: [18/100], Step: [3000/6250], Loss: 0.9644 \n",
      "\n",
      "Epoch: [18/100], Step: [3100/6250], Loss: 1.0556 \n",
      "\n",
      "Epoch: [18/100], Step: [3200/6250], Loss: 1.7002 \n",
      "\n",
      "Epoch: [18/100], Step: [3300/6250], Loss: 1.4982 \n",
      "\n",
      "Epoch: [18/100], Step: [3400/6250], Loss: 1.5765 \n",
      "\n",
      "Epoch: [18/100], Step: [3500/6250], Loss: 1.0441 \n",
      "\n",
      "Epoch: [18/100], Step: [3600/6250], Loss: 1.2379 \n",
      "\n",
      "Epoch: [18/100], Step: [3700/6250], Loss: 0.6532 \n",
      "\n",
      "Epoch: [18/100], Step: [3800/6250], Loss: 0.7602 \n",
      "\n",
      "Epoch: [18/100], Step: [3900/6250], Loss: 1.4892 \n",
      "\n",
      "Epoch: [18/100], Step: [4000/6250], Loss: 2.4072 \n",
      "\n",
      "Epoch: [18/100], Step: [4100/6250], Loss: 0.8885 \n",
      "\n",
      "Epoch: [18/100], Step: [4200/6250], Loss: 1.2726 \n",
      "\n",
      "Epoch: [18/100], Step: [4300/6250], Loss: 0.6806 \n",
      "\n",
      "Epoch: [18/100], Step: [4400/6250], Loss: 0.6868 \n",
      "\n",
      "Epoch: [18/100], Step: [4500/6250], Loss: 0.5058 \n",
      "\n",
      "Epoch: [18/100], Step: [4600/6250], Loss: 1.0179 \n",
      "\n",
      "Epoch: [18/100], Step: [4700/6250], Loss: 1.4094 \n",
      "\n",
      "Epoch: [18/100], Step: [4800/6250], Loss: 1.1049 \n",
      "\n",
      "Epoch: [18/100], Step: [4900/6250], Loss: 1.0022 \n",
      "\n",
      "Epoch: [18/100], Step: [5000/6250], Loss: 1.4412 \n",
      "\n",
      "Epoch: [18/100], Step: [5100/6250], Loss: 1.7177 \n",
      "\n",
      "Epoch: [18/100], Step: [5200/6250], Loss: 0.9890 \n",
      "\n",
      "Epoch: [18/100], Step: [5300/6250], Loss: 1.6907 \n",
      "\n",
      "Epoch: [18/100], Step: [5400/6250], Loss: 0.7663 \n",
      "\n",
      "Epoch: [18/100], Step: [5500/6250], Loss: 1.1225 \n",
      "\n",
      "Epoch: [18/100], Step: [5600/6250], Loss: 1.1871 \n",
      "\n",
      "Epoch: [18/100], Step: [5700/6250], Loss: 1.3231 \n",
      "\n",
      "Epoch: [18/100], Step: [5800/6250], Loss: 1.3224 \n",
      "\n",
      "Epoch: [18/100], Step: [5900/6250], Loss: 0.8423 \n",
      "\n",
      "Epoch: [18/100], Step: [6000/6250], Loss: 1.5811 \n",
      "\n",
      "Epoch: [18/100], Step: [6100/6250], Loss: 1.3376 \n",
      "\n",
      "Epoch: [18/100], Step: [6200/6250], Loss: 1.8659 \n",
      "\n",
      "Epoch: [19/100], Step: [100/6250], Loss: 1.0993 \n",
      "\n",
      "Epoch: [19/100], Step: [200/6250], Loss: 0.9133 \n",
      "\n",
      "Epoch: [19/100], Step: [300/6250], Loss: 1.3760 \n",
      "\n",
      "Epoch: [19/100], Step: [400/6250], Loss: 0.7712 \n",
      "\n",
      "Epoch: [19/100], Step: [500/6250], Loss: 1.3287 \n",
      "\n",
      "Epoch: [19/100], Step: [600/6250], Loss: 0.6766 \n",
      "\n",
      "Epoch: [19/100], Step: [700/6250], Loss: 0.9424 \n",
      "\n",
      "Epoch: [19/100], Step: [800/6250], Loss: 0.9983 \n",
      "\n",
      "Epoch: [19/100], Step: [900/6250], Loss: 0.8396 \n",
      "\n",
      "Epoch: [19/100], Step: [1000/6250], Loss: 1.2132 \n",
      "\n",
      "Epoch: [19/100], Step: [1100/6250], Loss: 1.2290 \n",
      "\n",
      "Epoch: [19/100], Step: [1200/6250], Loss: 1.1087 \n",
      "\n",
      "Epoch: [19/100], Step: [1300/6250], Loss: 0.8640 \n",
      "\n",
      "Epoch: [19/100], Step: [1400/6250], Loss: 1.3570 \n",
      "\n",
      "Epoch: [19/100], Step: [1500/6250], Loss: 1.8384 \n",
      "\n",
      "Epoch: [19/100], Step: [1600/6250], Loss: 0.8052 \n",
      "\n",
      "Epoch: [19/100], Step: [1700/6250], Loss: 1.0181 \n",
      "\n",
      "Epoch: [19/100], Step: [1800/6250], Loss: 1.4814 \n",
      "\n",
      "Epoch: [19/100], Step: [1900/6250], Loss: 1.2026 \n",
      "\n",
      "Epoch: [19/100], Step: [2000/6250], Loss: 1.4999 \n",
      "\n",
      "Epoch: [19/100], Step: [2100/6250], Loss: 1.0554 \n",
      "\n",
      "Epoch: [19/100], Step: [2200/6250], Loss: 1.2715 \n",
      "\n",
      "Epoch: [19/100], Step: [2300/6250], Loss: 0.9895 \n",
      "\n",
      "Epoch: [19/100], Step: [2400/6250], Loss: 1.0621 \n",
      "\n",
      "Epoch: [19/100], Step: [2500/6250], Loss: 0.7707 \n",
      "\n",
      "Epoch: [19/100], Step: [2600/6250], Loss: 1.3117 \n",
      "\n",
      "Epoch: [19/100], Step: [2700/6250], Loss: 0.6240 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [19/100], Step: [2800/6250], Loss: 0.6566 \n",
      "\n",
      "Epoch: [19/100], Step: [2900/6250], Loss: 0.8460 \n",
      "\n",
      "Epoch: [19/100], Step: [3000/6250], Loss: 1.1358 \n",
      "\n",
      "Epoch: [19/100], Step: [3100/6250], Loss: 0.4440 \n",
      "\n",
      "Epoch: [19/100], Step: [3200/6250], Loss: 0.9281 \n",
      "\n",
      "Epoch: [19/100], Step: [3300/6250], Loss: 1.4142 \n",
      "\n",
      "Epoch: [19/100], Step: [3400/6250], Loss: 0.8397 \n",
      "\n",
      "Epoch: [19/100], Step: [3500/6250], Loss: 0.8119 \n",
      "\n",
      "Epoch: [19/100], Step: [3600/6250], Loss: 1.1241 \n",
      "\n",
      "Epoch: [19/100], Step: [3700/6250], Loss: 1.7536 \n",
      "\n",
      "Epoch: [19/100], Step: [3800/6250], Loss: 0.9006 \n",
      "\n",
      "Epoch: [19/100], Step: [3900/6250], Loss: 1.5375 \n",
      "\n",
      "Epoch: [19/100], Step: [4000/6250], Loss: 1.5488 \n",
      "\n",
      "Epoch: [19/100], Step: [4100/6250], Loss: 1.2222 \n",
      "\n",
      "Epoch: [19/100], Step: [4200/6250], Loss: 0.7478 \n",
      "\n",
      "Epoch: [19/100], Step: [4300/6250], Loss: 1.0371 \n",
      "\n",
      "Epoch: [19/100], Step: [4400/6250], Loss: 1.2700 \n",
      "\n",
      "Epoch: [19/100], Step: [4500/6250], Loss: 1.7280 \n",
      "\n",
      "Epoch: [19/100], Step: [4600/6250], Loss: 1.0142 \n",
      "\n",
      "Epoch: [19/100], Step: [4700/6250], Loss: 1.3566 \n",
      "\n",
      "Epoch: [19/100], Step: [4800/6250], Loss: 0.9629 \n",
      "\n",
      "Epoch: [19/100], Step: [4900/6250], Loss: 0.5533 \n",
      "\n",
      "Epoch: [19/100], Step: [5000/6250], Loss: 1.4634 \n",
      "\n",
      "Epoch: [19/100], Step: [5100/6250], Loss: 1.3633 \n",
      "\n",
      "Epoch: [19/100], Step: [5200/6250], Loss: 0.6584 \n",
      "\n",
      "Epoch: [19/100], Step: [5300/6250], Loss: 0.9042 \n",
      "\n",
      "Epoch: [19/100], Step: [5400/6250], Loss: 1.0102 \n",
      "\n",
      "Epoch: [19/100], Step: [5500/6250], Loss: 1.8239 \n",
      "\n",
      "Epoch: [19/100], Step: [5600/6250], Loss: 1.9526 \n",
      "\n",
      "Epoch: [19/100], Step: [5700/6250], Loss: 0.6787 \n",
      "\n",
      "Epoch: [19/100], Step: [5800/6250], Loss: 0.8091 \n",
      "\n",
      "Epoch: [19/100], Step: [5900/6250], Loss: 0.8173 \n",
      "\n",
      "Epoch: [19/100], Step: [6000/6250], Loss: 0.9842 \n",
      "\n",
      "Epoch: [19/100], Step: [6100/6250], Loss: 0.7825 \n",
      "\n",
      "Epoch: [19/100], Step: [6200/6250], Loss: 1.1498 \n",
      "\n",
      "Epoch: [20/100], Step: [100/6250], Loss: 0.9622 \n",
      "\n",
      "Epoch: [20/100], Step: [200/6250], Loss: 1.6904 \n",
      "\n",
      "Epoch: [20/100], Step: [300/6250], Loss: 2.3756 \n",
      "\n",
      "Epoch: [20/100], Step: [400/6250], Loss: 1.8208 \n",
      "\n",
      "Epoch: [20/100], Step: [500/6250], Loss: 1.7493 \n",
      "\n",
      "Epoch: [20/100], Step: [600/6250], Loss: 0.6779 \n",
      "\n",
      "Epoch: [20/100], Step: [700/6250], Loss: 0.5047 \n",
      "\n",
      "Epoch: [20/100], Step: [800/6250], Loss: 1.4335 \n",
      "\n",
      "Epoch: [20/100], Step: [900/6250], Loss: 1.0793 \n",
      "\n",
      "Epoch: [20/100], Step: [1000/6250], Loss: 1.0731 \n",
      "\n",
      "Epoch: [20/100], Step: [1100/6250], Loss: 1.5106 \n",
      "\n",
      "Epoch: [20/100], Step: [1200/6250], Loss: 1.2895 \n",
      "\n",
      "Epoch: [20/100], Step: [1300/6250], Loss: 1.0673 \n",
      "\n",
      "Epoch: [20/100], Step: [1400/6250], Loss: 1.0275 \n",
      "\n",
      "Epoch: [20/100], Step: [1500/6250], Loss: 1.3693 \n",
      "\n",
      "Epoch: [20/100], Step: [1600/6250], Loss: 1.2502 \n",
      "\n",
      "Epoch: [20/100], Step: [1700/6250], Loss: 0.8522 \n",
      "\n",
      "Epoch: [20/100], Step: [1800/6250], Loss: 0.9223 \n",
      "\n",
      "Epoch: [20/100], Step: [1900/6250], Loss: 1.2132 \n",
      "\n",
      "Epoch: [20/100], Step: [2000/6250], Loss: 2.1464 \n",
      "\n",
      "Epoch: [20/100], Step: [2100/6250], Loss: 0.6954 \n",
      "\n",
      "Epoch: [20/100], Step: [2200/6250], Loss: 0.8089 \n",
      "\n",
      "Epoch: [20/100], Step: [2300/6250], Loss: 1.1657 \n",
      "\n",
      "Epoch: [20/100], Step: [2400/6250], Loss: 0.9349 \n",
      "\n",
      "Epoch: [20/100], Step: [2500/6250], Loss: 1.1639 \n",
      "\n",
      "Epoch: [20/100], Step: [2600/6250], Loss: 0.6364 \n",
      "\n",
      "Epoch: [20/100], Step: [2700/6250], Loss: 1.2221 \n",
      "\n",
      "Epoch: [20/100], Step: [2800/6250], Loss: 0.8092 \n",
      "\n",
      "Epoch: [20/100], Step: [2900/6250], Loss: 1.3151 \n",
      "\n",
      "Epoch: [20/100], Step: [3000/6250], Loss: 1.2695 \n",
      "\n",
      "Epoch: [20/100], Step: [3100/6250], Loss: 1.7255 \n",
      "\n",
      "Epoch: [20/100], Step: [3200/6250], Loss: 1.3404 \n",
      "\n",
      "Epoch: [20/100], Step: [3300/6250], Loss: 0.8036 \n",
      "\n",
      "Epoch: [20/100], Step: [3400/6250], Loss: 1.5383 \n",
      "\n",
      "Epoch: [20/100], Step: [3500/6250], Loss: 1.3293 \n",
      "\n",
      "Epoch: [20/100], Step: [3600/6250], Loss: 0.9283 \n",
      "\n",
      "Epoch: [20/100], Step: [3700/6250], Loss: 1.1585 \n",
      "\n",
      "Epoch: [20/100], Step: [3800/6250], Loss: 1.2601 \n",
      "\n",
      "Epoch: [20/100], Step: [3900/6250], Loss: 1.1778 \n",
      "\n",
      "Epoch: [20/100], Step: [4000/6250], Loss: 0.6305 \n",
      "\n",
      "Epoch: [20/100], Step: [4100/6250], Loss: 0.7808 \n",
      "\n",
      "Epoch: [20/100], Step: [4200/6250], Loss: 0.8812 \n",
      "\n",
      "Epoch: [20/100], Step: [4300/6250], Loss: 0.9168 \n",
      "\n",
      "Epoch: [20/100], Step: [4400/6250], Loss: 1.1975 \n",
      "\n",
      "Epoch: [20/100], Step: [4500/6250], Loss: 1.1140 \n",
      "\n",
      "Epoch: [20/100], Step: [4600/6250], Loss: 1.0211 \n",
      "\n",
      "Epoch: [20/100], Step: [4700/6250], Loss: 1.0090 \n",
      "\n",
      "Epoch: [20/100], Step: [4800/6250], Loss: 1.1533 \n",
      "\n",
      "Epoch: [20/100], Step: [4900/6250], Loss: 1.5342 \n",
      "\n",
      "Epoch: [20/100], Step: [5000/6250], Loss: 1.0533 \n",
      "\n",
      "Epoch: [20/100], Step: [5100/6250], Loss: 0.7562 \n",
      "\n",
      "Epoch: [20/100], Step: [5200/6250], Loss: 0.7597 \n",
      "\n",
      "Epoch: [20/100], Step: [5300/6250], Loss: 1.7573 \n",
      "\n",
      "Epoch: [20/100], Step: [5400/6250], Loss: 0.7695 \n",
      "\n",
      "Epoch: [20/100], Step: [5500/6250], Loss: 0.7079 \n",
      "\n",
      "Epoch: [20/100], Step: [5600/6250], Loss: 1.3158 \n",
      "\n",
      "Epoch: [20/100], Step: [5700/6250], Loss: 0.8084 \n",
      "\n",
      "Epoch: [20/100], Step: [5800/6250], Loss: 1.1979 \n",
      "\n",
      "Epoch: [20/100], Step: [5900/6250], Loss: 1.3341 \n",
      "\n",
      "Epoch: [20/100], Step: [6000/6250], Loss: 0.7398 \n",
      "\n",
      "Epoch: [20/100], Step: [6100/6250], Loss: 1.0585 \n",
      "\n",
      "Epoch: [20/100], Step: [6200/6250], Loss: 0.8744 \n",
      "\n",
      "Epoch: [21/100], Step: [100/6250], Loss: 1.4110 \n",
      "\n",
      "Epoch: [21/100], Step: [200/6250], Loss: 0.8597 \n",
      "\n",
      "Epoch: [21/100], Step: [300/6250], Loss: 1.7122 \n",
      "\n",
      "Epoch: [21/100], Step: [400/6250], Loss: 0.9819 \n",
      "\n",
      "Epoch: [21/100], Step: [500/6250], Loss: 0.8303 \n",
      "\n",
      "Epoch: [21/100], Step: [600/6250], Loss: 1.3250 \n",
      "\n",
      "Epoch: [21/100], Step: [700/6250], Loss: 0.8099 \n",
      "\n",
      "Epoch: [21/100], Step: [800/6250], Loss: 0.8588 \n",
      "\n",
      "Epoch: [21/100], Step: [900/6250], Loss: 1.3943 \n",
      "\n",
      "Epoch: [21/100], Step: [1000/6250], Loss: 1.5779 \n",
      "\n",
      "Epoch: [21/100], Step: [1100/6250], Loss: 1.0639 \n",
      "\n",
      "Epoch: [21/100], Step: [1200/6250], Loss: 1.2986 \n",
      "\n",
      "Epoch: [21/100], Step: [1300/6250], Loss: 0.7102 \n",
      "\n",
      "Epoch: [21/100], Step: [1400/6250], Loss: 0.9635 \n",
      "\n",
      "Epoch: [21/100], Step: [1500/6250], Loss: 0.7953 \n",
      "\n",
      "Epoch: [21/100], Step: [1600/6250], Loss: 1.2809 \n",
      "\n",
      "Epoch: [21/100], Step: [1700/6250], Loss: 0.9503 \n",
      "\n",
      "Epoch: [21/100], Step: [1800/6250], Loss: 0.8230 \n",
      "\n",
      "Epoch: [21/100], Step: [1900/6250], Loss: 0.8548 \n",
      "\n",
      "Epoch: [21/100], Step: [2000/6250], Loss: 0.6107 \n",
      "\n",
      "Epoch: [21/100], Step: [2100/6250], Loss: 0.6832 \n",
      "\n",
      "Epoch: [21/100], Step: [2200/6250], Loss: 0.7706 \n",
      "\n",
      "Epoch: [21/100], Step: [2300/6250], Loss: 1.5925 \n",
      "\n",
      "Epoch: [21/100], Step: [2400/6250], Loss: 0.5055 \n",
      "\n",
      "Epoch: [21/100], Step: [2500/6250], Loss: 0.8354 \n",
      "\n",
      "Epoch: [21/100], Step: [2600/6250], Loss: 0.8840 \n",
      "\n",
      "Epoch: [21/100], Step: [2700/6250], Loss: 1.6623 \n",
      "\n",
      "Epoch: [21/100], Step: [2800/6250], Loss: 1.1922 \n",
      "\n",
      "Epoch: [21/100], Step: [2900/6250], Loss: 1.2750 \n",
      "\n",
      "Epoch: [21/100], Step: [3000/6250], Loss: 1.2553 \n",
      "\n",
      "Epoch: [21/100], Step: [3100/6250], Loss: 0.6486 \n",
      "\n",
      "Epoch: [21/100], Step: [3200/6250], Loss: 0.6931 \n",
      "\n",
      "Epoch: [21/100], Step: [3300/6250], Loss: 0.5987 \n",
      "\n",
      "Epoch: [21/100], Step: [3400/6250], Loss: 1.4038 \n",
      "\n",
      "Epoch: [21/100], Step: [3500/6250], Loss: 0.4008 \n",
      "\n",
      "Epoch: [21/100], Step: [3600/6250], Loss: 1.2004 \n",
      "\n",
      "Epoch: [21/100], Step: [3700/6250], Loss: 1.1209 \n",
      "\n",
      "Epoch: [21/100], Step: [3800/6250], Loss: 0.7395 \n",
      "\n",
      "Epoch: [21/100], Step: [3900/6250], Loss: 0.6951 \n",
      "\n",
      "Epoch: [21/100], Step: [4000/6250], Loss: 0.8525 \n",
      "\n",
      "Epoch: [21/100], Step: [4100/6250], Loss: 1.2587 \n",
      "\n",
      "Epoch: [21/100], Step: [4200/6250], Loss: 0.9040 \n",
      "\n",
      "Epoch: [21/100], Step: [4300/6250], Loss: 1.0964 \n",
      "\n",
      "Epoch: [21/100], Step: [4400/6250], Loss: 1.1722 \n",
      "\n",
      "Epoch: [21/100], Step: [4500/6250], Loss: 1.0004 \n",
      "\n",
      "Epoch: [21/100], Step: [4600/6250], Loss: 1.2966 \n",
      "\n",
      "Epoch: [21/100], Step: [4700/6250], Loss: 1.2502 \n",
      "\n",
      "Epoch: [21/100], Step: [4800/6250], Loss: 1.5610 \n",
      "\n",
      "Epoch: [21/100], Step: [4900/6250], Loss: 0.9697 \n",
      "\n",
      "Epoch: [21/100], Step: [5000/6250], Loss: 0.4192 \n",
      "\n",
      "Epoch: [21/100], Step: [5100/6250], Loss: 1.0764 \n",
      "\n",
      "Epoch: [21/100], Step: [5200/6250], Loss: 1.2407 \n",
      "\n",
      "Epoch: [21/100], Step: [5300/6250], Loss: 0.8540 \n",
      "\n",
      "Epoch: [21/100], Step: [5400/6250], Loss: 0.7589 \n",
      "\n",
      "Epoch: [21/100], Step: [5500/6250], Loss: 1.0958 \n",
      "\n",
      "Epoch: [21/100], Step: [5600/6250], Loss: 0.8477 \n",
      "\n",
      "Epoch: [21/100], Step: [5700/6250], Loss: 1.3059 \n",
      "\n",
      "Epoch: [21/100], Step: [5800/6250], Loss: 0.9251 \n",
      "\n",
      "Epoch: [21/100], Step: [5900/6250], Loss: 0.8351 \n",
      "\n",
      "Epoch: [21/100], Step: [6000/6250], Loss: 0.7127 \n",
      "\n",
      "Epoch: [21/100], Step: [6100/6250], Loss: 1.2081 \n",
      "\n",
      "Epoch: [21/100], Step: [6200/6250], Loss: 1.1020 \n",
      "\n",
      "Epoch: [22/100], Step: [100/6250], Loss: 1.1362 \n",
      "\n",
      "Epoch: [22/100], Step: [200/6250], Loss: 2.0565 \n",
      "\n",
      "Epoch: [22/100], Step: [300/6250], Loss: 0.8420 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [22/100], Step: [400/6250], Loss: 0.4151 \n",
      "\n",
      "Epoch: [22/100], Step: [500/6250], Loss: 0.7361 \n",
      "\n",
      "Epoch: [22/100], Step: [600/6250], Loss: 0.8425 \n",
      "\n",
      "Epoch: [22/100], Step: [700/6250], Loss: 0.7044 \n",
      "\n",
      "Epoch: [22/100], Step: [800/6250], Loss: 1.5801 \n",
      "\n",
      "Epoch: [22/100], Step: [900/6250], Loss: 0.5508 \n",
      "\n",
      "Epoch: [22/100], Step: [1000/6250], Loss: 0.8681 \n",
      "\n",
      "Epoch: [22/100], Step: [1100/6250], Loss: 1.3796 \n",
      "\n",
      "Epoch: [22/100], Step: [1200/6250], Loss: 1.5893 \n",
      "\n",
      "Epoch: [22/100], Step: [1300/6250], Loss: 0.8164 \n",
      "\n",
      "Epoch: [22/100], Step: [1400/6250], Loss: 0.8928 \n",
      "\n",
      "Epoch: [22/100], Step: [1500/6250], Loss: 1.1014 \n",
      "\n",
      "Epoch: [22/100], Step: [1600/6250], Loss: 1.2982 \n",
      "\n",
      "Epoch: [22/100], Step: [1700/6250], Loss: 1.1129 \n",
      "\n",
      "Epoch: [22/100], Step: [1800/6250], Loss: 1.3440 \n",
      "\n",
      "Epoch: [22/100], Step: [1900/6250], Loss: 0.8983 \n",
      "\n",
      "Epoch: [22/100], Step: [2000/6250], Loss: 1.3107 \n",
      "\n",
      "Epoch: [22/100], Step: [2100/6250], Loss: 1.1704 \n",
      "\n",
      "Epoch: [22/100], Step: [2200/6250], Loss: 0.6288 \n",
      "\n",
      "Epoch: [22/100], Step: [2300/6250], Loss: 0.8230 \n",
      "\n",
      "Epoch: [22/100], Step: [2400/6250], Loss: 1.4639 \n",
      "\n",
      "Epoch: [22/100], Step: [2500/6250], Loss: 1.0378 \n",
      "\n",
      "Epoch: [22/100], Step: [2600/6250], Loss: 0.9929 \n",
      "\n",
      "Epoch: [22/100], Step: [2700/6250], Loss: 1.5827 \n",
      "\n",
      "Epoch: [22/100], Step: [2800/6250], Loss: 0.5731 \n",
      "\n",
      "Epoch: [22/100], Step: [2900/6250], Loss: 0.7710 \n",
      "\n",
      "Epoch: [22/100], Step: [3000/6250], Loss: 1.1740 \n",
      "\n",
      "Epoch: [22/100], Step: [3100/6250], Loss: 1.1715 \n",
      "\n",
      "Epoch: [22/100], Step: [3200/6250], Loss: 1.4331 \n",
      "\n",
      "Epoch: [22/100], Step: [3300/6250], Loss: 0.6405 \n",
      "\n",
      "Epoch: [22/100], Step: [3400/6250], Loss: 2.1450 \n",
      "\n",
      "Epoch: [22/100], Step: [3500/6250], Loss: 0.5509 \n",
      "\n",
      "Epoch: [22/100], Step: [3600/6250], Loss: 0.2468 \n",
      "\n",
      "Epoch: [22/100], Step: [3700/6250], Loss: 1.0622 \n",
      "\n",
      "Epoch: [22/100], Step: [3800/6250], Loss: 0.5754 \n",
      "\n",
      "Epoch: [22/100], Step: [3900/6250], Loss: 0.9725 \n",
      "\n",
      "Epoch: [22/100], Step: [4000/6250], Loss: 1.5149 \n",
      "\n",
      "Epoch: [22/100], Step: [4100/6250], Loss: 0.3768 \n",
      "\n",
      "Epoch: [22/100], Step: [4200/6250], Loss: 1.1217 \n",
      "\n",
      "Epoch: [22/100], Step: [4300/6250], Loss: 0.9305 \n",
      "\n",
      "Epoch: [22/100], Step: [4400/6250], Loss: 1.0019 \n",
      "\n",
      "Epoch: [22/100], Step: [4500/6250], Loss: 1.0769 \n",
      "\n",
      "Epoch: [22/100], Step: [4600/6250], Loss: 1.2991 \n",
      "\n",
      "Epoch: [22/100], Step: [4700/6250], Loss: 1.1919 \n",
      "\n",
      "Epoch: [22/100], Step: [4800/6250], Loss: 0.9750 \n",
      "\n",
      "Epoch: [22/100], Step: [4900/6250], Loss: 0.8772 \n",
      "\n",
      "Epoch: [22/100], Step: [5000/6250], Loss: 1.2242 \n",
      "\n",
      "Epoch: [22/100], Step: [5100/6250], Loss: 0.4479 \n",
      "\n",
      "Epoch: [22/100], Step: [5200/6250], Loss: 0.7556 \n",
      "\n",
      "Epoch: [22/100], Step: [5300/6250], Loss: 1.1258 \n",
      "\n",
      "Epoch: [22/100], Step: [5400/6250], Loss: 1.2015 \n",
      "\n",
      "Epoch: [22/100], Step: [5500/6250], Loss: 1.2194 \n",
      "\n",
      "Epoch: [22/100], Step: [5600/6250], Loss: 2.0225 \n",
      "\n",
      "Epoch: [22/100], Step: [5700/6250], Loss: 1.4441 \n",
      "\n",
      "Epoch: [22/100], Step: [5800/6250], Loss: 1.3523 \n",
      "\n",
      "Epoch: [22/100], Step: [5900/6250], Loss: 1.4168 \n",
      "\n",
      "Epoch: [22/100], Step: [6000/6250], Loss: 0.9175 \n",
      "\n",
      "Epoch: [22/100], Step: [6100/6250], Loss: 1.1051 \n",
      "\n",
      "Epoch: [22/100], Step: [6200/6250], Loss: 0.7382 \n",
      "\n",
      "Epoch: [23/100], Step: [100/6250], Loss: 1.0478 \n",
      "\n",
      "Epoch: [23/100], Step: [200/6250], Loss: 1.1907 \n",
      "\n",
      "Epoch: [23/100], Step: [300/6250], Loss: 1.1223 \n",
      "\n",
      "Epoch: [23/100], Step: [400/6250], Loss: 1.2320 \n",
      "\n",
      "Epoch: [23/100], Step: [500/6250], Loss: 0.8246 \n",
      "\n",
      "Epoch: [23/100], Step: [600/6250], Loss: 0.5587 \n",
      "\n",
      "Epoch: [23/100], Step: [700/6250], Loss: 1.3373 \n",
      "\n",
      "Epoch: [23/100], Step: [800/6250], Loss: 1.2434 \n",
      "\n",
      "Epoch: [23/100], Step: [900/6250], Loss: 0.6760 \n",
      "\n",
      "Epoch: [23/100], Step: [1000/6250], Loss: 1.4616 \n",
      "\n",
      "Epoch: [23/100], Step: [1100/6250], Loss: 1.2569 \n",
      "\n",
      "Epoch: [23/100], Step: [1200/6250], Loss: 0.4719 \n",
      "\n",
      "Epoch: [23/100], Step: [1300/6250], Loss: 1.2591 \n",
      "\n",
      "Epoch: [23/100], Step: [1400/6250], Loss: 1.5772 \n",
      "\n",
      "Epoch: [23/100], Step: [1500/6250], Loss: 1.0929 \n",
      "\n",
      "Epoch: [23/100], Step: [1600/6250], Loss: 1.4886 \n",
      "\n",
      "Epoch: [23/100], Step: [1700/6250], Loss: 1.0420 \n",
      "\n",
      "Epoch: [23/100], Step: [1800/6250], Loss: 1.6165 \n",
      "\n",
      "Epoch: [23/100], Step: [1900/6250], Loss: 1.2995 \n",
      "\n",
      "Epoch: [23/100], Step: [2000/6250], Loss: 0.7754 \n",
      "\n",
      "Epoch: [23/100], Step: [2100/6250], Loss: 1.2656 \n",
      "\n",
      "Epoch: [23/100], Step: [2200/6250], Loss: 1.3228 \n",
      "\n",
      "Epoch: [23/100], Step: [2300/6250], Loss: 0.8257 \n",
      "\n",
      "Epoch: [23/100], Step: [2400/6250], Loss: 0.5450 \n",
      "\n",
      "Epoch: [23/100], Step: [2500/6250], Loss: 1.2697 \n",
      "\n",
      "Epoch: [23/100], Step: [2600/6250], Loss: 1.1752 \n",
      "\n",
      "Epoch: [23/100], Step: [2700/6250], Loss: 1.6378 \n",
      "\n",
      "Epoch: [23/100], Step: [2800/6250], Loss: 0.7367 \n",
      "\n",
      "Epoch: [23/100], Step: [2900/6250], Loss: 1.8705 \n",
      "\n",
      "Epoch: [23/100], Step: [3000/6250], Loss: 0.8628 \n",
      "\n",
      "Epoch: [23/100], Step: [3100/6250], Loss: 0.8359 \n",
      "\n",
      "Epoch: [23/100], Step: [3200/6250], Loss: 1.3028 \n",
      "\n",
      "Epoch: [23/100], Step: [3300/6250], Loss: 1.3846 \n",
      "\n",
      "Epoch: [23/100], Step: [3400/6250], Loss: 1.3237 \n",
      "\n",
      "Epoch: [23/100], Step: [3500/6250], Loss: 1.1418 \n",
      "\n",
      "Epoch: [23/100], Step: [3600/6250], Loss: 1.2354 \n",
      "\n",
      "Epoch: [23/100], Step: [3700/6250], Loss: 1.3287 \n",
      "\n",
      "Epoch: [23/100], Step: [3800/6250], Loss: 1.0337 \n",
      "\n",
      "Epoch: [23/100], Step: [3900/6250], Loss: 1.2407 \n",
      "\n",
      "Epoch: [23/100], Step: [4000/6250], Loss: 1.6936 \n",
      "\n",
      "Epoch: [23/100], Step: [4100/6250], Loss: 0.9728 \n",
      "\n",
      "Epoch: [23/100], Step: [4200/6250], Loss: 0.5558 \n",
      "\n",
      "Epoch: [23/100], Step: [4300/6250], Loss: 1.5877 \n",
      "\n",
      "Epoch: [23/100], Step: [4400/6250], Loss: 0.9137 \n",
      "\n",
      "Epoch: [23/100], Step: [4500/6250], Loss: 1.7287 \n",
      "\n",
      "Epoch: [23/100], Step: [4600/6250], Loss: 0.9203 \n",
      "\n",
      "Epoch: [23/100], Step: [4700/6250], Loss: 1.2563 \n",
      "\n",
      "Epoch: [23/100], Step: [4800/6250], Loss: 1.3673 \n",
      "\n",
      "Epoch: [23/100], Step: [4900/6250], Loss: 0.9288 \n",
      "\n",
      "Epoch: [23/100], Step: [5000/6250], Loss: 1.1556 \n",
      "\n",
      "Epoch: [23/100], Step: [5100/6250], Loss: 1.6886 \n",
      "\n",
      "Epoch: [23/100], Step: [5200/6250], Loss: 1.0263 \n",
      "\n",
      "Epoch: [23/100], Step: [5300/6250], Loss: 0.9626 \n",
      "\n",
      "Epoch: [23/100], Step: [5400/6250], Loss: 0.9196 \n",
      "\n",
      "Epoch: [23/100], Step: [5500/6250], Loss: 1.1341 \n",
      "\n",
      "Epoch: [23/100], Step: [5600/6250], Loss: 1.3430 \n",
      "\n",
      "Epoch: [23/100], Step: [5700/6250], Loss: 1.1630 \n",
      "\n",
      "Epoch: [23/100], Step: [5800/6250], Loss: 1.4609 \n",
      "\n",
      "Epoch: [23/100], Step: [5900/6250], Loss: 1.2199 \n",
      "\n",
      "Epoch: [23/100], Step: [6000/6250], Loss: 1.5459 \n",
      "\n",
      "Epoch: [23/100], Step: [6100/6250], Loss: 1.1185 \n",
      "\n",
      "Epoch: [23/100], Step: [6200/6250], Loss: 1.2034 \n",
      "\n",
      "Epoch: [24/100], Step: [100/6250], Loss: 0.8845 \n",
      "\n",
      "Epoch: [24/100], Step: [200/6250], Loss: 1.9469 \n",
      "\n",
      "Epoch: [24/100], Step: [300/6250], Loss: 1.4493 \n",
      "\n",
      "Epoch: [24/100], Step: [400/6250], Loss: 1.1607 \n",
      "\n",
      "Epoch: [24/100], Step: [500/6250], Loss: 1.3775 \n",
      "\n",
      "Epoch: [24/100], Step: [600/6250], Loss: 1.4006 \n",
      "\n",
      "Epoch: [24/100], Step: [700/6250], Loss: 0.7194 \n",
      "\n",
      "Epoch: [24/100], Step: [800/6250], Loss: 0.7349 \n",
      "\n",
      "Epoch: [24/100], Step: [900/6250], Loss: 0.7489 \n",
      "\n",
      "Epoch: [24/100], Step: [1000/6250], Loss: 0.5578 \n",
      "\n",
      "Epoch: [24/100], Step: [1100/6250], Loss: 0.4530 \n",
      "\n",
      "Epoch: [24/100], Step: [1200/6250], Loss: 0.9498 \n",
      "\n",
      "Epoch: [24/100], Step: [1300/6250], Loss: 0.6747 \n",
      "\n",
      "Epoch: [24/100], Step: [1400/6250], Loss: 0.9649 \n",
      "\n",
      "Epoch: [24/100], Step: [1500/6250], Loss: 1.3442 \n",
      "\n",
      "Epoch: [24/100], Step: [1600/6250], Loss: 1.8114 \n",
      "\n",
      "Epoch: [24/100], Step: [1700/6250], Loss: 1.9616 \n",
      "\n",
      "Epoch: [24/100], Step: [1800/6250], Loss: 1.5871 \n",
      "\n",
      "Epoch: [24/100], Step: [1900/6250], Loss: 1.8794 \n",
      "\n",
      "Epoch: [24/100], Step: [2000/6250], Loss: 1.0513 \n",
      "\n",
      "Epoch: [24/100], Step: [2100/6250], Loss: 1.1491 \n",
      "\n",
      "Epoch: [24/100], Step: [2200/6250], Loss: 0.8496 \n",
      "\n",
      "Epoch: [24/100], Step: [2300/6250], Loss: 0.9513 \n",
      "\n",
      "Epoch: [24/100], Step: [2400/6250], Loss: 0.8504 \n",
      "\n",
      "Epoch: [24/100], Step: [2500/6250], Loss: 1.3084 \n",
      "\n",
      "Epoch: [24/100], Step: [2600/6250], Loss: 0.9032 \n",
      "\n",
      "Epoch: [24/100], Step: [2700/6250], Loss: 0.7401 \n",
      "\n",
      "Epoch: [24/100], Step: [2800/6250], Loss: 0.7940 \n",
      "\n",
      "Epoch: [24/100], Step: [2900/6250], Loss: 1.6256 \n",
      "\n",
      "Epoch: [24/100], Step: [3000/6250], Loss: 0.5049 \n",
      "\n",
      "Epoch: [24/100], Step: [3100/6250], Loss: 0.9558 \n",
      "\n",
      "Epoch: [24/100], Step: [3200/6250], Loss: 0.4965 \n",
      "\n",
      "Epoch: [24/100], Step: [3300/6250], Loss: 0.9704 \n",
      "\n",
      "Epoch: [24/100], Step: [3400/6250], Loss: 2.1525 \n",
      "\n",
      "Epoch: [24/100], Step: [3500/6250], Loss: 1.1531 \n",
      "\n",
      "Epoch: [24/100], Step: [3600/6250], Loss: 1.7730 \n",
      "\n",
      "Epoch: [24/100], Step: [3700/6250], Loss: 1.3301 \n",
      "\n",
      "Epoch: [24/100], Step: [3800/6250], Loss: 0.6948 \n",
      "\n",
      "Epoch: [24/100], Step: [3900/6250], Loss: 1.0503 \n",
      "\n",
      "Epoch: [24/100], Step: [4000/6250], Loss: 0.8350 \n",
      "\n",
      "Epoch: [24/100], Step: [4100/6250], Loss: 0.4555 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [24/100], Step: [4200/6250], Loss: 0.6363 \n",
      "\n",
      "Epoch: [24/100], Step: [4300/6250], Loss: 0.7789 \n",
      "\n",
      "Epoch: [24/100], Step: [4400/6250], Loss: 0.8447 \n",
      "\n",
      "Epoch: [24/100], Step: [4500/6250], Loss: 1.3175 \n",
      "\n",
      "Epoch: [24/100], Step: [4600/6250], Loss: 1.3794 \n",
      "\n",
      "Epoch: [24/100], Step: [4700/6250], Loss: 1.5919 \n",
      "\n",
      "Epoch: [24/100], Step: [4800/6250], Loss: 1.2986 \n",
      "\n",
      "Epoch: [24/100], Step: [4900/6250], Loss: 0.9284 \n",
      "\n",
      "Epoch: [24/100], Step: [5000/6250], Loss: 1.2973 \n",
      "\n",
      "Epoch: [24/100], Step: [5100/6250], Loss: 0.5010 \n",
      "\n",
      "Epoch: [24/100], Step: [5200/6250], Loss: 1.0641 \n",
      "\n",
      "Epoch: [24/100], Step: [5300/6250], Loss: 0.7367 \n",
      "\n",
      "Epoch: [24/100], Step: [5400/6250], Loss: 1.1087 \n",
      "\n",
      "Epoch: [24/100], Step: [5500/6250], Loss: 0.7076 \n",
      "\n",
      "Epoch: [24/100], Step: [5600/6250], Loss: 1.4249 \n",
      "\n",
      "Epoch: [24/100], Step: [5700/6250], Loss: 0.8034 \n",
      "\n",
      "Epoch: [24/100], Step: [5800/6250], Loss: 0.7336 \n",
      "\n",
      "Epoch: [24/100], Step: [5900/6250], Loss: 0.7370 \n",
      "\n",
      "Epoch: [24/100], Step: [6000/6250], Loss: 0.8714 \n",
      "\n",
      "Epoch: [24/100], Step: [6100/6250], Loss: 0.3802 \n",
      "\n",
      "Epoch: [24/100], Step: [6200/6250], Loss: 0.6477 \n",
      "\n",
      "Epoch: [25/100], Step: [100/6250], Loss: 1.3538 \n",
      "\n",
      "Epoch: [25/100], Step: [200/6250], Loss: 1.6271 \n",
      "\n",
      "Epoch: [25/100], Step: [300/6250], Loss: 1.3923 \n",
      "\n",
      "Epoch: [25/100], Step: [400/6250], Loss: 0.7059 \n",
      "\n",
      "Epoch: [25/100], Step: [500/6250], Loss: 1.9487 \n",
      "\n",
      "Epoch: [25/100], Step: [600/6250], Loss: 0.6559 \n",
      "\n",
      "Epoch: [25/100], Step: [700/6250], Loss: 1.6739 \n",
      "\n",
      "Epoch: [25/100], Step: [800/6250], Loss: 1.1137 \n",
      "\n",
      "Epoch: [25/100], Step: [900/6250], Loss: 0.9967 \n",
      "\n",
      "Epoch: [25/100], Step: [1000/6250], Loss: 1.0929 \n",
      "\n",
      "Epoch: [25/100], Step: [1100/6250], Loss: 1.1406 \n",
      "\n",
      "Epoch: [25/100], Step: [1200/6250], Loss: 1.1548 \n",
      "\n",
      "Epoch: [25/100], Step: [1300/6250], Loss: 1.1196 \n",
      "\n",
      "Epoch: [25/100], Step: [1400/6250], Loss: 0.4548 \n",
      "\n",
      "Epoch: [25/100], Step: [1500/6250], Loss: 0.6907 \n",
      "\n",
      "Epoch: [25/100], Step: [1600/6250], Loss: 1.0496 \n",
      "\n",
      "Epoch: [25/100], Step: [1700/6250], Loss: 0.4436 \n",
      "\n",
      "Epoch: [25/100], Step: [1800/6250], Loss: 0.8825 \n",
      "\n",
      "Epoch: [25/100], Step: [1900/6250], Loss: 1.2619 \n",
      "\n",
      "Epoch: [25/100], Step: [2000/6250], Loss: 1.0164 \n",
      "\n",
      "Epoch: [25/100], Step: [2100/6250], Loss: 0.9136 \n",
      "\n",
      "Epoch: [25/100], Step: [2200/6250], Loss: 1.0452 \n",
      "\n",
      "Epoch: [25/100], Step: [2300/6250], Loss: 1.7257 \n",
      "\n",
      "Epoch: [25/100], Step: [2400/6250], Loss: 0.7958 \n",
      "\n",
      "Epoch: [25/100], Step: [2500/6250], Loss: 1.2220 \n",
      "\n",
      "Epoch: [25/100], Step: [2600/6250], Loss: 0.6995 \n",
      "\n",
      "Epoch: [25/100], Step: [2700/6250], Loss: 0.3885 \n",
      "\n",
      "Epoch: [25/100], Step: [2800/6250], Loss: 0.5106 \n",
      "\n",
      "Epoch: [25/100], Step: [2900/6250], Loss: 0.7822 \n",
      "\n",
      "Epoch: [25/100], Step: [3000/6250], Loss: 0.5956 \n",
      "\n",
      "Epoch: [25/100], Step: [3100/6250], Loss: 0.7638 \n",
      "\n",
      "Epoch: [25/100], Step: [3200/6250], Loss: 0.8174 \n",
      "\n",
      "Epoch: [25/100], Step: [3300/6250], Loss: 1.1928 \n",
      "\n",
      "Epoch: [25/100], Step: [3400/6250], Loss: 1.2398 \n",
      "\n",
      "Epoch: [25/100], Step: [3500/6250], Loss: 0.6838 \n",
      "\n",
      "Epoch: [25/100], Step: [3600/6250], Loss: 1.1151 \n",
      "\n",
      "Epoch: [25/100], Step: [3700/6250], Loss: 1.9053 \n",
      "\n",
      "Epoch: [25/100], Step: [3800/6250], Loss: 1.3401 \n",
      "\n",
      "Epoch: [25/100], Step: [3900/6250], Loss: 0.8287 \n",
      "\n",
      "Epoch: [25/100], Step: [4000/6250], Loss: 1.8448 \n",
      "\n",
      "Epoch: [25/100], Step: [4100/6250], Loss: 0.7568 \n",
      "\n",
      "Epoch: [25/100], Step: [4200/6250], Loss: 1.2976 \n",
      "\n",
      "Epoch: [25/100], Step: [4300/6250], Loss: 1.1297 \n",
      "\n",
      "Epoch: [25/100], Step: [4400/6250], Loss: 1.2294 \n",
      "\n",
      "Epoch: [25/100], Step: [4500/6250], Loss: 0.8695 \n",
      "\n",
      "Epoch: [25/100], Step: [4600/6250], Loss: 1.5440 \n",
      "\n",
      "Epoch: [25/100], Step: [4700/6250], Loss: 2.0744 \n",
      "\n",
      "Epoch: [25/100], Step: [4800/6250], Loss: 1.0664 \n",
      "\n",
      "Epoch: [25/100], Step: [4900/6250], Loss: 0.7842 \n",
      "\n",
      "Epoch: [25/100], Step: [5000/6250], Loss: 1.8021 \n",
      "\n",
      "Epoch: [25/100], Step: [5100/6250], Loss: 0.5694 \n",
      "\n",
      "Epoch: [25/100], Step: [5200/6250], Loss: 1.5800 \n",
      "\n",
      "Epoch: [25/100], Step: [5300/6250], Loss: 0.6968 \n",
      "\n",
      "Epoch: [25/100], Step: [5400/6250], Loss: 0.7402 \n",
      "\n",
      "Epoch: [25/100], Step: [5500/6250], Loss: 1.1305 \n",
      "\n",
      "Epoch: [25/100], Step: [5600/6250], Loss: 1.1716 \n",
      "\n",
      "Epoch: [25/100], Step: [5700/6250], Loss: 1.3270 \n",
      "\n",
      "Epoch: [25/100], Step: [5800/6250], Loss: 0.9151 \n",
      "\n",
      "Epoch: [25/100], Step: [5900/6250], Loss: 1.0616 \n",
      "\n",
      "Epoch: [25/100], Step: [6000/6250], Loss: 1.3254 \n",
      "\n",
      "Epoch: [25/100], Step: [6100/6250], Loss: 1.1048 \n",
      "\n",
      "Epoch: [25/100], Step: [6200/6250], Loss: 0.9774 \n",
      "\n",
      "Epoch: [26/100], Step: [100/6250], Loss: 1.1149 \n",
      "\n",
      "Epoch: [26/100], Step: [200/6250], Loss: 1.2083 \n",
      "\n",
      "Epoch: [26/100], Step: [300/6250], Loss: 0.8063 \n",
      "\n",
      "Epoch: [26/100], Step: [400/6250], Loss: 1.6328 \n",
      "\n",
      "Epoch: [26/100], Step: [500/6250], Loss: 0.7022 \n",
      "\n",
      "Epoch: [26/100], Step: [600/6250], Loss: 1.0341 \n",
      "\n",
      "Epoch: [26/100], Step: [700/6250], Loss: 1.2320 \n",
      "\n",
      "Epoch: [26/100], Step: [800/6250], Loss: 1.2654 \n",
      "\n",
      "Epoch: [26/100], Step: [900/6250], Loss: 0.5625 \n",
      "\n",
      "Epoch: [26/100], Step: [1000/6250], Loss: 0.6978 \n",
      "\n",
      "Epoch: [26/100], Step: [1100/6250], Loss: 0.7001 \n",
      "\n",
      "Epoch: [26/100], Step: [1200/6250], Loss: 1.3038 \n",
      "\n",
      "Epoch: [26/100], Step: [1300/6250], Loss: 1.3316 \n",
      "\n",
      "Epoch: [26/100], Step: [1400/6250], Loss: 1.0425 \n",
      "\n",
      "Epoch: [26/100], Step: [1500/6250], Loss: 1.3002 \n",
      "\n",
      "Epoch: [26/100], Step: [1600/6250], Loss: 0.9272 \n",
      "\n",
      "Epoch: [26/100], Step: [1700/6250], Loss: 1.2467 \n",
      "\n",
      "Epoch: [26/100], Step: [1800/6250], Loss: 0.8998 \n",
      "\n",
      "Epoch: [26/100], Step: [1900/6250], Loss: 1.7064 \n",
      "\n",
      "Epoch: [26/100], Step: [2000/6250], Loss: 0.8591 \n",
      "\n",
      "Epoch: [26/100], Step: [2100/6250], Loss: 0.6228 \n",
      "\n",
      "Epoch: [26/100], Step: [2200/6250], Loss: 1.0220 \n",
      "\n",
      "Epoch: [26/100], Step: [2300/6250], Loss: 1.0154 \n",
      "\n",
      "Epoch: [26/100], Step: [2400/6250], Loss: 0.5977 \n",
      "\n",
      "Epoch: [26/100], Step: [2500/6250], Loss: 1.0679 \n",
      "\n",
      "Epoch: [26/100], Step: [2600/6250], Loss: 1.3323 \n",
      "\n",
      "Epoch: [26/100], Step: [2700/6250], Loss: 1.1289 \n",
      "\n",
      "Epoch: [26/100], Step: [2800/6250], Loss: 1.0741 \n",
      "\n",
      "Epoch: [26/100], Step: [2900/6250], Loss: 0.9462 \n",
      "\n",
      "Epoch: [26/100], Step: [3000/6250], Loss: 1.4188 \n",
      "\n",
      "Epoch: [26/100], Step: [3100/6250], Loss: 0.9061 \n",
      "\n",
      "Epoch: [26/100], Step: [3200/6250], Loss: 1.5324 \n",
      "\n",
      "Epoch: [26/100], Step: [3300/6250], Loss: 0.9028 \n",
      "\n",
      "Epoch: [26/100], Step: [3400/6250], Loss: 1.6561 \n",
      "\n",
      "Epoch: [26/100], Step: [3500/6250], Loss: 0.7715 \n",
      "\n",
      "Epoch: [26/100], Step: [3600/6250], Loss: 1.2572 \n",
      "\n",
      "Epoch: [26/100], Step: [3700/6250], Loss: 1.0591 \n",
      "\n",
      "Epoch: [26/100], Step: [3800/6250], Loss: 0.4723 \n",
      "\n",
      "Epoch: [26/100], Step: [3900/6250], Loss: 0.5111 \n",
      "\n",
      "Epoch: [26/100], Step: [4000/6250], Loss: 1.0026 \n",
      "\n",
      "Epoch: [26/100], Step: [4100/6250], Loss: 0.3271 \n",
      "\n",
      "Epoch: [26/100], Step: [4200/6250], Loss: 1.2497 \n",
      "\n",
      "Epoch: [26/100], Step: [4300/6250], Loss: 0.4760 \n",
      "\n",
      "Epoch: [26/100], Step: [4400/6250], Loss: 1.1330 \n",
      "\n",
      "Epoch: [26/100], Step: [4500/6250], Loss: 1.5427 \n",
      "\n",
      "Epoch: [26/100], Step: [4600/6250], Loss: 0.6302 \n",
      "\n",
      "Epoch: [26/100], Step: [4700/6250], Loss: 1.0290 \n",
      "\n",
      "Epoch: [26/100], Step: [4800/6250], Loss: 1.1050 \n",
      "\n",
      "Epoch: [26/100], Step: [4900/6250], Loss: 0.7948 \n",
      "\n",
      "Epoch: [26/100], Step: [5000/6250], Loss: 1.4368 \n",
      "\n",
      "Epoch: [26/100], Step: [5100/6250], Loss: 1.0281 \n",
      "\n",
      "Epoch: [26/100], Step: [5200/6250], Loss: 0.7613 \n",
      "\n",
      "Epoch: [26/100], Step: [5300/6250], Loss: 1.9431 \n",
      "\n",
      "Epoch: [26/100], Step: [5400/6250], Loss: 0.6127 \n",
      "\n",
      "Epoch: [26/100], Step: [5500/6250], Loss: 0.9817 \n",
      "\n",
      "Epoch: [26/100], Step: [5600/6250], Loss: 1.0584 \n",
      "\n",
      "Epoch: [26/100], Step: [5700/6250], Loss: 2.2819 \n",
      "\n",
      "Epoch: [26/100], Step: [5800/6250], Loss: 1.9464 \n",
      "\n",
      "Epoch: [26/100], Step: [5900/6250], Loss: 0.9099 \n",
      "\n",
      "Epoch: [26/100], Step: [6000/6250], Loss: 1.9461 \n",
      "\n",
      "Epoch: [26/100], Step: [6100/6250], Loss: 1.6613 \n",
      "\n",
      "Epoch: [26/100], Step: [6200/6250], Loss: 0.9605 \n",
      "\n",
      "Epoch: [27/100], Step: [100/6250], Loss: 0.3052 \n",
      "\n",
      "Epoch: [27/100], Step: [200/6250], Loss: 0.7894 \n",
      "\n",
      "Epoch: [27/100], Step: [300/6250], Loss: 0.7965 \n",
      "\n",
      "Epoch: [27/100], Step: [400/6250], Loss: 1.4316 \n",
      "\n",
      "Epoch: [27/100], Step: [500/6250], Loss: 1.4808 \n",
      "\n",
      "Epoch: [27/100], Step: [600/6250], Loss: 0.8654 \n",
      "\n",
      "Epoch: [27/100], Step: [700/6250], Loss: 0.6336 \n",
      "\n",
      "Epoch: [27/100], Step: [800/6250], Loss: 1.4947 \n",
      "\n",
      "Epoch: [27/100], Step: [900/6250], Loss: 0.5606 \n",
      "\n",
      "Epoch: [27/100], Step: [1000/6250], Loss: 1.3897 \n",
      "\n",
      "Epoch: [27/100], Step: [1100/6250], Loss: 1.5188 \n",
      "\n",
      "Epoch: [27/100], Step: [1200/6250], Loss: 0.9543 \n",
      "\n",
      "Epoch: [27/100], Step: [1300/6250], Loss: 0.4860 \n",
      "\n",
      "Epoch: [27/100], Step: [1400/6250], Loss: 1.1549 \n",
      "\n",
      "Epoch: [27/100], Step: [1500/6250], Loss: 0.6822 \n",
      "\n",
      "Epoch: [27/100], Step: [1600/6250], Loss: 1.1672 \n",
      "\n",
      "Epoch: [27/100], Step: [1700/6250], Loss: 1.4482 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [27/100], Step: [1800/6250], Loss: 0.5693 \n",
      "\n",
      "Epoch: [27/100], Step: [1900/6250], Loss: 0.8285 \n",
      "\n",
      "Epoch: [27/100], Step: [2000/6250], Loss: 1.1747 \n",
      "\n",
      "Epoch: [27/100], Step: [2100/6250], Loss: 1.0817 \n",
      "\n",
      "Epoch: [27/100], Step: [2200/6250], Loss: 1.6720 \n",
      "\n",
      "Epoch: [27/100], Step: [2300/6250], Loss: 1.5259 \n",
      "\n",
      "Epoch: [27/100], Step: [2400/6250], Loss: 1.1109 \n",
      "\n",
      "Epoch: [27/100], Step: [2500/6250], Loss: 0.5841 \n",
      "\n",
      "Epoch: [27/100], Step: [2600/6250], Loss: 1.1767 \n",
      "\n",
      "Epoch: [27/100], Step: [2700/6250], Loss: 1.0812 \n",
      "\n",
      "Epoch: [27/100], Step: [2800/6250], Loss: 1.7060 \n",
      "\n",
      "Epoch: [27/100], Step: [2900/6250], Loss: 0.8115 \n",
      "\n",
      "Epoch: [27/100], Step: [3000/6250], Loss: 1.1207 \n",
      "\n",
      "Epoch: [27/100], Step: [3100/6250], Loss: 0.5153 \n",
      "\n",
      "Epoch: [27/100], Step: [3200/6250], Loss: 1.3527 \n",
      "\n",
      "Epoch: [27/100], Step: [3300/6250], Loss: 0.7400 \n",
      "\n",
      "Epoch: [27/100], Step: [3400/6250], Loss: 2.0349 \n",
      "\n",
      "Epoch: [27/100], Step: [3500/6250], Loss: 1.1535 \n",
      "\n",
      "Epoch: [27/100], Step: [3600/6250], Loss: 0.7633 \n",
      "\n",
      "Epoch: [27/100], Step: [3700/6250], Loss: 1.6702 \n",
      "\n",
      "Epoch: [27/100], Step: [3800/6250], Loss: 1.6576 \n",
      "\n",
      "Epoch: [27/100], Step: [3900/6250], Loss: 1.1403 \n",
      "\n",
      "Epoch: [27/100], Step: [4000/6250], Loss: 1.3176 \n",
      "\n",
      "Epoch: [27/100], Step: [4100/6250], Loss: 1.8811 \n",
      "\n",
      "Epoch: [27/100], Step: [4200/6250], Loss: 1.6616 \n",
      "\n",
      "Epoch: [27/100], Step: [4300/6250], Loss: 1.0245 \n",
      "\n",
      "Epoch: [27/100], Step: [4400/6250], Loss: 0.8807 \n",
      "\n",
      "Epoch: [27/100], Step: [4500/6250], Loss: 0.9808 \n",
      "\n",
      "Epoch: [27/100], Step: [4600/6250], Loss: 1.8162 \n",
      "\n",
      "Epoch: [27/100], Step: [4700/6250], Loss: 0.9876 \n",
      "\n",
      "Epoch: [27/100], Step: [4800/6250], Loss: 0.8423 \n",
      "\n",
      "Epoch: [27/100], Step: [4900/6250], Loss: 0.7163 \n",
      "\n",
      "Epoch: [27/100], Step: [5000/6250], Loss: 1.1798 \n",
      "\n",
      "Epoch: [27/100], Step: [5100/6250], Loss: 1.1870 \n",
      "\n",
      "Epoch: [27/100], Step: [5200/6250], Loss: 0.8498 \n",
      "\n",
      "Epoch: [27/100], Step: [5300/6250], Loss: 0.6034 \n",
      "\n",
      "Epoch: [27/100], Step: [5400/6250], Loss: 0.6820 \n",
      "\n",
      "Epoch: [27/100], Step: [5500/6250], Loss: 1.0545 \n",
      "\n",
      "Epoch: [27/100], Step: [5600/6250], Loss: 0.5259 \n",
      "\n",
      "Epoch: [27/100], Step: [5700/6250], Loss: 1.2276 \n",
      "\n",
      "Epoch: [27/100], Step: [5800/6250], Loss: 1.1406 \n",
      "\n",
      "Epoch: [27/100], Step: [5900/6250], Loss: 1.0059 \n",
      "\n",
      "Epoch: [27/100], Step: [6000/6250], Loss: 0.9307 \n",
      "\n",
      "Epoch: [27/100], Step: [6100/6250], Loss: 0.8779 \n",
      "\n",
      "Epoch: [27/100], Step: [6200/6250], Loss: 1.1547 \n",
      "\n",
      "Epoch: [28/100], Step: [100/6250], Loss: 0.7515 \n",
      "\n",
      "Epoch: [28/100], Step: [200/6250], Loss: 0.8013 \n",
      "\n",
      "Epoch: [28/100], Step: [300/6250], Loss: 0.5467 \n",
      "\n",
      "Epoch: [28/100], Step: [400/6250], Loss: 1.4167 \n",
      "\n",
      "Epoch: [28/100], Step: [500/6250], Loss: 1.3479 \n",
      "\n",
      "Epoch: [28/100], Step: [600/6250], Loss: 1.3276 \n",
      "\n",
      "Epoch: [28/100], Step: [700/6250], Loss: 0.5553 \n",
      "\n",
      "Epoch: [28/100], Step: [800/6250], Loss: 0.7098 \n",
      "\n",
      "Epoch: [28/100], Step: [900/6250], Loss: 0.9294 \n",
      "\n",
      "Epoch: [28/100], Step: [1000/6250], Loss: 1.2625 \n",
      "\n",
      "Epoch: [28/100], Step: [1100/6250], Loss: 0.6368 \n",
      "\n",
      "Epoch: [28/100], Step: [1200/6250], Loss: 1.5637 \n",
      "\n",
      "Epoch: [28/100], Step: [1300/6250], Loss: 0.8636 \n",
      "\n",
      "Epoch: [28/100], Step: [1400/6250], Loss: 1.5259 \n",
      "\n",
      "Epoch: [28/100], Step: [1500/6250], Loss: 1.0770 \n",
      "\n",
      "Epoch: [28/100], Step: [1600/6250], Loss: 0.8080 \n",
      "\n",
      "Epoch: [28/100], Step: [1700/6250], Loss: 0.6685 \n",
      "\n",
      "Epoch: [28/100], Step: [1800/6250], Loss: 1.6730 \n",
      "\n",
      "Epoch: [28/100], Step: [1900/6250], Loss: 0.9126 \n",
      "\n",
      "Epoch: [28/100], Step: [2000/6250], Loss: 0.4697 \n",
      "\n",
      "Epoch: [28/100], Step: [2100/6250], Loss: 0.7274 \n",
      "\n",
      "Epoch: [28/100], Step: [2200/6250], Loss: 0.5390 \n",
      "\n",
      "Epoch: [28/100], Step: [2300/6250], Loss: 0.7512 \n",
      "\n",
      "Epoch: [28/100], Step: [2400/6250], Loss: 1.4013 \n",
      "\n",
      "Epoch: [28/100], Step: [2500/6250], Loss: 1.3875 \n",
      "\n",
      "Epoch: [28/100], Step: [2600/6250], Loss: 2.4511 \n",
      "\n",
      "Epoch: [28/100], Step: [2700/6250], Loss: 1.1620 \n",
      "\n",
      "Epoch: [28/100], Step: [2800/6250], Loss: 0.9020 \n",
      "\n",
      "Epoch: [28/100], Step: [2900/6250], Loss: 0.4471 \n",
      "\n",
      "Epoch: [28/100], Step: [3000/6250], Loss: 0.6921 \n",
      "\n",
      "Epoch: [28/100], Step: [3100/6250], Loss: 0.6821 \n",
      "\n",
      "Epoch: [28/100], Step: [3200/6250], Loss: 1.6572 \n",
      "\n",
      "Epoch: [28/100], Step: [3300/6250], Loss: 0.8693 \n",
      "\n",
      "Epoch: [28/100], Step: [3400/6250], Loss: 1.3456 \n",
      "\n",
      "Epoch: [28/100], Step: [3500/6250], Loss: 0.4722 \n",
      "\n",
      "Epoch: [28/100], Step: [3600/6250], Loss: 1.1093 \n",
      "\n",
      "Epoch: [28/100], Step: [3700/6250], Loss: 0.8488 \n",
      "\n",
      "Epoch: [28/100], Step: [3800/6250], Loss: 1.4296 \n",
      "\n",
      "Epoch: [28/100], Step: [3900/6250], Loss: 1.2006 \n",
      "\n",
      "Epoch: [28/100], Step: [4000/6250], Loss: 0.9363 \n",
      "\n",
      "Epoch: [28/100], Step: [4100/6250], Loss: 1.2119 \n",
      "\n",
      "Epoch: [28/100], Step: [4200/6250], Loss: 0.9185 \n",
      "\n",
      "Epoch: [28/100], Step: [4300/6250], Loss: 0.6449 \n",
      "\n",
      "Epoch: [28/100], Step: [4400/6250], Loss: 1.2011 \n",
      "\n",
      "Epoch: [28/100], Step: [4500/6250], Loss: 0.9558 \n",
      "\n",
      "Epoch: [28/100], Step: [4600/6250], Loss: 1.4544 \n",
      "\n",
      "Epoch: [28/100], Step: [4700/6250], Loss: 1.2773 \n",
      "\n",
      "Epoch: [28/100], Step: [4800/6250], Loss: 1.3026 \n",
      "\n",
      "Epoch: [28/100], Step: [4900/6250], Loss: 1.0416 \n",
      "\n",
      "Epoch: [28/100], Step: [5000/6250], Loss: 0.8030 \n",
      "\n",
      "Epoch: [28/100], Step: [5100/6250], Loss: 0.6490 \n",
      "\n",
      "Epoch: [28/100], Step: [5200/6250], Loss: 0.6752 \n",
      "\n",
      "Epoch: [28/100], Step: [5300/6250], Loss: 1.1750 \n",
      "\n",
      "Epoch: [28/100], Step: [5400/6250], Loss: 0.9239 \n",
      "\n",
      "Epoch: [28/100], Step: [5500/6250], Loss: 1.4471 \n",
      "\n",
      "Epoch: [28/100], Step: [5600/6250], Loss: 0.5607 \n",
      "\n",
      "Epoch: [28/100], Step: [5700/6250], Loss: 1.3126 \n",
      "\n",
      "Epoch: [28/100], Step: [5800/6250], Loss: 1.0589 \n",
      "\n",
      "Epoch: [28/100], Step: [5900/6250], Loss: 0.6937 \n",
      "\n",
      "Epoch: [28/100], Step: [6000/6250], Loss: 0.9692 \n",
      "\n",
      "Epoch: [28/100], Step: [6100/6250], Loss: 1.1367 \n",
      "\n",
      "Epoch: [28/100], Step: [6200/6250], Loss: 1.1002 \n",
      "\n",
      "Epoch: [29/100], Step: [100/6250], Loss: 0.7726 \n",
      "\n",
      "Epoch: [29/100], Step: [200/6250], Loss: 1.4447 \n",
      "\n",
      "Epoch: [29/100], Step: [300/6250], Loss: 0.9986 \n",
      "\n",
      "Epoch: [29/100], Step: [400/6250], Loss: 1.2557 \n",
      "\n",
      "Epoch: [29/100], Step: [500/6250], Loss: 1.3726 \n",
      "\n",
      "Epoch: [29/100], Step: [600/6250], Loss: 0.9230 \n",
      "\n",
      "Epoch: [29/100], Step: [700/6250], Loss: 0.7316 \n",
      "\n",
      "Epoch: [29/100], Step: [800/6250], Loss: 1.0980 \n",
      "\n",
      "Epoch: [29/100], Step: [900/6250], Loss: 0.8686 \n",
      "\n",
      "Epoch: [29/100], Step: [1000/6250], Loss: 1.3604 \n",
      "\n",
      "Epoch: [29/100], Step: [1100/6250], Loss: 0.5863 \n",
      "\n",
      "Epoch: [29/100], Step: [1200/6250], Loss: 0.7207 \n",
      "\n",
      "Epoch: [29/100], Step: [1300/6250], Loss: 0.4033 \n",
      "\n",
      "Epoch: [29/100], Step: [1400/6250], Loss: 0.8436 \n",
      "\n",
      "Epoch: [29/100], Step: [1500/6250], Loss: 1.2018 \n",
      "\n",
      "Epoch: [29/100], Step: [1600/6250], Loss: 0.6236 \n",
      "\n",
      "Epoch: [29/100], Step: [1700/6250], Loss: 1.4941 \n",
      "\n",
      "Epoch: [29/100], Step: [1800/6250], Loss: 0.5519 \n",
      "\n",
      "Epoch: [29/100], Step: [1900/6250], Loss: 1.0273 \n",
      "\n",
      "Epoch: [29/100], Step: [2000/6250], Loss: 0.5316 \n",
      "\n",
      "Epoch: [29/100], Step: [2100/6250], Loss: 0.9554 \n",
      "\n",
      "Epoch: [29/100], Step: [2200/6250], Loss: 0.9493 \n",
      "\n",
      "Epoch: [29/100], Step: [2300/6250], Loss: 0.9392 \n",
      "\n",
      "Epoch: [29/100], Step: [2400/6250], Loss: 0.9207 \n",
      "\n",
      "Epoch: [29/100], Step: [2500/6250], Loss: 1.6933 \n",
      "\n",
      "Epoch: [29/100], Step: [2600/6250], Loss: 0.7090 \n",
      "\n",
      "Epoch: [29/100], Step: [2700/6250], Loss: 1.0444 \n",
      "\n",
      "Epoch: [29/100], Step: [2800/6250], Loss: 1.3621 \n",
      "\n",
      "Epoch: [29/100], Step: [2900/6250], Loss: 1.3126 \n",
      "\n",
      "Epoch: [29/100], Step: [3000/6250], Loss: 1.2196 \n",
      "\n",
      "Epoch: [29/100], Step: [3100/6250], Loss: 1.1323 \n",
      "\n",
      "Epoch: [29/100], Step: [3200/6250], Loss: 0.3980 \n",
      "\n",
      "Epoch: [29/100], Step: [3300/6250], Loss: 0.7771 \n",
      "\n",
      "Epoch: [29/100], Step: [3400/6250], Loss: 1.2795 \n",
      "\n",
      "Epoch: [29/100], Step: [3500/6250], Loss: 1.1588 \n",
      "\n",
      "Epoch: [29/100], Step: [3600/6250], Loss: 1.2075 \n",
      "\n",
      "Epoch: [29/100], Step: [3700/6250], Loss: 1.5457 \n",
      "\n",
      "Epoch: [29/100], Step: [3800/6250], Loss: 1.4337 \n",
      "\n",
      "Epoch: [29/100], Step: [3900/6250], Loss: 0.9977 \n",
      "\n",
      "Epoch: [29/100], Step: [4000/6250], Loss: 1.3001 \n",
      "\n",
      "Epoch: [29/100], Step: [4100/6250], Loss: 1.2645 \n",
      "\n",
      "Epoch: [29/100], Step: [4200/6250], Loss: 0.5126 \n",
      "\n",
      "Epoch: [29/100], Step: [4300/6250], Loss: 1.2755 \n",
      "\n",
      "Epoch: [29/100], Step: [4400/6250], Loss: 1.1579 \n",
      "\n",
      "Epoch: [29/100], Step: [4500/6250], Loss: 1.0501 \n",
      "\n",
      "Epoch: [29/100], Step: [4600/6250], Loss: 1.0500 \n",
      "\n",
      "Epoch: [29/100], Step: [4700/6250], Loss: 0.7611 \n",
      "\n",
      "Epoch: [29/100], Step: [4800/6250], Loss: 0.4506 \n",
      "\n",
      "Epoch: [29/100], Step: [4900/6250], Loss: 0.5761 \n",
      "\n",
      "Epoch: [29/100], Step: [5000/6250], Loss: 0.5967 \n",
      "\n",
      "Epoch: [29/100], Step: [5100/6250], Loss: 0.5162 \n",
      "\n",
      "Epoch: [29/100], Step: [5200/6250], Loss: 0.3410 \n",
      "\n",
      "Epoch: [29/100], Step: [5300/6250], Loss: 0.5643 \n",
      "\n",
      "Epoch: [29/100], Step: [5400/6250], Loss: 0.7753 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [29/100], Step: [5500/6250], Loss: 0.7470 \n",
      "\n",
      "Epoch: [29/100], Step: [5600/6250], Loss: 0.5467 \n",
      "\n",
      "Epoch: [29/100], Step: [5700/6250], Loss: 0.5525 \n",
      "\n",
      "Epoch: [29/100], Step: [5800/6250], Loss: 0.5269 \n",
      "\n",
      "Epoch: [29/100], Step: [5900/6250], Loss: 1.4837 \n",
      "\n",
      "Epoch: [29/100], Step: [6000/6250], Loss: 0.7346 \n",
      "\n",
      "Epoch: [29/100], Step: [6100/6250], Loss: 1.8913 \n",
      "\n",
      "Epoch: [29/100], Step: [6200/6250], Loss: 0.7231 \n",
      "\n",
      "Epoch: [30/100], Step: [100/6250], Loss: 1.4900 \n",
      "\n",
      "Epoch: [30/100], Step: [200/6250], Loss: 0.6607 \n",
      "\n",
      "Epoch: [30/100], Step: [300/6250], Loss: 0.7242 \n",
      "\n",
      "Epoch: [30/100], Step: [400/6250], Loss: 0.6061 \n",
      "\n",
      "Epoch: [30/100], Step: [500/6250], Loss: 0.7780 \n",
      "\n",
      "Epoch: [30/100], Step: [600/6250], Loss: 0.9763 \n",
      "\n",
      "Epoch: [30/100], Step: [700/6250], Loss: 0.8746 \n",
      "\n",
      "Epoch: [30/100], Step: [800/6250], Loss: 0.8165 \n",
      "\n",
      "Epoch: [30/100], Step: [900/6250], Loss: 1.0823 \n",
      "\n",
      "Epoch: [30/100], Step: [1000/6250], Loss: 1.3128 \n",
      "\n",
      "Epoch: [30/100], Step: [1100/6250], Loss: 0.6432 \n",
      "\n",
      "Epoch: [30/100], Step: [1200/6250], Loss: 0.6181 \n",
      "\n",
      "Epoch: [30/100], Step: [1300/6250], Loss: 0.6478 \n",
      "\n",
      "Epoch: [30/100], Step: [1400/6250], Loss: 0.7663 \n",
      "\n",
      "Epoch: [30/100], Step: [1500/6250], Loss: 0.6235 \n",
      "\n",
      "Epoch: [30/100], Step: [1600/6250], Loss: 1.0643 \n",
      "\n",
      "Epoch: [30/100], Step: [1700/6250], Loss: 0.6267 \n",
      "\n",
      "Epoch: [30/100], Step: [1800/6250], Loss: 0.4185 \n",
      "\n",
      "Epoch: [30/100], Step: [1900/6250], Loss: 1.0343 \n",
      "\n",
      "Epoch: [30/100], Step: [2000/6250], Loss: 1.4334 \n",
      "\n",
      "Epoch: [30/100], Step: [2100/6250], Loss: 1.0899 \n",
      "\n",
      "Epoch: [30/100], Step: [2200/6250], Loss: 0.8341 \n",
      "\n",
      "Epoch: [30/100], Step: [2300/6250], Loss: 1.3137 \n",
      "\n",
      "Epoch: [30/100], Step: [2400/6250], Loss: 1.7449 \n",
      "\n",
      "Epoch: [30/100], Step: [2500/6250], Loss: 1.1092 \n",
      "\n",
      "Epoch: [30/100], Step: [2600/6250], Loss: 1.6284 \n",
      "\n",
      "Epoch: [30/100], Step: [2700/6250], Loss: 1.2174 \n",
      "\n",
      "Epoch: [30/100], Step: [2800/6250], Loss: 0.9236 \n",
      "\n",
      "Epoch: [30/100], Step: [2900/6250], Loss: 0.8666 \n",
      "\n",
      "Epoch: [30/100], Step: [3000/6250], Loss: 0.5550 \n",
      "\n",
      "Epoch: [30/100], Step: [3100/6250], Loss: 1.2448 \n",
      "\n",
      "Epoch: [30/100], Step: [3200/6250], Loss: 1.1839 \n",
      "\n",
      "Epoch: [30/100], Step: [3300/6250], Loss: 1.9943 \n",
      "\n",
      "Epoch: [30/100], Step: [3400/6250], Loss: 1.0714 \n",
      "\n",
      "Epoch: [30/100], Step: [3500/6250], Loss: 1.1766 \n",
      "\n",
      "Epoch: [30/100], Step: [3600/6250], Loss: 0.3686 \n",
      "\n",
      "Epoch: [30/100], Step: [3700/6250], Loss: 0.6349 \n",
      "\n",
      "Epoch: [30/100], Step: [3800/6250], Loss: 1.2698 \n",
      "\n",
      "Epoch: [30/100], Step: [3900/6250], Loss: 0.9341 \n",
      "\n",
      "Epoch: [30/100], Step: [4000/6250], Loss: 0.9692 \n",
      "\n",
      "Epoch: [30/100], Step: [4100/6250], Loss: 0.9729 \n",
      "\n",
      "Epoch: [30/100], Step: [4200/6250], Loss: 0.9652 \n",
      "\n",
      "Epoch: [30/100], Step: [4300/6250], Loss: 0.6567 \n",
      "\n",
      "Epoch: [30/100], Step: [4400/6250], Loss: 0.9223 \n",
      "\n",
      "Epoch: [30/100], Step: [4500/6250], Loss: 1.2084 \n",
      "\n",
      "Epoch: [30/100], Step: [4600/6250], Loss: 0.5949 \n",
      "\n",
      "Epoch: [30/100], Step: [4700/6250], Loss: 0.8119 \n",
      "\n",
      "Epoch: [30/100], Step: [4800/6250], Loss: 0.5433 \n",
      "\n",
      "Epoch: [30/100], Step: [4900/6250], Loss: 1.0405 \n",
      "\n",
      "Epoch: [30/100], Step: [5000/6250], Loss: 0.8151 \n",
      "\n",
      "Epoch: [30/100], Step: [5100/6250], Loss: 0.9309 \n",
      "\n",
      "Epoch: [30/100], Step: [5200/6250], Loss: 0.5223 \n",
      "\n",
      "Epoch: [30/100], Step: [5300/6250], Loss: 0.6877 \n",
      "\n",
      "Epoch: [30/100], Step: [5400/6250], Loss: 1.1230 \n",
      "\n",
      "Epoch: [30/100], Step: [5500/6250], Loss: 0.6489 \n",
      "\n",
      "Epoch: [30/100], Step: [5600/6250], Loss: 0.7133 \n",
      "\n",
      "Epoch: [30/100], Step: [5700/6250], Loss: 0.3114 \n",
      "\n",
      "Epoch: [30/100], Step: [5800/6250], Loss: 0.8067 \n",
      "\n",
      "Epoch: [30/100], Step: [5900/6250], Loss: 1.2396 \n",
      "\n",
      "Epoch: [30/100], Step: [6000/6250], Loss: 1.8080 \n",
      "\n",
      "Epoch: [30/100], Step: [6100/6250], Loss: 0.6962 \n",
      "\n",
      "Epoch: [30/100], Step: [6200/6250], Loss: 0.8926 \n",
      "\n",
      "Epoch: [31/100], Step: [100/6250], Loss: 1.2830 \n",
      "\n",
      "Epoch: [31/100], Step: [200/6250], Loss: 1.1255 \n",
      "\n",
      "Epoch: [31/100], Step: [300/6250], Loss: 0.9450 \n",
      "\n",
      "Epoch: [31/100], Step: [400/6250], Loss: 0.4582 \n",
      "\n",
      "Epoch: [31/100], Step: [500/6250], Loss: 1.1451 \n",
      "\n",
      "Epoch: [31/100], Step: [600/6250], Loss: 0.6794 \n",
      "\n",
      "Epoch: [31/100], Step: [700/6250], Loss: 0.7312 \n",
      "\n",
      "Epoch: [31/100], Step: [800/6250], Loss: 1.0472 \n",
      "\n",
      "Epoch: [31/100], Step: [900/6250], Loss: 1.0301 \n",
      "\n",
      "Epoch: [31/100], Step: [1000/6250], Loss: 1.6707 \n",
      "\n",
      "Epoch: [31/100], Step: [1100/6250], Loss: 0.7527 \n",
      "\n",
      "Epoch: [31/100], Step: [1200/6250], Loss: 1.3212 \n",
      "\n",
      "Epoch: [31/100], Step: [1300/6250], Loss: 0.4784 \n",
      "\n",
      "Epoch: [31/100], Step: [1400/6250], Loss: 1.2371 \n",
      "\n",
      "Epoch: [31/100], Step: [1500/6250], Loss: 0.7764 \n",
      "\n",
      "Epoch: [31/100], Step: [1600/6250], Loss: 0.7842 \n",
      "\n",
      "Epoch: [31/100], Step: [1700/6250], Loss: 1.6122 \n",
      "\n",
      "Epoch: [31/100], Step: [1800/6250], Loss: 0.9992 \n",
      "\n",
      "Epoch: [31/100], Step: [1900/6250], Loss: 1.1274 \n",
      "\n",
      "Epoch: [31/100], Step: [2000/6250], Loss: 1.5087 \n",
      "\n",
      "Epoch: [31/100], Step: [2100/6250], Loss: 1.1551 \n",
      "\n",
      "Epoch: [31/100], Step: [2200/6250], Loss: 1.2675 \n",
      "\n",
      "Epoch: [31/100], Step: [2300/6250], Loss: 0.9292 \n",
      "\n",
      "Epoch: [31/100], Step: [2400/6250], Loss: 0.9425 \n",
      "\n",
      "Epoch: [31/100], Step: [2500/6250], Loss: 0.9410 \n",
      "\n",
      "Epoch: [31/100], Step: [2600/6250], Loss: 0.9053 \n",
      "\n",
      "Epoch: [31/100], Step: [2700/6250], Loss: 1.2868 \n",
      "\n",
      "Epoch: [31/100], Step: [2800/6250], Loss: 0.6035 \n",
      "\n",
      "Epoch: [31/100], Step: [2900/6250], Loss: 0.4748 \n",
      "\n",
      "Epoch: [31/100], Step: [3000/6250], Loss: 0.5769 \n",
      "\n",
      "Epoch: [31/100], Step: [3100/6250], Loss: 0.4497 \n",
      "\n",
      "Epoch: [31/100], Step: [3200/6250], Loss: 0.6521 \n",
      "\n",
      "Epoch: [31/100], Step: [3300/6250], Loss: 1.4381 \n",
      "\n",
      "Epoch: [31/100], Step: [3400/6250], Loss: 0.7324 \n",
      "\n",
      "Epoch: [31/100], Step: [3500/6250], Loss: 1.1389 \n",
      "\n",
      "Epoch: [31/100], Step: [3600/6250], Loss: 1.3271 \n",
      "\n",
      "Epoch: [31/100], Step: [3700/6250], Loss: 2.3679 \n",
      "\n",
      "Epoch: [31/100], Step: [3800/6250], Loss: 0.7069 \n",
      "\n",
      "Epoch: [31/100], Step: [3900/6250], Loss: 1.2027 \n",
      "\n",
      "Epoch: [31/100], Step: [4000/6250], Loss: 0.4721 \n",
      "\n",
      "Epoch: [31/100], Step: [4100/6250], Loss: 0.4648 \n",
      "\n",
      "Epoch: [31/100], Step: [4200/6250], Loss: 1.1698 \n",
      "\n",
      "Epoch: [31/100], Step: [4300/6250], Loss: 0.9611 \n",
      "\n",
      "Epoch: [31/100], Step: [4400/6250], Loss: 0.8102 \n",
      "\n",
      "Epoch: [31/100], Step: [4500/6250], Loss: 0.7648 \n",
      "\n",
      "Epoch: [31/100], Step: [4600/6250], Loss: 0.6904 \n",
      "\n",
      "Epoch: [31/100], Step: [4700/6250], Loss: 0.8858 \n",
      "\n",
      "Epoch: [31/100], Step: [4800/6250], Loss: 1.0182 \n",
      "\n",
      "Epoch: [31/100], Step: [4900/6250], Loss: 0.4515 \n",
      "\n",
      "Epoch: [31/100], Step: [5000/6250], Loss: 1.1383 \n",
      "\n",
      "Epoch: [31/100], Step: [5100/6250], Loss: 1.4928 \n",
      "\n",
      "Epoch: [31/100], Step: [5200/6250], Loss: 0.7506 \n",
      "\n",
      "Epoch: [31/100], Step: [5300/6250], Loss: 0.9568 \n",
      "\n",
      "Epoch: [31/100], Step: [5400/6250], Loss: 0.7201 \n",
      "\n",
      "Epoch: [31/100], Step: [5500/6250], Loss: 0.9451 \n",
      "\n",
      "Epoch: [31/100], Step: [5600/6250], Loss: 0.5319 \n",
      "\n",
      "Epoch: [31/100], Step: [5700/6250], Loss: 0.8028 \n",
      "\n",
      "Epoch: [31/100], Step: [5800/6250], Loss: 0.4105 \n",
      "\n",
      "Epoch: [31/100], Step: [5900/6250], Loss: 0.8738 \n",
      "\n",
      "Epoch: [31/100], Step: [6000/6250], Loss: 1.0053 \n",
      "\n",
      "Epoch: [31/100], Step: [6100/6250], Loss: 1.1879 \n",
      "\n",
      "Epoch: [31/100], Step: [6200/6250], Loss: 1.0535 \n",
      "\n",
      "Epoch: [32/100], Step: [100/6250], Loss: 0.8602 \n",
      "\n",
      "Epoch: [32/100], Step: [200/6250], Loss: 1.3282 \n",
      "\n",
      "Epoch: [32/100], Step: [300/6250], Loss: 1.1103 \n",
      "\n",
      "Epoch: [32/100], Step: [400/6250], Loss: 0.7476 \n",
      "\n",
      "Epoch: [32/100], Step: [500/6250], Loss: 0.8178 \n",
      "\n",
      "Epoch: [32/100], Step: [600/6250], Loss: 0.4765 \n",
      "\n",
      "Epoch: [32/100], Step: [700/6250], Loss: 1.0743 \n",
      "\n",
      "Epoch: [32/100], Step: [800/6250], Loss: 1.4895 \n",
      "\n",
      "Epoch: [32/100], Step: [900/6250], Loss: 0.7131 \n",
      "\n",
      "Epoch: [32/100], Step: [1000/6250], Loss: 0.9779 \n",
      "\n",
      "Epoch: [32/100], Step: [1100/6250], Loss: 0.6736 \n",
      "\n",
      "Epoch: [32/100], Step: [1200/6250], Loss: 0.8134 \n",
      "\n",
      "Epoch: [32/100], Step: [1300/6250], Loss: 0.8980 \n",
      "\n",
      "Epoch: [32/100], Step: [1400/6250], Loss: 1.0335 \n",
      "\n",
      "Epoch: [32/100], Step: [1500/6250], Loss: 1.0247 \n",
      "\n",
      "Epoch: [32/100], Step: [1600/6250], Loss: 0.6230 \n",
      "\n",
      "Epoch: [32/100], Step: [1700/6250], Loss: 1.2489 \n",
      "\n",
      "Epoch: [32/100], Step: [1800/6250], Loss: 1.6421 \n",
      "\n",
      "Epoch: [32/100], Step: [1900/6250], Loss: 0.9291 \n",
      "\n",
      "Epoch: [32/100], Step: [2000/6250], Loss: 0.6475 \n",
      "\n",
      "Epoch: [32/100], Step: [2100/6250], Loss: 1.1340 \n",
      "\n",
      "Epoch: [32/100], Step: [2200/6250], Loss: 0.6793 \n",
      "\n",
      "Epoch: [32/100], Step: [2300/6250], Loss: 1.2174 \n",
      "\n",
      "Epoch: [32/100], Step: [2400/6250], Loss: 1.5543 \n",
      "\n",
      "Epoch: [32/100], Step: [2500/6250], Loss: 0.8233 \n",
      "\n",
      "Epoch: [32/100], Step: [2600/6250], Loss: 0.8012 \n",
      "\n",
      "Epoch: [32/100], Step: [2700/6250], Loss: 0.9408 \n",
      "\n",
      "Epoch: [32/100], Step: [2800/6250], Loss: 0.5419 \n",
      "\n",
      "Epoch: [32/100], Step: [2900/6250], Loss: 1.1390 \n",
      "\n",
      "Epoch: [32/100], Step: [3000/6250], Loss: 1.3212 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [32/100], Step: [3100/6250], Loss: 1.1669 \n",
      "\n",
      "Epoch: [32/100], Step: [3200/6250], Loss: 1.1113 \n",
      "\n",
      "Epoch: [32/100], Step: [3300/6250], Loss: 1.2272 \n",
      "\n",
      "Epoch: [32/100], Step: [3400/6250], Loss: 0.6868 \n",
      "\n",
      "Epoch: [32/100], Step: [3500/6250], Loss: 0.7411 \n",
      "\n",
      "Epoch: [32/100], Step: [3600/6250], Loss: 1.4468 \n",
      "\n",
      "Epoch: [32/100], Step: [3700/6250], Loss: 1.4419 \n",
      "\n",
      "Epoch: [32/100], Step: [3800/6250], Loss: 1.2064 \n",
      "\n",
      "Epoch: [32/100], Step: [3900/6250], Loss: 0.9364 \n",
      "\n",
      "Epoch: [32/100], Step: [4000/6250], Loss: 1.7292 \n",
      "\n",
      "Epoch: [32/100], Step: [4100/6250], Loss: 1.1108 \n",
      "\n",
      "Epoch: [32/100], Step: [4200/6250], Loss: 0.8152 \n",
      "\n",
      "Epoch: [32/100], Step: [4300/6250], Loss: 0.8989 \n",
      "\n",
      "Epoch: [32/100], Step: [4400/6250], Loss: 0.6279 \n",
      "\n",
      "Epoch: [32/100], Step: [4500/6250], Loss: 1.4795 \n",
      "\n",
      "Epoch: [32/100], Step: [4600/6250], Loss: 0.3986 \n",
      "\n",
      "Epoch: [32/100], Step: [4700/6250], Loss: 0.3821 \n",
      "\n",
      "Epoch: [32/100], Step: [4800/6250], Loss: 1.0307 \n",
      "\n",
      "Epoch: [32/100], Step: [4900/6250], Loss: 0.8666 \n",
      "\n",
      "Epoch: [32/100], Step: [5000/6250], Loss: 0.8196 \n",
      "\n",
      "Epoch: [32/100], Step: [5100/6250], Loss: 0.9512 \n",
      "\n",
      "Epoch: [32/100], Step: [5200/6250], Loss: 0.6387 \n",
      "\n",
      "Epoch: [32/100], Step: [5300/6250], Loss: 1.1869 \n",
      "\n",
      "Epoch: [32/100], Step: [5400/6250], Loss: 1.7487 \n",
      "\n",
      "Epoch: [32/100], Step: [5500/6250], Loss: 1.5423 \n",
      "\n",
      "Epoch: [32/100], Step: [5600/6250], Loss: 0.3595 \n",
      "\n",
      "Epoch: [32/100], Step: [5700/6250], Loss: 0.7801 \n",
      "\n",
      "Epoch: [32/100], Step: [5800/6250], Loss: 2.1726 \n",
      "\n",
      "Epoch: [32/100], Step: [5900/6250], Loss: 1.1194 \n",
      "\n",
      "Epoch: [32/100], Step: [6000/6250], Loss: 1.8952 \n",
      "\n",
      "Epoch: [32/100], Step: [6100/6250], Loss: 0.7624 \n",
      "\n",
      "Epoch: [32/100], Step: [6200/6250], Loss: 1.9081 \n",
      "\n",
      "Epoch: [33/100], Step: [100/6250], Loss: 0.6118 \n",
      "\n",
      "Epoch: [33/100], Step: [200/6250], Loss: 1.5056 \n",
      "\n",
      "Epoch: [33/100], Step: [300/6250], Loss: 1.4463 \n",
      "\n",
      "Epoch: [33/100], Step: [400/6250], Loss: 0.9868 \n",
      "\n",
      "Epoch: [33/100], Step: [500/6250], Loss: 0.7569 \n",
      "\n",
      "Epoch: [33/100], Step: [600/6250], Loss: 0.8096 \n",
      "\n",
      "Epoch: [33/100], Step: [700/6250], Loss: 0.7923 \n",
      "\n",
      "Epoch: [33/100], Step: [800/6250], Loss: 0.9391 \n",
      "\n",
      "Epoch: [33/100], Step: [900/6250], Loss: 0.9885 \n",
      "\n",
      "Epoch: [33/100], Step: [1000/6250], Loss: 0.8104 \n",
      "\n",
      "Epoch: [33/100], Step: [1100/6250], Loss: 0.9187 \n",
      "\n",
      "Epoch: [33/100], Step: [1200/6250], Loss: 1.2489 \n",
      "\n",
      "Epoch: [33/100], Step: [1300/6250], Loss: 1.3508 \n",
      "\n",
      "Epoch: [33/100], Step: [1400/6250], Loss: 0.3652 \n",
      "\n",
      "Epoch: [33/100], Step: [1500/6250], Loss: 0.9903 \n",
      "\n",
      "Epoch: [33/100], Step: [1600/6250], Loss: 0.3826 \n",
      "\n",
      "Epoch: [33/100], Step: [1700/6250], Loss: 0.9427 \n",
      "\n",
      "Epoch: [33/100], Step: [1800/6250], Loss: 1.1377 \n",
      "\n",
      "Epoch: [33/100], Step: [1900/6250], Loss: 1.1360 \n",
      "\n",
      "Epoch: [33/100], Step: [2000/6250], Loss: 0.3953 \n",
      "\n",
      "Epoch: [33/100], Step: [2100/6250], Loss: 1.3406 \n",
      "\n",
      "Epoch: [33/100], Step: [2200/6250], Loss: 0.8208 \n",
      "\n",
      "Epoch: [33/100], Step: [2300/6250], Loss: 0.6295 \n",
      "\n",
      "Epoch: [33/100], Step: [2400/6250], Loss: 0.4146 \n",
      "\n",
      "Epoch: [33/100], Step: [2500/6250], Loss: 1.2529 \n",
      "\n",
      "Epoch: [33/100], Step: [2600/6250], Loss: 0.4952 \n",
      "\n",
      "Epoch: [33/100], Step: [2700/6250], Loss: 0.6524 \n",
      "\n",
      "Epoch: [33/100], Step: [2800/6250], Loss: 0.5695 \n",
      "\n",
      "Epoch: [33/100], Step: [2900/6250], Loss: 0.9391 \n",
      "\n",
      "Epoch: [33/100], Step: [3000/6250], Loss: 0.4724 \n",
      "\n",
      "Epoch: [33/100], Step: [3100/6250], Loss: 0.9656 \n",
      "\n",
      "Epoch: [33/100], Step: [3200/6250], Loss: 0.5139 \n",
      "\n",
      "Epoch: [33/100], Step: [3300/6250], Loss: 0.5195 \n",
      "\n",
      "Epoch: [33/100], Step: [3400/6250], Loss: 0.6373 \n",
      "\n",
      "Epoch: [33/100], Step: [3500/6250], Loss: 0.8903 \n",
      "\n",
      "Epoch: [33/100], Step: [3600/6250], Loss: 0.7786 \n",
      "\n",
      "Epoch: [33/100], Step: [3700/6250], Loss: 0.6842 \n",
      "\n",
      "Epoch: [33/100], Step: [3800/6250], Loss: 1.8325 \n",
      "\n",
      "Epoch: [33/100], Step: [3900/6250], Loss: 0.6533 \n",
      "\n",
      "Epoch: [33/100], Step: [4000/6250], Loss: 1.2802 \n",
      "\n",
      "Epoch: [33/100], Step: [4100/6250], Loss: 0.6814 \n",
      "\n",
      "Epoch: [33/100], Step: [4200/6250], Loss: 1.1478 \n",
      "\n",
      "Epoch: [33/100], Step: [4300/6250], Loss: 0.3759 \n",
      "\n",
      "Epoch: [33/100], Step: [4400/6250], Loss: 1.2375 \n",
      "\n",
      "Epoch: [33/100], Step: [4500/6250], Loss: 1.3988 \n",
      "\n",
      "Epoch: [33/100], Step: [4600/6250], Loss: 0.7131 \n",
      "\n",
      "Epoch: [33/100], Step: [4700/6250], Loss: 0.4348 \n",
      "\n",
      "Epoch: [33/100], Step: [4800/6250], Loss: 1.6940 \n",
      "\n",
      "Epoch: [33/100], Step: [4900/6250], Loss: 1.0653 \n",
      "\n",
      "Epoch: [33/100], Step: [5000/6250], Loss: 0.9793 \n",
      "\n",
      "Epoch: [33/100], Step: [5100/6250], Loss: 0.7276 \n",
      "\n",
      "Epoch: [33/100], Step: [5200/6250], Loss: 0.8943 \n",
      "\n",
      "Epoch: [33/100], Step: [5300/6250], Loss: 0.9869 \n",
      "\n",
      "Epoch: [33/100], Step: [5400/6250], Loss: 1.0708 \n",
      "\n",
      "Epoch: [33/100], Step: [5500/6250], Loss: 0.4387 \n",
      "\n",
      "Epoch: [33/100], Step: [5600/6250], Loss: 1.3613 \n",
      "\n",
      "Epoch: [33/100], Step: [5700/6250], Loss: 1.0388 \n",
      "\n",
      "Epoch: [33/100], Step: [5800/6250], Loss: 1.4207 \n",
      "\n",
      "Epoch: [33/100], Step: [5900/6250], Loss: 1.0008 \n",
      "\n",
      "Epoch: [33/100], Step: [6000/6250], Loss: 1.1630 \n",
      "\n",
      "Epoch: [33/100], Step: [6100/6250], Loss: 0.8232 \n",
      "\n",
      "Epoch: [33/100], Step: [6200/6250], Loss: 0.1650 \n",
      "\n",
      "Epoch: [34/100], Step: [100/6250], Loss: 0.6980 \n",
      "\n",
      "Epoch: [34/100], Step: [200/6250], Loss: 1.1631 \n",
      "\n",
      "Epoch: [34/100], Step: [300/6250], Loss: 0.9849 \n",
      "\n",
      "Epoch: [34/100], Step: [400/6250], Loss: 1.0030 \n",
      "\n",
      "Epoch: [34/100], Step: [500/6250], Loss: 1.0778 \n",
      "\n",
      "Epoch: [34/100], Step: [600/6250], Loss: 1.2491 \n",
      "\n",
      "Epoch: [34/100], Step: [700/6250], Loss: 1.0795 \n",
      "\n",
      "Epoch: [34/100], Step: [800/6250], Loss: 0.7628 \n",
      "\n",
      "Epoch: [34/100], Step: [900/6250], Loss: 0.4887 \n",
      "\n",
      "Epoch: [34/100], Step: [1000/6250], Loss: 2.0342 \n",
      "\n",
      "Epoch: [34/100], Step: [1100/6250], Loss: 0.9900 \n",
      "\n",
      "Epoch: [34/100], Step: [1200/6250], Loss: 1.2945 \n",
      "\n",
      "Epoch: [34/100], Step: [1300/6250], Loss: 0.4068 \n",
      "\n",
      "Epoch: [34/100], Step: [1400/6250], Loss: 0.6680 \n",
      "\n",
      "Epoch: [34/100], Step: [1500/6250], Loss: 0.4333 \n",
      "\n",
      "Epoch: [34/100], Step: [1600/6250], Loss: 1.2315 \n",
      "\n",
      "Epoch: [34/100], Step: [1700/6250], Loss: 0.7288 \n",
      "\n",
      "Epoch: [34/100], Step: [1800/6250], Loss: 0.5131 \n",
      "\n",
      "Epoch: [34/100], Step: [1900/6250], Loss: 0.8465 \n",
      "\n",
      "Epoch: [34/100], Step: [2000/6250], Loss: 0.5075 \n",
      "\n",
      "Epoch: [34/100], Step: [2100/6250], Loss: 0.8799 \n",
      "\n",
      "Epoch: [34/100], Step: [2200/6250], Loss: 1.3523 \n",
      "\n",
      "Epoch: [34/100], Step: [2300/6250], Loss: 0.2540 \n",
      "\n",
      "Epoch: [34/100], Step: [2400/6250], Loss: 0.9724 \n",
      "\n",
      "Epoch: [34/100], Step: [2500/6250], Loss: 1.0825 \n",
      "\n",
      "Epoch: [34/100], Step: [2600/6250], Loss: 2.1594 \n",
      "\n",
      "Epoch: [34/100], Step: [2700/6250], Loss: 0.5661 \n",
      "\n",
      "Epoch: [34/100], Step: [2800/6250], Loss: 0.9382 \n",
      "\n",
      "Epoch: [34/100], Step: [2900/6250], Loss: 0.8336 \n",
      "\n",
      "Epoch: [34/100], Step: [3000/6250], Loss: 1.2283 \n",
      "\n",
      "Epoch: [34/100], Step: [3100/6250], Loss: 1.5832 \n",
      "\n",
      "Epoch: [34/100], Step: [3200/6250], Loss: 1.0123 \n",
      "\n",
      "Epoch: [34/100], Step: [3300/6250], Loss: 0.3583 \n",
      "\n",
      "Epoch: [34/100], Step: [3400/6250], Loss: 0.5400 \n",
      "\n",
      "Epoch: [34/100], Step: [3500/6250], Loss: 1.2647 \n",
      "\n",
      "Epoch: [34/100], Step: [3600/6250], Loss: 1.3454 \n",
      "\n",
      "Epoch: [34/100], Step: [3700/6250], Loss: 0.6537 \n",
      "\n",
      "Epoch: [34/100], Step: [3800/6250], Loss: 0.9224 \n",
      "\n",
      "Epoch: [34/100], Step: [3900/6250], Loss: 0.3172 \n",
      "\n",
      "Epoch: [34/100], Step: [4000/6250], Loss: 0.5427 \n",
      "\n",
      "Epoch: [34/100], Step: [4100/6250], Loss: 0.5747 \n",
      "\n",
      "Epoch: [34/100], Step: [4200/6250], Loss: 0.8489 \n",
      "\n",
      "Epoch: [34/100], Step: [4300/6250], Loss: 1.0766 \n",
      "\n",
      "Epoch: [34/100], Step: [4400/6250], Loss: 0.5356 \n",
      "\n",
      "Epoch: [34/100], Step: [4500/6250], Loss: 1.3181 \n",
      "\n",
      "Epoch: [34/100], Step: [4600/6250], Loss: 0.8592 \n",
      "\n",
      "Epoch: [34/100], Step: [4700/6250], Loss: 0.6282 \n",
      "\n",
      "Epoch: [34/100], Step: [4800/6250], Loss: 0.9103 \n",
      "\n",
      "Epoch: [34/100], Step: [4900/6250], Loss: 2.1038 \n",
      "\n",
      "Epoch: [34/100], Step: [5000/6250], Loss: 1.5321 \n",
      "\n",
      "Epoch: [34/100], Step: [5100/6250], Loss: 1.2859 \n",
      "\n",
      "Epoch: [34/100], Step: [5200/6250], Loss: 0.6313 \n",
      "\n",
      "Epoch: [34/100], Step: [5300/6250], Loss: 0.7114 \n",
      "\n",
      "Epoch: [34/100], Step: [5400/6250], Loss: 1.0725 \n",
      "\n",
      "Epoch: [34/100], Step: [5500/6250], Loss: 1.1575 \n",
      "\n",
      "Epoch: [34/100], Step: [5600/6250], Loss: 0.7650 \n",
      "\n",
      "Epoch: [34/100], Step: [5700/6250], Loss: 1.8043 \n",
      "\n",
      "Epoch: [34/100], Step: [5800/6250], Loss: 1.1449 \n",
      "\n",
      "Epoch: [34/100], Step: [5900/6250], Loss: 1.0914 \n",
      "\n",
      "Epoch: [34/100], Step: [6000/6250], Loss: 0.7459 \n",
      "\n",
      "Epoch: [34/100], Step: [6100/6250], Loss: 1.1133 \n",
      "\n",
      "Epoch: [34/100], Step: [6200/6250], Loss: 1.0825 \n",
      "\n",
      "Epoch: [35/100], Step: [100/6250], Loss: 1.0654 \n",
      "\n",
      "Epoch: [35/100], Step: [200/6250], Loss: 1.1985 \n",
      "\n",
      "Epoch: [35/100], Step: [300/6250], Loss: 0.8106 \n",
      "\n",
      "Epoch: [35/100], Step: [400/6250], Loss: 1.0589 \n",
      "\n",
      "Epoch: [35/100], Step: [500/6250], Loss: 0.9765 \n",
      "\n",
      "Epoch: [35/100], Step: [600/6250], Loss: 0.6169 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [35/100], Step: [700/6250], Loss: 0.2857 \n",
      "\n",
      "Epoch: [35/100], Step: [800/6250], Loss: 0.5277 \n",
      "\n",
      "Epoch: [35/100], Step: [900/6250], Loss: 0.3825 \n",
      "\n",
      "Epoch: [35/100], Step: [1000/6250], Loss: 0.8949 \n",
      "\n",
      "Epoch: [35/100], Step: [1100/6250], Loss: 0.7869 \n",
      "\n",
      "Epoch: [35/100], Step: [1200/6250], Loss: 0.4768 \n",
      "\n",
      "Epoch: [35/100], Step: [1300/6250], Loss: 0.1450 \n",
      "\n",
      "Epoch: [35/100], Step: [1400/6250], Loss: 2.3036 \n",
      "\n",
      "Epoch: [35/100], Step: [1500/6250], Loss: 1.6360 \n",
      "\n",
      "Epoch: [35/100], Step: [1600/6250], Loss: 0.6230 \n",
      "\n",
      "Epoch: [35/100], Step: [1700/6250], Loss: 1.2116 \n",
      "\n",
      "Epoch: [35/100], Step: [1800/6250], Loss: 1.2941 \n",
      "\n",
      "Epoch: [35/100], Step: [1900/6250], Loss: 1.7081 \n",
      "\n",
      "Epoch: [35/100], Step: [2000/6250], Loss: 0.5495 \n",
      "\n",
      "Epoch: [35/100], Step: [2100/6250], Loss: 0.6373 \n",
      "\n",
      "Epoch: [35/100], Step: [2200/6250], Loss: 0.8815 \n",
      "\n",
      "Epoch: [35/100], Step: [2300/6250], Loss: 0.0863 \n",
      "\n",
      "Epoch: [35/100], Step: [2400/6250], Loss: 0.6953 \n",
      "\n",
      "Epoch: [35/100], Step: [2500/6250], Loss: 0.5337 \n",
      "\n",
      "Epoch: [35/100], Step: [2600/6250], Loss: 0.9126 \n",
      "\n",
      "Epoch: [35/100], Step: [2700/6250], Loss: 0.2656 \n",
      "\n",
      "Epoch: [35/100], Step: [2800/6250], Loss: 1.0351 \n",
      "\n",
      "Epoch: [35/100], Step: [2900/6250], Loss: 0.3139 \n",
      "\n",
      "Epoch: [35/100], Step: [3000/6250], Loss: 0.3071 \n",
      "\n",
      "Epoch: [35/100], Step: [3100/6250], Loss: 0.7267 \n",
      "\n",
      "Epoch: [35/100], Step: [3200/6250], Loss: 0.4563 \n",
      "\n",
      "Epoch: [35/100], Step: [3300/6250], Loss: 0.9189 \n",
      "\n",
      "Epoch: [35/100], Step: [3400/6250], Loss: 0.7914 \n",
      "\n",
      "Epoch: [35/100], Step: [3500/6250], Loss: 1.1539 \n",
      "\n",
      "Epoch: [35/100], Step: [3600/6250], Loss: 0.3711 \n",
      "\n",
      "Epoch: [35/100], Step: [3700/6250], Loss: 0.9673 \n",
      "\n",
      "Epoch: [35/100], Step: [3800/6250], Loss: 1.0339 \n",
      "\n",
      "Epoch: [35/100], Step: [3900/6250], Loss: 0.8326 \n",
      "\n",
      "Epoch: [35/100], Step: [4000/6250], Loss: 1.2024 \n",
      "\n",
      "Epoch: [35/100], Step: [4100/6250], Loss: 0.9190 \n",
      "\n",
      "Epoch: [35/100], Step: [4200/6250], Loss: 0.9167 \n",
      "\n",
      "Epoch: [35/100], Step: [4300/6250], Loss: 0.8128 \n",
      "\n",
      "Epoch: [35/100], Step: [4400/6250], Loss: 0.6024 \n",
      "\n",
      "Epoch: [35/100], Step: [4500/6250], Loss: 0.8217 \n",
      "\n",
      "Epoch: [35/100], Step: [4600/6250], Loss: 1.1298 \n",
      "\n",
      "Epoch: [35/100], Step: [4700/6250], Loss: 1.2306 \n",
      "\n",
      "Epoch: [35/100], Step: [4800/6250], Loss: 0.8766 \n",
      "\n",
      "Epoch: [35/100], Step: [4900/6250], Loss: 0.8742 \n",
      "\n",
      "Epoch: [35/100], Step: [5000/6250], Loss: 1.1992 \n",
      "\n",
      "Epoch: [35/100], Step: [5100/6250], Loss: 0.7724 \n",
      "\n",
      "Epoch: [35/100], Step: [5200/6250], Loss: 0.9163 \n",
      "\n",
      "Epoch: [35/100], Step: [5300/6250], Loss: 1.0825 \n",
      "\n",
      "Epoch: [35/100], Step: [5400/6250], Loss: 1.0348 \n",
      "\n",
      "Epoch: [35/100], Step: [5500/6250], Loss: 1.1770 \n",
      "\n",
      "Epoch: [35/100], Step: [5600/6250], Loss: 0.5438 \n",
      "\n",
      "Epoch: [35/100], Step: [5700/6250], Loss: 1.5532 \n",
      "\n",
      "Epoch: [35/100], Step: [5800/6250], Loss: 0.7854 \n",
      "\n",
      "Epoch: [35/100], Step: [5900/6250], Loss: 0.9627 \n",
      "\n",
      "Epoch: [35/100], Step: [6000/6250], Loss: 0.6304 \n",
      "\n",
      "Epoch: [35/100], Step: [6100/6250], Loss: 0.9243 \n",
      "\n",
      "Epoch: [35/100], Step: [6200/6250], Loss: 1.2109 \n",
      "\n",
      "Epoch: [36/100], Step: [100/6250], Loss: 0.9187 \n",
      "\n",
      "Epoch: [36/100], Step: [200/6250], Loss: 0.5239 \n",
      "\n",
      "Epoch: [36/100], Step: [300/6250], Loss: 0.5141 \n",
      "\n",
      "Epoch: [36/100], Step: [400/6250], Loss: 0.7834 \n",
      "\n",
      "Epoch: [36/100], Step: [500/6250], Loss: 0.6573 \n",
      "\n",
      "Epoch: [36/100], Step: [600/6250], Loss: 0.8653 \n",
      "\n",
      "Epoch: [36/100], Step: [700/6250], Loss: 0.7497 \n",
      "\n",
      "Epoch: [36/100], Step: [800/6250], Loss: 0.9161 \n",
      "\n",
      "Epoch: [36/100], Step: [900/6250], Loss: 1.7536 \n",
      "\n",
      "Epoch: [36/100], Step: [1000/6250], Loss: 0.8369 \n",
      "\n",
      "Epoch: [36/100], Step: [1100/6250], Loss: 0.8983 \n",
      "\n",
      "Epoch: [36/100], Step: [1200/6250], Loss: 0.8390 \n",
      "\n",
      "Epoch: [36/100], Step: [1300/6250], Loss: 0.3679 \n",
      "\n",
      "Epoch: [36/100], Step: [1400/6250], Loss: 1.3823 \n",
      "\n",
      "Epoch: [36/100], Step: [1500/6250], Loss: 1.2332 \n",
      "\n",
      "Epoch: [36/100], Step: [1600/6250], Loss: 1.0364 \n",
      "\n",
      "Epoch: [36/100], Step: [1700/6250], Loss: 0.5635 \n",
      "\n",
      "Epoch: [36/100], Step: [1800/6250], Loss: 0.5018 \n",
      "\n",
      "Epoch: [36/100], Step: [1900/6250], Loss: 0.6740 \n",
      "\n",
      "Epoch: [36/100], Step: [2000/6250], Loss: 0.6942 \n",
      "\n",
      "Epoch: [36/100], Step: [2100/6250], Loss: 0.6412 \n",
      "\n",
      "Epoch: [36/100], Step: [2200/6250], Loss: 0.6829 \n",
      "\n",
      "Epoch: [36/100], Step: [2300/6250], Loss: 0.7978 \n",
      "\n",
      "Epoch: [36/100], Step: [2400/6250], Loss: 1.1793 \n",
      "\n",
      "Epoch: [36/100], Step: [2500/6250], Loss: 1.0962 \n",
      "\n",
      "Epoch: [36/100], Step: [2600/6250], Loss: 0.4565 \n",
      "\n",
      "Epoch: [36/100], Step: [2700/6250], Loss: 0.6258 \n",
      "\n",
      "Epoch: [36/100], Step: [2800/6250], Loss: 0.8107 \n",
      "\n",
      "Epoch: [36/100], Step: [2900/6250], Loss: 1.6864 \n",
      "\n",
      "Epoch: [36/100], Step: [3000/6250], Loss: 0.7985 \n",
      "\n",
      "Epoch: [36/100], Step: [3100/6250], Loss: 0.6900 \n",
      "\n",
      "Epoch: [36/100], Step: [3200/6250], Loss: 0.5532 \n",
      "\n",
      "Epoch: [36/100], Step: [3300/6250], Loss: 1.0278 \n",
      "\n",
      "Epoch: [36/100], Step: [3400/6250], Loss: 0.7806 \n",
      "\n",
      "Epoch: [36/100], Step: [3500/6250], Loss: 1.1492 \n",
      "\n",
      "Epoch: [36/100], Step: [3600/6250], Loss: 1.3340 \n",
      "\n",
      "Epoch: [36/100], Step: [3700/6250], Loss: 1.8966 \n",
      "\n",
      "Epoch: [36/100], Step: [3800/6250], Loss: 0.9355 \n",
      "\n",
      "Epoch: [36/100], Step: [3900/6250], Loss: 0.9989 \n",
      "\n",
      "Epoch: [36/100], Step: [4000/6250], Loss: 1.0875 \n",
      "\n",
      "Epoch: [36/100], Step: [4100/6250], Loss: 1.0202 \n",
      "\n",
      "Epoch: [36/100], Step: [4200/6250], Loss: 0.8729 \n",
      "\n",
      "Epoch: [36/100], Step: [4300/6250], Loss: 0.2902 \n",
      "\n",
      "Epoch: [36/100], Step: [4400/6250], Loss: 1.6297 \n",
      "\n",
      "Epoch: [36/100], Step: [4500/6250], Loss: 1.6595 \n",
      "\n",
      "Epoch: [36/100], Step: [4600/6250], Loss: 0.9309 \n",
      "\n",
      "Epoch: [36/100], Step: [4700/6250], Loss: 1.6554 \n",
      "\n",
      "Epoch: [36/100], Step: [4800/6250], Loss: 0.2965 \n",
      "\n",
      "Epoch: [36/100], Step: [4900/6250], Loss: 1.1203 \n",
      "\n",
      "Epoch: [36/100], Step: [5000/6250], Loss: 0.9596 \n",
      "\n",
      "Epoch: [36/100], Step: [5100/6250], Loss: 0.7976 \n",
      "\n",
      "Epoch: [36/100], Step: [5200/6250], Loss: 0.8863 \n",
      "\n",
      "Epoch: [36/100], Step: [5300/6250], Loss: 0.9566 \n",
      "\n",
      "Epoch: [36/100], Step: [5400/6250], Loss: 0.6143 \n",
      "\n",
      "Epoch: [36/100], Step: [5500/6250], Loss: 0.4199 \n",
      "\n",
      "Epoch: [36/100], Step: [5600/6250], Loss: 0.8930 \n",
      "\n",
      "Epoch: [36/100], Step: [5700/6250], Loss: 0.3482 \n",
      "\n",
      "Epoch: [36/100], Step: [5800/6250], Loss: 0.9116 \n",
      "\n",
      "Epoch: [36/100], Step: [5900/6250], Loss: 1.3576 \n",
      "\n",
      "Epoch: [36/100], Step: [6000/6250], Loss: 0.7551 \n",
      "\n",
      "Epoch: [36/100], Step: [6100/6250], Loss: 0.3363 \n",
      "\n",
      "Epoch: [36/100], Step: [6200/6250], Loss: 0.5735 \n",
      "\n",
      "Epoch: [37/100], Step: [100/6250], Loss: 0.2563 \n",
      "\n",
      "Epoch: [37/100], Step: [200/6250], Loss: 0.3948 \n",
      "\n",
      "Epoch: [37/100], Step: [300/6250], Loss: 0.9293 \n",
      "\n",
      "Epoch: [37/100], Step: [400/6250], Loss: 1.7834 \n",
      "\n",
      "Epoch: [37/100], Step: [500/6250], Loss: 0.5611 \n",
      "\n",
      "Epoch: [37/100], Step: [600/6250], Loss: 0.9810 \n",
      "\n",
      "Epoch: [37/100], Step: [700/6250], Loss: 0.3563 \n",
      "\n",
      "Epoch: [37/100], Step: [800/6250], Loss: 1.0684 \n",
      "\n",
      "Epoch: [37/100], Step: [900/6250], Loss: 1.1250 \n",
      "\n",
      "Epoch: [37/100], Step: [1000/6250], Loss: 0.9858 \n",
      "\n",
      "Epoch: [37/100], Step: [1100/6250], Loss: 1.1530 \n",
      "\n",
      "Epoch: [37/100], Step: [1200/6250], Loss: 1.0145 \n",
      "\n",
      "Epoch: [37/100], Step: [1300/6250], Loss: 0.5462 \n",
      "\n",
      "Epoch: [37/100], Step: [1400/6250], Loss: 1.7996 \n",
      "\n",
      "Epoch: [37/100], Step: [1500/6250], Loss: 0.8127 \n",
      "\n",
      "Epoch: [37/100], Step: [1600/6250], Loss: 0.8047 \n",
      "\n",
      "Epoch: [37/100], Step: [1700/6250], Loss: 0.9304 \n",
      "\n",
      "Epoch: [37/100], Step: [1800/6250], Loss: 0.3964 \n",
      "\n",
      "Epoch: [37/100], Step: [1900/6250], Loss: 0.8540 \n",
      "\n",
      "Epoch: [37/100], Step: [2000/6250], Loss: 0.5337 \n",
      "\n",
      "Epoch: [37/100], Step: [2100/6250], Loss: 1.6881 \n",
      "\n",
      "Epoch: [37/100], Step: [2200/6250], Loss: 0.9412 \n",
      "\n",
      "Epoch: [37/100], Step: [2300/6250], Loss: 1.4318 \n",
      "\n",
      "Epoch: [37/100], Step: [2400/6250], Loss: 0.5336 \n",
      "\n",
      "Epoch: [37/100], Step: [2500/6250], Loss: 0.9308 \n",
      "\n",
      "Epoch: [37/100], Step: [2600/6250], Loss: 0.7969 \n",
      "\n",
      "Epoch: [37/100], Step: [2700/6250], Loss: 0.5860 \n",
      "\n",
      "Epoch: [37/100], Step: [2800/6250], Loss: 1.0159 \n",
      "\n",
      "Epoch: [37/100], Step: [2900/6250], Loss: 0.7237 \n",
      "\n",
      "Epoch: [37/100], Step: [3000/6250], Loss: 0.5833 \n",
      "\n",
      "Epoch: [37/100], Step: [3100/6250], Loss: 1.2123 \n",
      "\n",
      "Epoch: [37/100], Step: [3200/6250], Loss: 0.8548 \n",
      "\n",
      "Epoch: [37/100], Step: [3300/6250], Loss: 1.3756 \n",
      "\n",
      "Epoch: [37/100], Step: [3400/6250], Loss: 0.5733 \n",
      "\n",
      "Epoch: [37/100], Step: [3500/6250], Loss: 0.7442 \n",
      "\n",
      "Epoch: [37/100], Step: [3600/6250], Loss: 1.2926 \n",
      "\n",
      "Epoch: [37/100], Step: [3700/6250], Loss: 0.4833 \n",
      "\n",
      "Epoch: [37/100], Step: [3800/6250], Loss: 0.9793 \n",
      "\n",
      "Epoch: [37/100], Step: [3900/6250], Loss: 0.9535 \n",
      "\n",
      "Epoch: [37/100], Step: [4000/6250], Loss: 1.2770 \n",
      "\n",
      "Epoch: [37/100], Step: [4100/6250], Loss: 1.0006 \n",
      "\n",
      "Epoch: [37/100], Step: [4200/6250], Loss: 0.8026 \n",
      "\n",
      "Epoch: [37/100], Step: [4300/6250], Loss: 0.6682 \n",
      "\n",
      "Epoch: [37/100], Step: [4400/6250], Loss: 0.7653 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [37/100], Step: [4500/6250], Loss: 0.3983 \n",
      "\n",
      "Epoch: [37/100], Step: [4600/6250], Loss: 1.2134 \n",
      "\n",
      "Epoch: [37/100], Step: [4700/6250], Loss: 0.7076 \n",
      "\n",
      "Epoch: [37/100], Step: [4800/6250], Loss: 0.4870 \n",
      "\n",
      "Epoch: [37/100], Step: [4900/6250], Loss: 0.5786 \n",
      "\n",
      "Epoch: [37/100], Step: [5000/6250], Loss: 0.5940 \n",
      "\n",
      "Epoch: [37/100], Step: [5100/6250], Loss: 1.4226 \n",
      "\n",
      "Epoch: [37/100], Step: [5200/6250], Loss: 1.1273 \n",
      "\n",
      "Epoch: [37/100], Step: [5300/6250], Loss: 0.7052 \n",
      "\n",
      "Epoch: [37/100], Step: [5400/6250], Loss: 0.9866 \n",
      "\n",
      "Epoch: [37/100], Step: [5500/6250], Loss: 1.1350 \n",
      "\n",
      "Epoch: [37/100], Step: [5600/6250], Loss: 0.3611 \n",
      "\n",
      "Epoch: [37/100], Step: [5700/6250], Loss: 0.8218 \n",
      "\n",
      "Epoch: [37/100], Step: [5800/6250], Loss: 0.7557 \n",
      "\n",
      "Epoch: [37/100], Step: [5900/6250], Loss: 1.1269 \n",
      "\n",
      "Epoch: [37/100], Step: [6000/6250], Loss: 0.8100 \n",
      "\n",
      "Epoch: [37/100], Step: [6100/6250], Loss: 0.6514 \n",
      "\n",
      "Epoch: [37/100], Step: [6200/6250], Loss: 0.3229 \n",
      "\n",
      "Epoch: [38/100], Step: [100/6250], Loss: 1.6735 \n",
      "\n",
      "Epoch: [38/100], Step: [200/6250], Loss: 0.6679 \n",
      "\n",
      "Epoch: [38/100], Step: [300/6250], Loss: 1.0191 \n",
      "\n",
      "Epoch: [38/100], Step: [400/6250], Loss: 0.7299 \n",
      "\n",
      "Epoch: [38/100], Step: [500/6250], Loss: 0.7111 \n",
      "\n",
      "Epoch: [38/100], Step: [600/6250], Loss: 0.6468 \n",
      "\n",
      "Epoch: [38/100], Step: [700/6250], Loss: 1.1024 \n",
      "\n",
      "Epoch: [38/100], Step: [800/6250], Loss: 0.7760 \n",
      "\n",
      "Epoch: [38/100], Step: [900/6250], Loss: 0.6535 \n",
      "\n",
      "Epoch: [38/100], Step: [1000/6250], Loss: 0.4230 \n",
      "\n",
      "Epoch: [38/100], Step: [1100/6250], Loss: 0.9739 \n",
      "\n",
      "Epoch: [38/100], Step: [1200/6250], Loss: 1.2760 \n",
      "\n",
      "Epoch: [38/100], Step: [1300/6250], Loss: 1.2519 \n",
      "\n",
      "Epoch: [38/100], Step: [1400/6250], Loss: 1.1023 \n",
      "\n",
      "Epoch: [38/100], Step: [1500/6250], Loss: 0.8196 \n",
      "\n",
      "Epoch: [38/100], Step: [1600/6250], Loss: 1.3428 \n",
      "\n",
      "Epoch: [38/100], Step: [1700/6250], Loss: 0.7751 \n",
      "\n",
      "Epoch: [38/100], Step: [1800/6250], Loss: 1.3790 \n",
      "\n",
      "Epoch: [38/100], Step: [1900/6250], Loss: 0.4349 \n",
      "\n",
      "Epoch: [38/100], Step: [2000/6250], Loss: 0.8179 \n",
      "\n",
      "Epoch: [38/100], Step: [2100/6250], Loss: 0.7430 \n",
      "\n",
      "Epoch: [38/100], Step: [2200/6250], Loss: 1.2581 \n",
      "\n",
      "Epoch: [38/100], Step: [2300/6250], Loss: 0.8712 \n",
      "\n",
      "Epoch: [38/100], Step: [2400/6250], Loss: 0.3813 \n",
      "\n",
      "Epoch: [38/100], Step: [2500/6250], Loss: 2.0907 \n",
      "\n",
      "Epoch: [38/100], Step: [2600/6250], Loss: 0.5748 \n",
      "\n",
      "Epoch: [38/100], Step: [2700/6250], Loss: 1.5333 \n",
      "\n",
      "Epoch: [38/100], Step: [2800/6250], Loss: 1.5026 \n",
      "\n",
      "Epoch: [38/100], Step: [2900/6250], Loss: 0.3918 \n",
      "\n",
      "Epoch: [38/100], Step: [3000/6250], Loss: 0.5914 \n",
      "\n",
      "Epoch: [38/100], Step: [3100/6250], Loss: 1.7183 \n",
      "\n",
      "Epoch: [38/100], Step: [3200/6250], Loss: 1.3145 \n",
      "\n",
      "Epoch: [38/100], Step: [3300/6250], Loss: 1.0516 \n",
      "\n",
      "Epoch: [38/100], Step: [3400/6250], Loss: 0.9904 \n",
      "\n",
      "Epoch: [38/100], Step: [3500/6250], Loss: 0.4769 \n",
      "\n",
      "Epoch: [38/100], Step: [3600/6250], Loss: 0.9697 \n",
      "\n",
      "Epoch: [38/100], Step: [3700/6250], Loss: 0.7439 \n",
      "\n",
      "Epoch: [38/100], Step: [3800/6250], Loss: 1.5079 \n",
      "\n",
      "Epoch: [38/100], Step: [3900/6250], Loss: 0.8769 \n",
      "\n",
      "Epoch: [38/100], Step: [4000/6250], Loss: 0.5448 \n",
      "\n",
      "Epoch: [38/100], Step: [4100/6250], Loss: 1.8000 \n",
      "\n",
      "Epoch: [38/100], Step: [4200/6250], Loss: 1.4446 \n",
      "\n",
      "Epoch: [38/100], Step: [4300/6250], Loss: 0.4134 \n",
      "\n",
      "Epoch: [38/100], Step: [4400/6250], Loss: 0.4302 \n",
      "\n",
      "Epoch: [38/100], Step: [4500/6250], Loss: 0.7028 \n",
      "\n",
      "Epoch: [38/100], Step: [4600/6250], Loss: 1.3356 \n",
      "\n",
      "Epoch: [38/100], Step: [4700/6250], Loss: 1.6099 \n",
      "\n",
      "Epoch: [38/100], Step: [4800/6250], Loss: 0.9937 \n",
      "\n",
      "Epoch: [38/100], Step: [4900/6250], Loss: 0.4924 \n",
      "\n",
      "Epoch: [38/100], Step: [5000/6250], Loss: 0.7833 \n",
      "\n",
      "Epoch: [38/100], Step: [5100/6250], Loss: 0.9548 \n",
      "\n",
      "Epoch: [38/100], Step: [5200/6250], Loss: 1.0244 \n",
      "\n",
      "Epoch: [38/100], Step: [5300/6250], Loss: 1.5770 \n",
      "\n",
      "Epoch: [38/100], Step: [5400/6250], Loss: 1.2340 \n",
      "\n",
      "Epoch: [38/100], Step: [5500/6250], Loss: 0.7697 \n",
      "\n",
      "Epoch: [38/100], Step: [5600/6250], Loss: 1.1863 \n",
      "\n",
      "Epoch: [38/100], Step: [5700/6250], Loss: 0.8476 \n",
      "\n",
      "Epoch: [38/100], Step: [5800/6250], Loss: 0.3302 \n",
      "\n",
      "Epoch: [38/100], Step: [5900/6250], Loss: 0.8883 \n",
      "\n",
      "Epoch: [38/100], Step: [6000/6250], Loss: 0.7195 \n",
      "\n",
      "Epoch: [38/100], Step: [6100/6250], Loss: 0.4255 \n",
      "\n",
      "Epoch: [38/100], Step: [6200/6250], Loss: 1.4022 \n",
      "\n",
      "Epoch: [39/100], Step: [100/6250], Loss: 0.4330 \n",
      "\n",
      "Epoch: [39/100], Step: [200/6250], Loss: 0.8177 \n",
      "\n",
      "Epoch: [39/100], Step: [300/6250], Loss: 0.6549 \n",
      "\n",
      "Epoch: [39/100], Step: [400/6250], Loss: 0.5648 \n",
      "\n",
      "Epoch: [39/100], Step: [500/6250], Loss: 1.2845 \n",
      "\n",
      "Epoch: [39/100], Step: [600/6250], Loss: 0.7305 \n",
      "\n",
      "Epoch: [39/100], Step: [700/6250], Loss: 0.6788 \n",
      "\n",
      "Epoch: [39/100], Step: [800/6250], Loss: 1.4409 \n",
      "\n",
      "Epoch: [39/100], Step: [900/6250], Loss: 0.7603 \n",
      "\n",
      "Epoch: [39/100], Step: [1000/6250], Loss: 1.1264 \n",
      "\n",
      "Epoch: [39/100], Step: [1100/6250], Loss: 0.7830 \n",
      "\n",
      "Epoch: [39/100], Step: [1200/6250], Loss: 0.9114 \n",
      "\n",
      "Epoch: [39/100], Step: [1300/6250], Loss: 0.2406 \n",
      "\n",
      "Epoch: [39/100], Step: [1400/6250], Loss: 0.8961 \n",
      "\n",
      "Epoch: [39/100], Step: [1500/6250], Loss: 0.8000 \n",
      "\n",
      "Epoch: [39/100], Step: [1600/6250], Loss: 0.8694 \n",
      "\n",
      "Epoch: [39/100], Step: [1700/6250], Loss: 1.2837 \n",
      "\n",
      "Epoch: [39/100], Step: [1800/6250], Loss: 0.6913 \n",
      "\n",
      "Epoch: [39/100], Step: [1900/6250], Loss: 0.3339 \n",
      "\n",
      "Epoch: [39/100], Step: [2000/6250], Loss: 1.0720 \n",
      "\n",
      "Epoch: [39/100], Step: [2100/6250], Loss: 0.5085 \n",
      "\n",
      "Epoch: [39/100], Step: [2200/6250], Loss: 0.9936 \n",
      "\n",
      "Epoch: [39/100], Step: [2300/6250], Loss: 0.5096 \n",
      "\n",
      "Epoch: [39/100], Step: [2400/6250], Loss: 0.4058 \n",
      "\n",
      "Epoch: [39/100], Step: [2500/6250], Loss: 0.5673 \n",
      "\n",
      "Epoch: [39/100], Step: [2600/6250], Loss: 1.4232 \n",
      "\n",
      "Epoch: [39/100], Step: [2700/6250], Loss: 1.0627 \n",
      "\n",
      "Epoch: [39/100], Step: [2800/6250], Loss: 0.6530 \n",
      "\n",
      "Epoch: [39/100], Step: [2900/6250], Loss: 0.9003 \n",
      "\n",
      "Epoch: [39/100], Step: [3000/6250], Loss: 0.7059 \n",
      "\n",
      "Epoch: [39/100], Step: [3100/6250], Loss: 1.2891 \n",
      "\n",
      "Epoch: [39/100], Step: [3200/6250], Loss: 0.6931 \n",
      "\n",
      "Epoch: [39/100], Step: [3300/6250], Loss: 0.7557 \n",
      "\n",
      "Epoch: [39/100], Step: [3400/6250], Loss: 1.0227 \n",
      "\n",
      "Epoch: [39/100], Step: [3500/6250], Loss: 1.1158 \n",
      "\n",
      "Epoch: [39/100], Step: [3600/6250], Loss: 1.0546 \n",
      "\n",
      "Epoch: [39/100], Step: [3700/6250], Loss: 1.3419 \n",
      "\n",
      "Epoch: [39/100], Step: [3800/6250], Loss: 1.4687 \n",
      "\n",
      "Epoch: [39/100], Step: [3900/6250], Loss: 1.5078 \n",
      "\n",
      "Epoch: [39/100], Step: [4000/6250], Loss: 1.4169 \n",
      "\n",
      "Epoch: [39/100], Step: [4100/6250], Loss: 1.5061 \n",
      "\n",
      "Epoch: [39/100], Step: [4200/6250], Loss: 0.8963 \n",
      "\n",
      "Epoch: [39/100], Step: [4300/6250], Loss: 1.2386 \n",
      "\n",
      "Epoch: [39/100], Step: [4400/6250], Loss: 0.8427 \n",
      "\n",
      "Epoch: [39/100], Step: [4500/6250], Loss: 0.8143 \n",
      "\n",
      "Epoch: [39/100], Step: [4600/6250], Loss: 0.8930 \n",
      "\n",
      "Epoch: [39/100], Step: [4700/6250], Loss: 1.2840 \n",
      "\n",
      "Epoch: [39/100], Step: [4800/6250], Loss: 0.4913 \n",
      "\n",
      "Epoch: [39/100], Step: [4900/6250], Loss: 0.6174 \n",
      "\n",
      "Epoch: [39/100], Step: [5000/6250], Loss: 0.7796 \n",
      "\n",
      "Epoch: [39/100], Step: [5100/6250], Loss: 1.0393 \n",
      "\n",
      "Epoch: [39/100], Step: [5200/6250], Loss: 0.6390 \n",
      "\n",
      "Epoch: [39/100], Step: [5300/6250], Loss: 1.2089 \n",
      "\n",
      "Epoch: [39/100], Step: [5400/6250], Loss: 0.8516 \n",
      "\n",
      "Epoch: [39/100], Step: [5500/6250], Loss: 0.7488 \n",
      "\n",
      "Epoch: [39/100], Step: [5600/6250], Loss: 0.7436 \n",
      "\n",
      "Epoch: [39/100], Step: [5700/6250], Loss: 0.5634 \n",
      "\n",
      "Epoch: [39/100], Step: [5800/6250], Loss: 1.3493 \n",
      "\n",
      "Epoch: [39/100], Step: [5900/6250], Loss: 1.7680 \n",
      "\n",
      "Epoch: [39/100], Step: [6000/6250], Loss: 1.6614 \n",
      "\n",
      "Epoch: [39/100], Step: [6100/6250], Loss: 0.5416 \n",
      "\n",
      "Epoch: [39/100], Step: [6200/6250], Loss: 1.5233 \n",
      "\n",
      "Epoch: [40/100], Step: [100/6250], Loss: 0.9858 \n",
      "\n",
      "Epoch: [40/100], Step: [200/6250], Loss: 1.3325 \n",
      "\n",
      "Epoch: [40/100], Step: [300/6250], Loss: 0.2332 \n",
      "\n",
      "Epoch: [40/100], Step: [400/6250], Loss: 0.4063 \n",
      "\n",
      "Epoch: [40/100], Step: [500/6250], Loss: 1.1757 \n",
      "\n",
      "Epoch: [40/100], Step: [600/6250], Loss: 1.1102 \n",
      "\n",
      "Epoch: [40/100], Step: [700/6250], Loss: 0.5412 \n",
      "\n",
      "Epoch: [40/100], Step: [800/6250], Loss: 1.5749 \n",
      "\n",
      "Epoch: [40/100], Step: [900/6250], Loss: 1.1952 \n",
      "\n",
      "Epoch: [40/100], Step: [1000/6250], Loss: 1.3608 \n",
      "\n",
      "Epoch: [40/100], Step: [1100/6250], Loss: 0.8126 \n",
      "\n",
      "Epoch: [40/100], Step: [1200/6250], Loss: 0.5253 \n",
      "\n",
      "Epoch: [40/100], Step: [1300/6250], Loss: 1.0746 \n",
      "\n",
      "Epoch: [40/100], Step: [1400/6250], Loss: 1.0147 \n",
      "\n",
      "Epoch: [40/100], Step: [1500/6250], Loss: 0.5709 \n",
      "\n",
      "Epoch: [40/100], Step: [1600/6250], Loss: 0.6115 \n",
      "\n",
      "Epoch: [40/100], Step: [1700/6250], Loss: 0.7784 \n",
      "\n",
      "Epoch: [40/100], Step: [1800/6250], Loss: 0.7606 \n",
      "\n",
      "Epoch: [40/100], Step: [1900/6250], Loss: 0.6566 \n",
      "\n",
      "Epoch: [40/100], Step: [2000/6250], Loss: 0.5588 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [40/100], Step: [2100/6250], Loss: 0.5940 \n",
      "\n",
      "Epoch: [40/100], Step: [2200/6250], Loss: 0.4804 \n",
      "\n",
      "Epoch: [40/100], Step: [2300/6250], Loss: 0.7572 \n",
      "\n",
      "Epoch: [40/100], Step: [2400/6250], Loss: 0.5463 \n",
      "\n",
      "Epoch: [40/100], Step: [2500/6250], Loss: 0.4539 \n",
      "\n",
      "Epoch: [40/100], Step: [2600/6250], Loss: 1.5436 \n",
      "\n",
      "Epoch: [40/100], Step: [2700/6250], Loss: 1.2343 \n",
      "\n",
      "Epoch: [40/100], Step: [2800/6250], Loss: 0.6474 \n",
      "\n",
      "Epoch: [40/100], Step: [2900/6250], Loss: 1.0282 \n",
      "\n",
      "Epoch: [40/100], Step: [3000/6250], Loss: 1.3290 \n",
      "\n",
      "Epoch: [40/100], Step: [3100/6250], Loss: 1.6769 \n",
      "\n",
      "Epoch: [40/100], Step: [3200/6250], Loss: 0.8936 \n",
      "\n",
      "Epoch: [40/100], Step: [3300/6250], Loss: 0.5791 \n",
      "\n",
      "Epoch: [40/100], Step: [3400/6250], Loss: 0.4549 \n",
      "\n",
      "Epoch: [40/100], Step: [3500/6250], Loss: 1.1993 \n",
      "\n",
      "Epoch: [40/100], Step: [3600/6250], Loss: 0.6689 \n",
      "\n",
      "Epoch: [40/100], Step: [3700/6250], Loss: 0.9797 \n",
      "\n",
      "Epoch: [40/100], Step: [3800/6250], Loss: 0.6957 \n",
      "\n",
      "Epoch: [40/100], Step: [3900/6250], Loss: 1.1297 \n",
      "\n",
      "Epoch: [40/100], Step: [4000/6250], Loss: 1.2394 \n",
      "\n",
      "Epoch: [40/100], Step: [4100/6250], Loss: 0.5917 \n",
      "\n",
      "Epoch: [40/100], Step: [4200/6250], Loss: 1.2053 \n",
      "\n",
      "Epoch: [40/100], Step: [4300/6250], Loss: 0.2673 \n",
      "\n",
      "Epoch: [40/100], Step: [4400/6250], Loss: 0.6762 \n",
      "\n",
      "Epoch: [40/100], Step: [4500/6250], Loss: 1.1790 \n",
      "\n",
      "Epoch: [40/100], Step: [4600/6250], Loss: 1.0875 \n",
      "\n",
      "Epoch: [40/100], Step: [4700/6250], Loss: 0.5064 \n",
      "\n",
      "Epoch: [40/100], Step: [4800/6250], Loss: 0.7540 \n",
      "\n",
      "Epoch: [40/100], Step: [4900/6250], Loss: 0.4691 \n",
      "\n",
      "Epoch: [40/100], Step: [5000/6250], Loss: 1.0239 \n",
      "\n",
      "Epoch: [40/100], Step: [5100/6250], Loss: 0.7577 \n",
      "\n",
      "Epoch: [40/100], Step: [5200/6250], Loss: 0.6862 \n",
      "\n",
      "Epoch: [40/100], Step: [5300/6250], Loss: 0.4884 \n",
      "\n",
      "Epoch: [40/100], Step: [5400/6250], Loss: 0.6735 \n",
      "\n",
      "Epoch: [40/100], Step: [5500/6250], Loss: 0.4398 \n",
      "\n",
      "Epoch: [40/100], Step: [5600/6250], Loss: 0.6917 \n",
      "\n",
      "Epoch: [40/100], Step: [5700/6250], Loss: 1.1394 \n",
      "\n",
      "Epoch: [40/100], Step: [5800/6250], Loss: 0.6407 \n",
      "\n",
      "Epoch: [40/100], Step: [5900/6250], Loss: 1.2375 \n",
      "\n",
      "Epoch: [40/100], Step: [6000/6250], Loss: 0.3972 \n",
      "\n",
      "Epoch: [40/100], Step: [6100/6250], Loss: 0.5830 \n",
      "\n",
      "Epoch: [40/100], Step: [6200/6250], Loss: 1.2019 \n",
      "\n",
      "Epoch: [41/100], Step: [100/6250], Loss: 0.5233 \n",
      "\n",
      "Epoch: [41/100], Step: [200/6250], Loss: 0.4496 \n",
      "\n",
      "Epoch: [41/100], Step: [300/6250], Loss: 1.1465 \n",
      "\n",
      "Epoch: [41/100], Step: [400/6250], Loss: 0.4035 \n",
      "\n",
      "Epoch: [41/100], Step: [500/6250], Loss: 0.8279 \n",
      "\n",
      "Epoch: [41/100], Step: [600/6250], Loss: 0.7576 \n",
      "\n",
      "Epoch: [41/100], Step: [700/6250], Loss: 0.6804 \n",
      "\n",
      "Epoch: [41/100], Step: [800/6250], Loss: 0.8282 \n",
      "\n",
      "Epoch: [41/100], Step: [900/6250], Loss: 0.3539 \n",
      "\n",
      "Epoch: [41/100], Step: [1000/6250], Loss: 0.8901 \n",
      "\n",
      "Epoch: [41/100], Step: [1100/6250], Loss: 1.0359 \n",
      "\n",
      "Epoch: [41/100], Step: [1200/6250], Loss: 0.3689 \n",
      "\n",
      "Epoch: [41/100], Step: [1300/6250], Loss: 0.5925 \n",
      "\n",
      "Epoch: [41/100], Step: [1400/6250], Loss: 0.5983 \n",
      "\n",
      "Epoch: [41/100], Step: [1500/6250], Loss: 0.7693 \n",
      "\n",
      "Epoch: [41/100], Step: [1600/6250], Loss: 0.6017 \n",
      "\n",
      "Epoch: [41/100], Step: [1700/6250], Loss: 0.3737 \n",
      "\n",
      "Epoch: [41/100], Step: [1800/6250], Loss: 0.6530 \n",
      "\n",
      "Epoch: [41/100], Step: [1900/6250], Loss: 0.6753 \n",
      "\n",
      "Epoch: [41/100], Step: [2000/6250], Loss: 1.3337 \n",
      "\n",
      "Epoch: [41/100], Step: [2100/6250], Loss: 0.9530 \n",
      "\n",
      "Epoch: [41/100], Step: [2200/6250], Loss: 1.1504 \n",
      "\n",
      "Epoch: [41/100], Step: [2300/6250], Loss: 1.2471 \n",
      "\n",
      "Epoch: [41/100], Step: [2400/6250], Loss: 0.9766 \n",
      "\n",
      "Epoch: [41/100], Step: [2500/6250], Loss: 0.5923 \n",
      "\n",
      "Epoch: [41/100], Step: [2600/6250], Loss: 0.9086 \n",
      "\n",
      "Epoch: [41/100], Step: [2700/6250], Loss: 1.0594 \n",
      "\n",
      "Epoch: [41/100], Step: [2800/6250], Loss: 1.5920 \n",
      "\n",
      "Epoch: [41/100], Step: [2900/6250], Loss: 1.2250 \n",
      "\n",
      "Epoch: [41/100], Step: [3000/6250], Loss: 1.4003 \n",
      "\n",
      "Epoch: [41/100], Step: [3100/6250], Loss: 0.6069 \n",
      "\n",
      "Epoch: [41/100], Step: [3200/6250], Loss: 0.9232 \n",
      "\n",
      "Epoch: [41/100], Step: [3300/6250], Loss: 0.3554 \n",
      "\n",
      "Epoch: [41/100], Step: [3400/6250], Loss: 1.2271 \n",
      "\n",
      "Epoch: [41/100], Step: [3500/6250], Loss: 1.8050 \n",
      "\n",
      "Epoch: [41/100], Step: [3600/6250], Loss: 1.3519 \n",
      "\n",
      "Epoch: [41/100], Step: [3700/6250], Loss: 0.4456 \n",
      "\n",
      "Epoch: [41/100], Step: [3800/6250], Loss: 0.7352 \n",
      "\n",
      "Epoch: [41/100], Step: [3900/6250], Loss: 0.9933 \n",
      "\n",
      "Epoch: [41/100], Step: [4000/6250], Loss: 0.9017 \n",
      "\n",
      "Epoch: [41/100], Step: [4100/6250], Loss: 0.9618 \n",
      "\n",
      "Epoch: [41/100], Step: [4200/6250], Loss: 0.5251 \n",
      "\n",
      "Epoch: [41/100], Step: [4300/6250], Loss: 0.4094 \n",
      "\n",
      "Epoch: [41/100], Step: [4400/6250], Loss: 1.3171 \n",
      "\n",
      "Epoch: [41/100], Step: [4500/6250], Loss: 1.6842 \n",
      "\n",
      "Epoch: [41/100], Step: [4600/6250], Loss: 0.8076 \n",
      "\n",
      "Epoch: [41/100], Step: [4700/6250], Loss: 0.4455 \n",
      "\n",
      "Epoch: [41/100], Step: [4800/6250], Loss: 0.3447 \n",
      "\n",
      "Epoch: [41/100], Step: [4900/6250], Loss: 0.8116 \n",
      "\n",
      "Epoch: [41/100], Step: [5000/6250], Loss: 0.5335 \n",
      "\n",
      "Epoch: [41/100], Step: [5100/6250], Loss: 1.2064 \n",
      "\n",
      "Epoch: [41/100], Step: [5200/6250], Loss: 0.3137 \n",
      "\n",
      "Epoch: [41/100], Step: [5300/6250], Loss: 0.6401 \n",
      "\n",
      "Epoch: [41/100], Step: [5400/6250], Loss: 0.4316 \n",
      "\n",
      "Epoch: [41/100], Step: [5500/6250], Loss: 0.4949 \n",
      "\n",
      "Epoch: [41/100], Step: [5600/6250], Loss: 0.5942 \n",
      "\n",
      "Epoch: [41/100], Step: [5700/6250], Loss: 0.5160 \n",
      "\n",
      "Epoch: [41/100], Step: [5800/6250], Loss: 0.7789 \n",
      "\n",
      "Epoch: [41/100], Step: [5900/6250], Loss: 0.2355 \n",
      "\n",
      "Epoch: [41/100], Step: [6000/6250], Loss: 1.2326 \n",
      "\n",
      "Epoch: [41/100], Step: [6100/6250], Loss: 0.7769 \n",
      "\n",
      "Epoch: [41/100], Step: [6200/6250], Loss: 0.4463 \n",
      "\n",
      "Epoch: [42/100], Step: [100/6250], Loss: 0.6471 \n",
      "\n",
      "Epoch: [42/100], Step: [200/6250], Loss: 0.5755 \n",
      "\n",
      "Epoch: [42/100], Step: [300/6250], Loss: 0.9412 \n",
      "\n",
      "Epoch: [42/100], Step: [400/6250], Loss: 1.6243 \n",
      "\n",
      "Epoch: [42/100], Step: [500/6250], Loss: 0.9109 \n",
      "\n",
      "Epoch: [42/100], Step: [600/6250], Loss: 1.4278 \n",
      "\n",
      "Epoch: [42/100], Step: [700/6250], Loss: 0.8379 \n",
      "\n",
      "Epoch: [42/100], Step: [800/6250], Loss: 0.4553 \n",
      "\n",
      "Epoch: [42/100], Step: [900/6250], Loss: 0.3461 \n",
      "\n",
      "Epoch: [42/100], Step: [1000/6250], Loss: 0.9372 \n",
      "\n",
      "Epoch: [42/100], Step: [1100/6250], Loss: 0.4789 \n",
      "\n",
      "Epoch: [42/100], Step: [1200/6250], Loss: 0.5313 \n",
      "\n",
      "Epoch: [42/100], Step: [1300/6250], Loss: 0.9484 \n",
      "\n",
      "Epoch: [42/100], Step: [1400/6250], Loss: 0.5931 \n",
      "\n",
      "Epoch: [42/100], Step: [1500/6250], Loss: 1.1057 \n",
      "\n",
      "Epoch: [42/100], Step: [1600/6250], Loss: 0.7072 \n",
      "\n",
      "Epoch: [42/100], Step: [1700/6250], Loss: 1.3390 \n",
      "\n",
      "Epoch: [42/100], Step: [1800/6250], Loss: 0.7351 \n",
      "\n",
      "Epoch: [42/100], Step: [1900/6250], Loss: 0.8382 \n",
      "\n",
      "Epoch: [42/100], Step: [2000/6250], Loss: 1.1321 \n",
      "\n",
      "Epoch: [42/100], Step: [2100/6250], Loss: 1.0272 \n",
      "\n",
      "Epoch: [42/100], Step: [2200/6250], Loss: 0.4822 \n",
      "\n",
      "Epoch: [42/100], Step: [2300/6250], Loss: 0.6493 \n",
      "\n",
      "Epoch: [42/100], Step: [2400/6250], Loss: 1.4289 \n",
      "\n",
      "Epoch: [42/100], Step: [2500/6250], Loss: 0.9283 \n",
      "\n",
      "Epoch: [42/100], Step: [2600/6250], Loss: 1.7233 \n",
      "\n",
      "Epoch: [42/100], Step: [2700/6250], Loss: 0.5345 \n",
      "\n",
      "Epoch: [42/100], Step: [2800/6250], Loss: 1.2307 \n",
      "\n",
      "Epoch: [42/100], Step: [2900/6250], Loss: 0.3141 \n",
      "\n",
      "Epoch: [42/100], Step: [3000/6250], Loss: 0.5015 \n",
      "\n",
      "Epoch: [42/100], Step: [3100/6250], Loss: 0.9878 \n",
      "\n",
      "Epoch: [42/100], Step: [3200/6250], Loss: 0.8383 \n",
      "\n",
      "Epoch: [42/100], Step: [3300/6250], Loss: 1.1670 \n",
      "\n",
      "Epoch: [42/100], Step: [3400/6250], Loss: 1.0455 \n",
      "\n",
      "Epoch: [42/100], Step: [3500/6250], Loss: 0.7046 \n",
      "\n",
      "Epoch: [42/100], Step: [3600/6250], Loss: 1.0249 \n",
      "\n",
      "Epoch: [42/100], Step: [3700/6250], Loss: 0.3342 \n",
      "\n",
      "Epoch: [42/100], Step: [3800/6250], Loss: 0.1685 \n",
      "\n",
      "Epoch: [42/100], Step: [3900/6250], Loss: 0.6543 \n",
      "\n",
      "Epoch: [42/100], Step: [4000/6250], Loss: 0.6330 \n",
      "\n",
      "Epoch: [42/100], Step: [4100/6250], Loss: 0.5562 \n",
      "\n",
      "Epoch: [42/100], Step: [4200/6250], Loss: 0.7133 \n",
      "\n",
      "Epoch: [42/100], Step: [4300/6250], Loss: 0.7650 \n",
      "\n",
      "Epoch: [42/100], Step: [4400/6250], Loss: 0.6172 \n",
      "\n",
      "Epoch: [42/100], Step: [4500/6250], Loss: 0.8719 \n",
      "\n",
      "Epoch: [42/100], Step: [4600/6250], Loss: 0.8492 \n",
      "\n",
      "Epoch: [42/100], Step: [4700/6250], Loss: 0.7990 \n",
      "\n",
      "Epoch: [42/100], Step: [4800/6250], Loss: 0.4593 \n",
      "\n",
      "Epoch: [42/100], Step: [4900/6250], Loss: 0.2741 \n",
      "\n",
      "Epoch: [42/100], Step: [5000/6250], Loss: 0.2982 \n",
      "\n",
      "Epoch: [42/100], Step: [5100/6250], Loss: 0.5722 \n",
      "\n",
      "Epoch: [42/100], Step: [5200/6250], Loss: 1.0919 \n",
      "\n",
      "Epoch: [42/100], Step: [5300/6250], Loss: 1.5878 \n",
      "\n",
      "Epoch: [42/100], Step: [5400/6250], Loss: 1.4719 \n",
      "\n",
      "Epoch: [42/100], Step: [5500/6250], Loss: 0.3131 \n",
      "\n",
      "Epoch: [42/100], Step: [5600/6250], Loss: 0.5394 \n",
      "\n",
      "Epoch: [42/100], Step: [5700/6250], Loss: 0.4926 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [42/100], Step: [5800/6250], Loss: 0.8406 \n",
      "\n",
      "Epoch: [42/100], Step: [5900/6250], Loss: 1.2772 \n",
      "\n",
      "Epoch: [42/100], Step: [6000/6250], Loss: 0.6183 \n",
      "\n",
      "Epoch: [42/100], Step: [6100/6250], Loss: 1.0797 \n",
      "\n",
      "Epoch: [42/100], Step: [6200/6250], Loss: 0.3549 \n",
      "\n",
      "Epoch: [43/100], Step: [100/6250], Loss: 0.9613 \n",
      "\n",
      "Epoch: [43/100], Step: [200/6250], Loss: 1.0840 \n",
      "\n",
      "Epoch: [43/100], Step: [300/6250], Loss: 0.6724 \n",
      "\n",
      "Epoch: [43/100], Step: [400/6250], Loss: 0.5599 \n",
      "\n",
      "Epoch: [43/100], Step: [500/6250], Loss: 0.3232 \n",
      "\n",
      "Epoch: [43/100], Step: [600/6250], Loss: 0.3616 \n",
      "\n",
      "Epoch: [43/100], Step: [700/6250], Loss: 1.2250 \n",
      "\n",
      "Epoch: [43/100], Step: [800/6250], Loss: 1.0877 \n",
      "\n",
      "Epoch: [43/100], Step: [900/6250], Loss: 0.6912 \n",
      "\n",
      "Epoch: [43/100], Step: [1000/6250], Loss: 0.8955 \n",
      "\n",
      "Epoch: [43/100], Step: [1100/6250], Loss: 0.5530 \n",
      "\n",
      "Epoch: [43/100], Step: [1200/6250], Loss: 1.2561 \n",
      "\n",
      "Epoch: [43/100], Step: [1300/6250], Loss: 0.3344 \n",
      "\n",
      "Epoch: [43/100], Step: [1400/6250], Loss: 0.5168 \n",
      "\n",
      "Epoch: [43/100], Step: [1500/6250], Loss: 0.4888 \n",
      "\n",
      "Epoch: [43/100], Step: [1600/6250], Loss: 1.2165 \n",
      "\n",
      "Epoch: [43/100], Step: [1700/6250], Loss: 0.7021 \n",
      "\n",
      "Epoch: [43/100], Step: [1800/6250], Loss: 1.2901 \n",
      "\n",
      "Epoch: [43/100], Step: [1900/6250], Loss: 0.6088 \n",
      "\n",
      "Epoch: [43/100], Step: [2000/6250], Loss: 0.5119 \n",
      "\n",
      "Epoch: [43/100], Step: [2100/6250], Loss: 1.1117 \n",
      "\n",
      "Epoch: [43/100], Step: [2200/6250], Loss: 0.8407 \n",
      "\n",
      "Epoch: [43/100], Step: [2300/6250], Loss: 1.6155 \n",
      "\n",
      "Epoch: [43/100], Step: [2400/6250], Loss: 0.9194 \n",
      "\n",
      "Epoch: [43/100], Step: [2500/6250], Loss: 0.1582 \n",
      "\n",
      "Epoch: [43/100], Step: [2600/6250], Loss: 0.4603 \n",
      "\n",
      "Epoch: [43/100], Step: [2700/6250], Loss: 0.7835 \n",
      "\n",
      "Epoch: [43/100], Step: [2800/6250], Loss: 0.6269 \n",
      "\n",
      "Epoch: [43/100], Step: [2900/6250], Loss: 1.2403 \n",
      "\n",
      "Epoch: [43/100], Step: [3000/6250], Loss: 0.9261 \n",
      "\n",
      "Epoch: [43/100], Step: [3100/6250], Loss: 0.7344 \n",
      "\n",
      "Epoch: [43/100], Step: [3200/6250], Loss: 1.4250 \n",
      "\n",
      "Epoch: [43/100], Step: [3300/6250], Loss: 0.8113 \n",
      "\n",
      "Epoch: [43/100], Step: [3400/6250], Loss: 1.2076 \n",
      "\n",
      "Epoch: [43/100], Step: [3500/6250], Loss: 0.4285 \n",
      "\n",
      "Epoch: [43/100], Step: [3600/6250], Loss: 0.4648 \n",
      "\n",
      "Epoch: [43/100], Step: [3700/6250], Loss: 1.2575 \n",
      "\n",
      "Epoch: [43/100], Step: [3800/6250], Loss: 0.7926 \n",
      "\n",
      "Epoch: [43/100], Step: [3900/6250], Loss: 0.5500 \n",
      "\n",
      "Epoch: [43/100], Step: [4000/6250], Loss: 0.9644 \n",
      "\n",
      "Epoch: [43/100], Step: [4100/6250], Loss: 2.0449 \n",
      "\n",
      "Epoch: [43/100], Step: [4200/6250], Loss: 0.9044 \n",
      "\n",
      "Epoch: [43/100], Step: [4300/6250], Loss: 0.6246 \n",
      "\n",
      "Epoch: [43/100], Step: [4400/6250], Loss: 0.9930 \n",
      "\n",
      "Epoch: [43/100], Step: [4500/6250], Loss: 1.2484 \n",
      "\n",
      "Epoch: [43/100], Step: [4600/6250], Loss: 0.8122 \n",
      "\n",
      "Epoch: [43/100], Step: [4700/6250], Loss: 0.4227 \n",
      "\n",
      "Epoch: [43/100], Step: [4800/6250], Loss: 1.4002 \n",
      "\n",
      "Epoch: [43/100], Step: [4900/6250], Loss: 0.7580 \n",
      "\n",
      "Epoch: [43/100], Step: [5000/6250], Loss: 0.7127 \n",
      "\n",
      "Epoch: [43/100], Step: [5100/6250], Loss: 1.0265 \n",
      "\n",
      "Epoch: [43/100], Step: [5200/6250], Loss: 1.9430 \n",
      "\n",
      "Epoch: [43/100], Step: [5300/6250], Loss: 0.6122 \n",
      "\n",
      "Epoch: [43/100], Step: [5400/6250], Loss: 0.8469 \n",
      "\n",
      "Epoch: [43/100], Step: [5500/6250], Loss: 0.6629 \n",
      "\n",
      "Epoch: [43/100], Step: [5600/6250], Loss: 0.6533 \n",
      "\n",
      "Epoch: [43/100], Step: [5700/6250], Loss: 0.7827 \n",
      "\n",
      "Epoch: [43/100], Step: [5800/6250], Loss: 1.0243 \n",
      "\n",
      "Epoch: [43/100], Step: [5900/6250], Loss: 0.7036 \n",
      "\n",
      "Epoch: [43/100], Step: [6000/6250], Loss: 0.5172 \n",
      "\n",
      "Epoch: [43/100], Step: [6100/6250], Loss: 0.8443 \n",
      "\n",
      "Epoch: [43/100], Step: [6200/6250], Loss: 0.9995 \n",
      "\n",
      "Epoch: [44/100], Step: [100/6250], Loss: 0.7689 \n",
      "\n",
      "Epoch: [44/100], Step: [200/6250], Loss: 1.3261 \n",
      "\n",
      "Epoch: [44/100], Step: [300/6250], Loss: 0.7473 \n",
      "\n",
      "Epoch: [44/100], Step: [400/6250], Loss: 0.5216 \n",
      "\n",
      "Epoch: [44/100], Step: [500/6250], Loss: 0.7677 \n",
      "\n",
      "Epoch: [44/100], Step: [600/6250], Loss: 0.3708 \n",
      "\n",
      "Epoch: [44/100], Step: [700/6250], Loss: 1.1070 \n",
      "\n",
      "Epoch: [44/100], Step: [800/6250], Loss: 1.0640 \n",
      "\n",
      "Epoch: [44/100], Step: [900/6250], Loss: 0.3388 \n",
      "\n",
      "Epoch: [44/100], Step: [1000/6250], Loss: 1.2196 \n",
      "\n",
      "Epoch: [44/100], Step: [1100/6250], Loss: 0.7005 \n",
      "\n",
      "Epoch: [44/100], Step: [1200/6250], Loss: 0.5896 \n",
      "\n",
      "Epoch: [44/100], Step: [1300/6250], Loss: 0.4589 \n",
      "\n",
      "Epoch: [44/100], Step: [1400/6250], Loss: 1.5815 \n",
      "\n",
      "Epoch: [44/100], Step: [1500/6250], Loss: 0.7529 \n",
      "\n",
      "Epoch: [44/100], Step: [1600/6250], Loss: 0.3725 \n",
      "\n",
      "Epoch: [44/100], Step: [1700/6250], Loss: 0.6851 \n",
      "\n",
      "Epoch: [44/100], Step: [1800/6250], Loss: 0.6247 \n",
      "\n",
      "Epoch: [44/100], Step: [1900/6250], Loss: 1.2596 \n",
      "\n",
      "Epoch: [44/100], Step: [2000/6250], Loss: 0.3913 \n",
      "\n",
      "Epoch: [44/100], Step: [2100/6250], Loss: 0.7001 \n",
      "\n",
      "Epoch: [44/100], Step: [2200/6250], Loss: 1.4611 \n",
      "\n",
      "Epoch: [44/100], Step: [2300/6250], Loss: 0.8579 \n",
      "\n",
      "Epoch: [44/100], Step: [2400/6250], Loss: 0.9702 \n",
      "\n",
      "Epoch: [44/100], Step: [2500/6250], Loss: 0.8185 \n",
      "\n",
      "Epoch: [44/100], Step: [2600/6250], Loss: 0.5239 \n",
      "\n",
      "Epoch: [44/100], Step: [2700/6250], Loss: 0.9446 \n",
      "\n",
      "Epoch: [44/100], Step: [2800/6250], Loss: 0.6380 \n",
      "\n",
      "Epoch: [44/100], Step: [2900/6250], Loss: 0.9643 \n",
      "\n",
      "Epoch: [44/100], Step: [3000/6250], Loss: 0.9632 \n",
      "\n",
      "Epoch: [44/100], Step: [3100/6250], Loss: 0.7975 \n",
      "\n",
      "Epoch: [44/100], Step: [3200/6250], Loss: 0.4682 \n",
      "\n",
      "Epoch: [44/100], Step: [3300/6250], Loss: 1.9351 \n",
      "\n",
      "Epoch: [44/100], Step: [3400/6250], Loss: 0.4142 \n",
      "\n",
      "Epoch: [44/100], Step: [3500/6250], Loss: 1.1817 \n",
      "\n",
      "Epoch: [44/100], Step: [3600/6250], Loss: 0.4394 \n",
      "\n",
      "Epoch: [44/100], Step: [3700/6250], Loss: 1.1156 \n",
      "\n",
      "Epoch: [44/100], Step: [3800/6250], Loss: 0.6663 \n",
      "\n",
      "Epoch: [44/100], Step: [3900/6250], Loss: 0.5148 \n",
      "\n",
      "Epoch: [44/100], Step: [4000/6250], Loss: 0.7439 \n",
      "\n",
      "Epoch: [44/100], Step: [4100/6250], Loss: 0.5482 \n",
      "\n",
      "Epoch: [44/100], Step: [4200/6250], Loss: 0.6365 \n",
      "\n",
      "Epoch: [44/100], Step: [4300/6250], Loss: 0.7263 \n",
      "\n",
      "Epoch: [44/100], Step: [4400/6250], Loss: 0.3851 \n",
      "\n",
      "Epoch: [44/100], Step: [4500/6250], Loss: 1.1654 \n",
      "\n",
      "Epoch: [44/100], Step: [4600/6250], Loss: 1.1495 \n",
      "\n",
      "Epoch: [44/100], Step: [4700/6250], Loss: 0.1682 \n",
      "\n",
      "Epoch: [44/100], Step: [4800/6250], Loss: 0.9959 \n",
      "\n",
      "Epoch: [44/100], Step: [4900/6250], Loss: 1.1329 \n",
      "\n",
      "Epoch: [44/100], Step: [5000/6250], Loss: 0.2153 \n",
      "\n",
      "Epoch: [44/100], Step: [5100/6250], Loss: 0.4597 \n",
      "\n",
      "Epoch: [44/100], Step: [5200/6250], Loss: 0.3890 \n",
      "\n",
      "Epoch: [44/100], Step: [5300/6250], Loss: 0.2791 \n",
      "\n",
      "Epoch: [44/100], Step: [5400/6250], Loss: 1.2853 \n",
      "\n",
      "Epoch: [44/100], Step: [5500/6250], Loss: 0.4135 \n",
      "\n",
      "Epoch: [44/100], Step: [5600/6250], Loss: 0.7592 \n",
      "\n",
      "Epoch: [44/100], Step: [5700/6250], Loss: 0.8680 \n",
      "\n",
      "Epoch: [44/100], Step: [5800/6250], Loss: 0.4562 \n",
      "\n",
      "Epoch: [44/100], Step: [5900/6250], Loss: 0.9275 \n",
      "\n",
      "Epoch: [44/100], Step: [6000/6250], Loss: 0.6956 \n",
      "\n",
      "Epoch: [44/100], Step: [6100/6250], Loss: 0.2666 \n",
      "\n",
      "Epoch: [44/100], Step: [6200/6250], Loss: 0.3362 \n",
      "\n",
      "Epoch: [45/100], Step: [100/6250], Loss: 0.9260 \n",
      "\n",
      "Epoch: [45/100], Step: [200/6250], Loss: 0.4813 \n",
      "\n",
      "Epoch: [45/100], Step: [300/6250], Loss: 0.4299 \n",
      "\n",
      "Epoch: [45/100], Step: [400/6250], Loss: 0.3775 \n",
      "\n",
      "Epoch: [45/100], Step: [500/6250], Loss: 0.8185 \n",
      "\n",
      "Epoch: [45/100], Step: [600/6250], Loss: 0.6670 \n",
      "\n",
      "Epoch: [45/100], Step: [700/6250], Loss: 0.9603 \n",
      "\n",
      "Epoch: [45/100], Step: [800/6250], Loss: 0.8199 \n",
      "\n",
      "Epoch: [45/100], Step: [900/6250], Loss: 1.0584 \n",
      "\n",
      "Epoch: [45/100], Step: [1000/6250], Loss: 0.8011 \n",
      "\n",
      "Epoch: [45/100], Step: [1100/6250], Loss: 0.7500 \n",
      "\n",
      "Epoch: [45/100], Step: [1200/6250], Loss: 0.4594 \n",
      "\n",
      "Epoch: [45/100], Step: [1300/6250], Loss: 0.5408 \n",
      "\n",
      "Epoch: [45/100], Step: [1400/6250], Loss: 0.6040 \n",
      "\n",
      "Epoch: [45/100], Step: [1500/6250], Loss: 0.5625 \n",
      "\n",
      "Epoch: [45/100], Step: [1600/6250], Loss: 1.3063 \n",
      "\n",
      "Epoch: [45/100], Step: [1700/6250], Loss: 1.0705 \n",
      "\n",
      "Epoch: [45/100], Step: [1800/6250], Loss: 0.7018 \n",
      "\n",
      "Epoch: [45/100], Step: [1900/6250], Loss: 1.1906 \n",
      "\n",
      "Epoch: [45/100], Step: [2000/6250], Loss: 1.3323 \n",
      "\n",
      "Epoch: [45/100], Step: [2100/6250], Loss: 0.7998 \n",
      "\n",
      "Epoch: [45/100], Step: [2200/6250], Loss: 0.3461 \n",
      "\n",
      "Epoch: [45/100], Step: [2300/6250], Loss: 0.2744 \n",
      "\n",
      "Epoch: [45/100], Step: [2400/6250], Loss: 0.3980 \n",
      "\n",
      "Epoch: [45/100], Step: [2500/6250], Loss: 0.6691 \n",
      "\n",
      "Epoch: [45/100], Step: [2600/6250], Loss: 0.5690 \n",
      "\n",
      "Epoch: [45/100], Step: [2700/6250], Loss: 0.4063 \n",
      "\n",
      "Epoch: [45/100], Step: [2800/6250], Loss: 0.7127 \n",
      "\n",
      "Epoch: [45/100], Step: [2900/6250], Loss: 0.3893 \n",
      "\n",
      "Epoch: [45/100], Step: [3000/6250], Loss: 0.5771 \n",
      "\n",
      "Epoch: [45/100], Step: [3100/6250], Loss: 1.7054 \n",
      "\n",
      "Epoch: [45/100], Step: [3200/6250], Loss: 0.4275 \n",
      "\n",
      "Epoch: [45/100], Step: [3300/6250], Loss: 0.9508 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [45/100], Step: [3400/6250], Loss: 0.3561 \n",
      "\n",
      "Epoch: [45/100], Step: [3500/6250], Loss: 1.4512 \n",
      "\n",
      "Epoch: [45/100], Step: [3600/6250], Loss: 0.6312 \n",
      "\n",
      "Epoch: [45/100], Step: [3700/6250], Loss: 0.3080 \n",
      "\n",
      "Epoch: [45/100], Step: [3800/6250], Loss: 0.4589 \n",
      "\n",
      "Epoch: [45/100], Step: [3900/6250], Loss: 1.5586 \n",
      "\n",
      "Epoch: [45/100], Step: [4000/6250], Loss: 1.0311 \n",
      "\n",
      "Epoch: [45/100], Step: [4100/6250], Loss: 0.1776 \n",
      "\n",
      "Epoch: [45/100], Step: [4200/6250], Loss: 0.9694 \n",
      "\n",
      "Epoch: [45/100], Step: [4300/6250], Loss: 1.0077 \n",
      "\n",
      "Epoch: [45/100], Step: [4400/6250], Loss: 0.3426 \n",
      "\n",
      "Epoch: [45/100], Step: [4500/6250], Loss: 0.7141 \n",
      "\n",
      "Epoch: [45/100], Step: [4600/6250], Loss: 1.3873 \n",
      "\n",
      "Epoch: [45/100], Step: [4700/6250], Loss: 1.1764 \n",
      "\n",
      "Epoch: [45/100], Step: [4800/6250], Loss: 0.6971 \n",
      "\n",
      "Epoch: [45/100], Step: [4900/6250], Loss: 0.5121 \n",
      "\n",
      "Epoch: [45/100], Step: [5000/6250], Loss: 0.6909 \n",
      "\n",
      "Epoch: [45/100], Step: [5100/6250], Loss: 0.4646 \n",
      "\n",
      "Epoch: [45/100], Step: [5200/6250], Loss: 0.4962 \n",
      "\n",
      "Epoch: [45/100], Step: [5300/6250], Loss: 2.5474 \n",
      "\n",
      "Epoch: [45/100], Step: [5400/6250], Loss: 1.7819 \n",
      "\n",
      "Epoch: [45/100], Step: [5500/6250], Loss: 1.2203 \n",
      "\n",
      "Epoch: [45/100], Step: [5600/6250], Loss: 0.7634 \n",
      "\n",
      "Epoch: [45/100], Step: [5700/6250], Loss: 0.9560 \n",
      "\n",
      "Epoch: [45/100], Step: [5800/6250], Loss: 0.6804 \n",
      "\n",
      "Epoch: [45/100], Step: [5900/6250], Loss: 0.7559 \n",
      "\n",
      "Epoch: [45/100], Step: [6000/6250], Loss: 0.9329 \n",
      "\n",
      "Epoch: [45/100], Step: [6100/6250], Loss: 1.5539 \n",
      "\n",
      "Epoch: [45/100], Step: [6200/6250], Loss: 1.5326 \n",
      "\n",
      "Epoch: [46/100], Step: [100/6250], Loss: 1.3095 \n",
      "\n",
      "Epoch: [46/100], Step: [200/6250], Loss: 0.9040 \n",
      "\n",
      "Epoch: [46/100], Step: [300/6250], Loss: 0.6151 \n",
      "\n",
      "Epoch: [46/100], Step: [400/6250], Loss: 1.5444 \n",
      "\n",
      "Epoch: [46/100], Step: [500/6250], Loss: 1.4027 \n",
      "\n",
      "Epoch: [46/100], Step: [600/6250], Loss: 0.4251 \n",
      "\n",
      "Epoch: [46/100], Step: [700/6250], Loss: 0.7756 \n",
      "\n",
      "Epoch: [46/100], Step: [800/6250], Loss: 0.9995 \n",
      "\n",
      "Epoch: [46/100], Step: [900/6250], Loss: 0.6326 \n",
      "\n",
      "Epoch: [46/100], Step: [1000/6250], Loss: 1.0545 \n",
      "\n",
      "Epoch: [46/100], Step: [1100/6250], Loss: 0.4145 \n",
      "\n",
      "Epoch: [46/100], Step: [1200/6250], Loss: 0.3429 \n",
      "\n",
      "Epoch: [46/100], Step: [1300/6250], Loss: 1.0247 \n",
      "\n",
      "Epoch: [46/100], Step: [1400/6250], Loss: 0.8230 \n",
      "\n",
      "Epoch: [46/100], Step: [1500/6250], Loss: 0.4245 \n",
      "\n",
      "Epoch: [46/100], Step: [1600/6250], Loss: 1.0025 \n",
      "\n",
      "Epoch: [46/100], Step: [1700/6250], Loss: 0.9694 \n",
      "\n",
      "Epoch: [46/100], Step: [1800/6250], Loss: 0.7089 \n",
      "\n",
      "Epoch: [46/100], Step: [1900/6250], Loss: 0.5172 \n",
      "\n",
      "Epoch: [46/100], Step: [2000/6250], Loss: 1.0404 \n",
      "\n",
      "Epoch: [46/100], Step: [2100/6250], Loss: 1.5633 \n",
      "\n",
      "Epoch: [46/100], Step: [2200/6250], Loss: 0.4563 \n",
      "\n",
      "Epoch: [46/100], Step: [2300/6250], Loss: 1.1555 \n",
      "\n",
      "Epoch: [46/100], Step: [2400/6250], Loss: 0.6782 \n",
      "\n",
      "Epoch: [46/100], Step: [2500/6250], Loss: 1.1583 \n",
      "\n",
      "Epoch: [46/100], Step: [2600/6250], Loss: 0.8399 \n",
      "\n",
      "Epoch: [46/100], Step: [2700/6250], Loss: 0.3233 \n",
      "\n",
      "Epoch: [46/100], Step: [2800/6250], Loss: 0.8500 \n",
      "\n",
      "Epoch: [46/100], Step: [2900/6250], Loss: 1.1438 \n",
      "\n",
      "Epoch: [46/100], Step: [3000/6250], Loss: 1.0711 \n",
      "\n",
      "Epoch: [46/100], Step: [3100/6250], Loss: 0.7589 \n",
      "\n",
      "Epoch: [46/100], Step: [3200/6250], Loss: 0.2453 \n",
      "\n",
      "Epoch: [46/100], Step: [3300/6250], Loss: 0.7401 \n",
      "\n",
      "Epoch: [46/100], Step: [3400/6250], Loss: 0.5507 \n",
      "\n",
      "Epoch: [46/100], Step: [3500/6250], Loss: 1.1477 \n",
      "\n",
      "Epoch: [46/100], Step: [3600/6250], Loss: 0.2363 \n",
      "\n",
      "Epoch: [46/100], Step: [3700/6250], Loss: 1.1400 \n",
      "\n",
      "Epoch: [46/100], Step: [3800/6250], Loss: 1.0200 \n",
      "\n",
      "Epoch: [46/100], Step: [3900/6250], Loss: 1.0168 \n",
      "\n",
      "Epoch: [46/100], Step: [4000/6250], Loss: 0.6144 \n",
      "\n",
      "Epoch: [46/100], Step: [4100/6250], Loss: 0.3709 \n",
      "\n",
      "Epoch: [46/100], Step: [4200/6250], Loss: 1.1032 \n",
      "\n",
      "Epoch: [46/100], Step: [4300/6250], Loss: 0.7036 \n",
      "\n",
      "Epoch: [46/100], Step: [4400/6250], Loss: 0.2148 \n",
      "\n",
      "Epoch: [46/100], Step: [4500/6250], Loss: 0.6972 \n",
      "\n",
      "Epoch: [46/100], Step: [4600/6250], Loss: 0.7653 \n",
      "\n",
      "Epoch: [46/100], Step: [4700/6250], Loss: 0.9723 \n",
      "\n",
      "Epoch: [46/100], Step: [4800/6250], Loss: 0.4041 \n",
      "\n",
      "Epoch: [46/100], Step: [4900/6250], Loss: 0.9635 \n",
      "\n",
      "Epoch: [46/100], Step: [5000/6250], Loss: 1.0597 \n",
      "\n",
      "Epoch: [46/100], Step: [5100/6250], Loss: 0.6018 \n",
      "\n",
      "Epoch: [46/100], Step: [5200/6250], Loss: 0.4770 \n",
      "\n",
      "Epoch: [46/100], Step: [5300/6250], Loss: 0.3217 \n",
      "\n",
      "Epoch: [46/100], Step: [5400/6250], Loss: 0.7798 \n",
      "\n",
      "Epoch: [46/100], Step: [5500/6250], Loss: 0.5982 \n",
      "\n",
      "Epoch: [46/100], Step: [5600/6250], Loss: 0.9517 \n",
      "\n",
      "Epoch: [46/100], Step: [5700/6250], Loss: 0.7623 \n",
      "\n",
      "Epoch: [46/100], Step: [5800/6250], Loss: 0.3900 \n",
      "\n",
      "Epoch: [46/100], Step: [5900/6250], Loss: 0.4769 \n",
      "\n",
      "Epoch: [46/100], Step: [6000/6250], Loss: 0.8762 \n",
      "\n",
      "Epoch: [46/100], Step: [6100/6250], Loss: 1.0627 \n",
      "\n",
      "Epoch: [46/100], Step: [6200/6250], Loss: 0.2832 \n",
      "\n",
      "Epoch: [47/100], Step: [100/6250], Loss: 0.9541 \n",
      "\n",
      "Epoch: [47/100], Step: [200/6250], Loss: 0.4336 \n",
      "\n",
      "Epoch: [47/100], Step: [300/6250], Loss: 0.8612 \n",
      "\n",
      "Epoch: [47/100], Step: [400/6250], Loss: 0.5679 \n",
      "\n",
      "Epoch: [47/100], Step: [500/6250], Loss: 0.7202 \n",
      "\n",
      "Epoch: [47/100], Step: [600/6250], Loss: 0.8511 \n",
      "\n",
      "Epoch: [47/100], Step: [700/6250], Loss: 0.5363 \n",
      "\n",
      "Epoch: [47/100], Step: [800/6250], Loss: 0.6835 \n",
      "\n",
      "Epoch: [47/100], Step: [900/6250], Loss: 1.7816 \n",
      "\n",
      "Epoch: [47/100], Step: [1000/6250], Loss: 0.7468 \n",
      "\n",
      "Epoch: [47/100], Step: [1100/6250], Loss: 0.4124 \n",
      "\n",
      "Epoch: [47/100], Step: [1200/6250], Loss: 1.3018 \n",
      "\n",
      "Epoch: [47/100], Step: [1300/6250], Loss: 0.5263 \n",
      "\n",
      "Epoch: [47/100], Step: [1400/6250], Loss: 0.7172 \n",
      "\n",
      "Epoch: [47/100], Step: [1500/6250], Loss: 0.3791 \n",
      "\n",
      "Epoch: [47/100], Step: [1600/6250], Loss: 0.2467 \n",
      "\n",
      "Epoch: [47/100], Step: [1700/6250], Loss: 0.9151 \n",
      "\n",
      "Epoch: [47/100], Step: [1800/6250], Loss: 0.7719 \n",
      "\n",
      "Epoch: [47/100], Step: [1900/6250], Loss: 0.6113 \n",
      "\n",
      "Epoch: [47/100], Step: [2000/6250], Loss: 0.4108 \n",
      "\n",
      "Epoch: [47/100], Step: [2100/6250], Loss: 0.2614 \n",
      "\n",
      "Epoch: [47/100], Step: [2200/6250], Loss: 0.5407 \n",
      "\n",
      "Epoch: [47/100], Step: [2300/6250], Loss: 0.6130 \n",
      "\n",
      "Epoch: [47/100], Step: [2400/6250], Loss: 0.6643 \n",
      "\n",
      "Epoch: [47/100], Step: [2500/6250], Loss: 0.2508 \n",
      "\n",
      "Epoch: [47/100], Step: [2600/6250], Loss: 0.7655 \n",
      "\n",
      "Epoch: [47/100], Step: [2700/6250], Loss: 0.3455 \n",
      "\n",
      "Epoch: [47/100], Step: [2800/6250], Loss: 0.8433 \n",
      "\n",
      "Epoch: [47/100], Step: [2900/6250], Loss: 0.1680 \n",
      "\n",
      "Epoch: [47/100], Step: [3000/6250], Loss: 1.2437 \n",
      "\n",
      "Epoch: [47/100], Step: [3100/6250], Loss: 0.9532 \n",
      "\n",
      "Epoch: [47/100], Step: [3200/6250], Loss: 0.6146 \n",
      "\n",
      "Epoch: [47/100], Step: [3300/6250], Loss: 1.0438 \n",
      "\n",
      "Epoch: [47/100], Step: [3400/6250], Loss: 1.1434 \n",
      "\n",
      "Epoch: [47/100], Step: [3500/6250], Loss: 0.8692 \n",
      "\n",
      "Epoch: [47/100], Step: [3600/6250], Loss: 0.8827 \n",
      "\n",
      "Epoch: [47/100], Step: [3700/6250], Loss: 0.5966 \n",
      "\n",
      "Epoch: [47/100], Step: [3800/6250], Loss: 0.3330 \n",
      "\n",
      "Epoch: [47/100], Step: [3900/6250], Loss: 0.4691 \n",
      "\n",
      "Epoch: [47/100], Step: [4000/6250], Loss: 0.7785 \n",
      "\n",
      "Epoch: [47/100], Step: [4100/6250], Loss: 1.4843 \n",
      "\n",
      "Epoch: [47/100], Step: [4200/6250], Loss: 0.7645 \n",
      "\n",
      "Epoch: [47/100], Step: [4300/6250], Loss: 0.7270 \n",
      "\n",
      "Epoch: [47/100], Step: [4400/6250], Loss: 0.3877 \n",
      "\n",
      "Epoch: [47/100], Step: [4500/6250], Loss: 0.5247 \n",
      "\n",
      "Epoch: [47/100], Step: [4600/6250], Loss: 0.4052 \n",
      "\n",
      "Epoch: [47/100], Step: [4700/6250], Loss: 0.6583 \n",
      "\n",
      "Epoch: [47/100], Step: [4800/6250], Loss: 0.5784 \n",
      "\n",
      "Epoch: [47/100], Step: [4900/6250], Loss: 1.1087 \n",
      "\n",
      "Epoch: [47/100], Step: [5000/6250], Loss: 0.7860 \n",
      "\n",
      "Epoch: [47/100], Step: [5100/6250], Loss: 1.3677 \n",
      "\n",
      "Epoch: [47/100], Step: [5200/6250], Loss: 0.9645 \n",
      "\n",
      "Epoch: [47/100], Step: [5300/6250], Loss: 0.3672 \n",
      "\n",
      "Epoch: [47/100], Step: [5400/6250], Loss: 0.6314 \n",
      "\n",
      "Epoch: [47/100], Step: [5500/6250], Loss: 0.5358 \n",
      "\n",
      "Epoch: [47/100], Step: [5600/6250], Loss: 1.1365 \n",
      "\n",
      "Epoch: [47/100], Step: [5700/6250], Loss: 0.6118 \n",
      "\n",
      "Epoch: [47/100], Step: [5800/6250], Loss: 0.9955 \n",
      "\n",
      "Epoch: [47/100], Step: [5900/6250], Loss: 1.5838 \n",
      "\n",
      "Epoch: [47/100], Step: [6000/6250], Loss: 0.5107 \n",
      "\n",
      "Epoch: [47/100], Step: [6100/6250], Loss: 0.8444 \n",
      "\n",
      "Epoch: [47/100], Step: [6200/6250], Loss: 0.9920 \n",
      "\n",
      "Epoch: [48/100], Step: [100/6250], Loss: 1.0992 \n",
      "\n",
      "Epoch: [48/100], Step: [200/6250], Loss: 0.4372 \n",
      "\n",
      "Epoch: [48/100], Step: [300/6250], Loss: 1.3910 \n",
      "\n",
      "Epoch: [48/100], Step: [400/6250], Loss: 0.5473 \n",
      "\n",
      "Epoch: [48/100], Step: [500/6250], Loss: 1.0652 \n",
      "\n",
      "Epoch: [48/100], Step: [600/6250], Loss: 1.2040 \n",
      "\n",
      "Epoch: [48/100], Step: [700/6250], Loss: 0.8567 \n",
      "\n",
      "Epoch: [48/100], Step: [800/6250], Loss: 0.6728 \n",
      "\n",
      "Epoch: [48/100], Step: [900/6250], Loss: 1.3054 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [48/100], Step: [1000/6250], Loss: 0.9404 \n",
      "\n",
      "Epoch: [48/100], Step: [1100/6250], Loss: 0.1613 \n",
      "\n",
      "Epoch: [48/100], Step: [1200/6250], Loss: 1.1159 \n",
      "\n",
      "Epoch: [48/100], Step: [1300/6250], Loss: 0.7847 \n",
      "\n",
      "Epoch: [48/100], Step: [1400/6250], Loss: 0.5231 \n",
      "\n",
      "Epoch: [48/100], Step: [1500/6250], Loss: 0.5734 \n",
      "\n",
      "Epoch: [48/100], Step: [1600/6250], Loss: 0.5561 \n",
      "\n",
      "Epoch: [48/100], Step: [1700/6250], Loss: 0.2735 \n",
      "\n",
      "Epoch: [48/100], Step: [1800/6250], Loss: 0.8584 \n",
      "\n",
      "Epoch: [48/100], Step: [1900/6250], Loss: 0.9537 \n",
      "\n",
      "Epoch: [48/100], Step: [2000/6250], Loss: 0.1834 \n",
      "\n",
      "Epoch: [48/100], Step: [2100/6250], Loss: 2.1091 \n",
      "\n",
      "Epoch: [48/100], Step: [2200/6250], Loss: 0.6520 \n",
      "\n",
      "Epoch: [48/100], Step: [2300/6250], Loss: 0.4840 \n",
      "\n",
      "Epoch: [48/100], Step: [2400/6250], Loss: 0.3457 \n",
      "\n",
      "Epoch: [48/100], Step: [2500/6250], Loss: 0.7607 \n",
      "\n",
      "Epoch: [48/100], Step: [2600/6250], Loss: 0.7160 \n",
      "\n",
      "Epoch: [48/100], Step: [2700/6250], Loss: 0.9069 \n",
      "\n",
      "Epoch: [48/100], Step: [2800/6250], Loss: 0.8566 \n",
      "\n",
      "Epoch: [48/100], Step: [2900/6250], Loss: 0.8199 \n",
      "\n",
      "Epoch: [48/100], Step: [3000/6250], Loss: 0.9637 \n",
      "\n",
      "Epoch: [48/100], Step: [3100/6250], Loss: 0.5783 \n",
      "\n",
      "Epoch: [48/100], Step: [3200/6250], Loss: 0.8988 \n",
      "\n",
      "Epoch: [48/100], Step: [3300/6250], Loss: 0.8553 \n",
      "\n",
      "Epoch: [48/100], Step: [3400/6250], Loss: 1.2054 \n",
      "\n",
      "Epoch: [48/100], Step: [3500/6250], Loss: 1.0686 \n",
      "\n",
      "Epoch: [48/100], Step: [3600/6250], Loss: 1.0620 \n",
      "\n",
      "Epoch: [48/100], Step: [3700/6250], Loss: 0.8165 \n",
      "\n",
      "Epoch: [48/100], Step: [3800/6250], Loss: 1.0045 \n",
      "\n",
      "Epoch: [48/100], Step: [3900/6250], Loss: 0.3213 \n",
      "\n",
      "Epoch: [48/100], Step: [4000/6250], Loss: 0.6415 \n",
      "\n",
      "Epoch: [48/100], Step: [4100/6250], Loss: 0.3800 \n",
      "\n",
      "Epoch: [48/100], Step: [4200/6250], Loss: 0.9531 \n",
      "\n",
      "Epoch: [48/100], Step: [4300/6250], Loss: 0.8044 \n",
      "\n",
      "Epoch: [48/100], Step: [4400/6250], Loss: 0.9378 \n",
      "\n",
      "Epoch: [48/100], Step: [4500/6250], Loss: 0.7137 \n",
      "\n",
      "Epoch: [48/100], Step: [4600/6250], Loss: 0.4038 \n",
      "\n",
      "Epoch: [48/100], Step: [4700/6250], Loss: 0.6587 \n",
      "\n",
      "Epoch: [48/100], Step: [4800/6250], Loss: 0.6336 \n",
      "\n",
      "Epoch: [48/100], Step: [4900/6250], Loss: 0.9403 \n",
      "\n",
      "Epoch: [48/100], Step: [5000/6250], Loss: 0.7372 \n",
      "\n",
      "Epoch: [48/100], Step: [5100/6250], Loss: 0.3076 \n",
      "\n",
      "Epoch: [48/100], Step: [5200/6250], Loss: 0.8170 \n",
      "\n",
      "Epoch: [48/100], Step: [5300/6250], Loss: 0.3358 \n",
      "\n",
      "Epoch: [48/100], Step: [5400/6250], Loss: 1.1210 \n",
      "\n",
      "Epoch: [48/100], Step: [5500/6250], Loss: 0.6020 \n",
      "\n",
      "Epoch: [48/100], Step: [5600/6250], Loss: 0.5781 \n",
      "\n",
      "Epoch: [48/100], Step: [5700/6250], Loss: 0.9036 \n",
      "\n",
      "Epoch: [48/100], Step: [5800/6250], Loss: 0.8342 \n",
      "\n",
      "Epoch: [48/100], Step: [5900/6250], Loss: 1.0901 \n",
      "\n",
      "Epoch: [48/100], Step: [6000/6250], Loss: 0.9364 \n",
      "\n",
      "Epoch: [48/100], Step: [6100/6250], Loss: 0.5215 \n",
      "\n",
      "Epoch: [48/100], Step: [6200/6250], Loss: 0.7434 \n",
      "\n",
      "Epoch: [49/100], Step: [100/6250], Loss: 0.7531 \n",
      "\n",
      "Epoch: [49/100], Step: [200/6250], Loss: 0.7635 \n",
      "\n",
      "Epoch: [49/100], Step: [300/6250], Loss: 0.7143 \n",
      "\n",
      "Epoch: [49/100], Step: [400/6250], Loss: 0.5748 \n",
      "\n",
      "Epoch: [49/100], Step: [500/6250], Loss: 1.1595 \n",
      "\n",
      "Epoch: [49/100], Step: [600/6250], Loss: 0.2467 \n",
      "\n",
      "Epoch: [49/100], Step: [700/6250], Loss: 0.7217 \n",
      "\n",
      "Epoch: [49/100], Step: [800/6250], Loss: 0.8964 \n",
      "\n",
      "Epoch: [49/100], Step: [900/6250], Loss: 1.7016 \n",
      "\n",
      "Epoch: [49/100], Step: [1000/6250], Loss: 0.7888 \n",
      "\n",
      "Epoch: [49/100], Step: [1100/6250], Loss: 1.2647 \n",
      "\n",
      "Epoch: [49/100], Step: [1200/6250], Loss: 0.6375 \n",
      "\n",
      "Epoch: [49/100], Step: [1300/6250], Loss: 0.8157 \n",
      "\n",
      "Epoch: [49/100], Step: [1400/6250], Loss: 0.5439 \n",
      "\n",
      "Epoch: [49/100], Step: [1500/6250], Loss: 0.8938 \n",
      "\n",
      "Epoch: [49/100], Step: [1600/6250], Loss: 0.5744 \n",
      "\n",
      "Epoch: [49/100], Step: [1700/6250], Loss: 0.6383 \n",
      "\n",
      "Epoch: [49/100], Step: [1800/6250], Loss: 0.5550 \n",
      "\n",
      "Epoch: [49/100], Step: [1900/6250], Loss: 0.5951 \n",
      "\n",
      "Epoch: [49/100], Step: [2000/6250], Loss: 0.4728 \n",
      "\n",
      "Epoch: [49/100], Step: [2100/6250], Loss: 0.9445 \n",
      "\n",
      "Epoch: [49/100], Step: [2200/6250], Loss: 0.9291 \n",
      "\n",
      "Epoch: [49/100], Step: [2300/6250], Loss: 1.1440 \n",
      "\n",
      "Epoch: [49/100], Step: [2400/6250], Loss: 0.5706 \n",
      "\n",
      "Epoch: [49/100], Step: [2500/6250], Loss: 0.6548 \n",
      "\n",
      "Epoch: [49/100], Step: [2600/6250], Loss: 0.5888 \n",
      "\n",
      "Epoch: [49/100], Step: [2700/6250], Loss: 1.0252 \n",
      "\n",
      "Epoch: [49/100], Step: [2800/6250], Loss: 0.6923 \n",
      "\n",
      "Epoch: [49/100], Step: [2900/6250], Loss: 0.7739 \n",
      "\n",
      "Epoch: [49/100], Step: [3000/6250], Loss: 1.3232 \n",
      "\n",
      "Epoch: [49/100], Step: [3100/6250], Loss: 0.5529 \n",
      "\n",
      "Epoch: [49/100], Step: [3200/6250], Loss: 0.5414 \n",
      "\n",
      "Epoch: [49/100], Step: [3300/6250], Loss: 0.9363 \n",
      "\n",
      "Epoch: [49/100], Step: [3400/6250], Loss: 0.4205 \n",
      "\n",
      "Epoch: [49/100], Step: [3500/6250], Loss: 0.6951 \n",
      "\n",
      "Epoch: [49/100], Step: [3600/6250], Loss: 0.5419 \n",
      "\n",
      "Epoch: [49/100], Step: [3700/6250], Loss: 0.3886 \n",
      "\n",
      "Epoch: [49/100], Step: [3800/6250], Loss: 1.0407 \n",
      "\n",
      "Epoch: [49/100], Step: [3900/6250], Loss: 1.2057 \n",
      "\n",
      "Epoch: [49/100], Step: [4000/6250], Loss: 1.0530 \n",
      "\n",
      "Epoch: [49/100], Step: [4100/6250], Loss: 1.0157 \n",
      "\n",
      "Epoch: [49/100], Step: [4200/6250], Loss: 1.5517 \n",
      "\n",
      "Epoch: [49/100], Step: [4300/6250], Loss: 0.3792 \n",
      "\n",
      "Epoch: [49/100], Step: [4400/6250], Loss: 1.0596 \n",
      "\n",
      "Epoch: [49/100], Step: [4500/6250], Loss: 0.7394 \n",
      "\n",
      "Epoch: [49/100], Step: [4600/6250], Loss: 0.6232 \n",
      "\n",
      "Epoch: [49/100], Step: [4700/6250], Loss: 0.4867 \n",
      "\n",
      "Epoch: [49/100], Step: [4800/6250], Loss: 1.5307 \n",
      "\n",
      "Epoch: [49/100], Step: [4900/6250], Loss: 0.5479 \n",
      "\n",
      "Epoch: [49/100], Step: [5000/6250], Loss: 0.5901 \n",
      "\n",
      "Epoch: [49/100], Step: [5100/6250], Loss: 0.6337 \n",
      "\n",
      "Epoch: [49/100], Step: [5200/6250], Loss: 0.7314 \n",
      "\n",
      "Epoch: [49/100], Step: [5300/6250], Loss: 2.0695 \n",
      "\n",
      "Epoch: [49/100], Step: [5400/6250], Loss: 0.2846 \n",
      "\n",
      "Epoch: [49/100], Step: [5500/6250], Loss: 0.9623 \n",
      "\n",
      "Epoch: [49/100], Step: [5600/6250], Loss: 0.3282 \n",
      "\n",
      "Epoch: [49/100], Step: [5700/6250], Loss: 0.3161 \n",
      "\n",
      "Epoch: [49/100], Step: [5800/6250], Loss: 1.2677 \n",
      "\n",
      "Epoch: [49/100], Step: [5900/6250], Loss: 0.6994 \n",
      "\n",
      "Epoch: [49/100], Step: [6000/6250], Loss: 0.3326 \n",
      "\n",
      "Epoch: [49/100], Step: [6100/6250], Loss: 0.7445 \n",
      "\n",
      "Epoch: [49/100], Step: [6200/6250], Loss: 1.1343 \n",
      "\n",
      "Epoch: [50/100], Step: [100/6250], Loss: 1.2014 \n",
      "\n",
      "Epoch: [50/100], Step: [200/6250], Loss: 0.4466 \n",
      "\n",
      "Epoch: [50/100], Step: [300/6250], Loss: 1.2086 \n",
      "\n",
      "Epoch: [50/100], Step: [400/6250], Loss: 1.4936 \n",
      "\n",
      "Epoch: [50/100], Step: [500/6250], Loss: 0.3878 \n",
      "\n",
      "Epoch: [50/100], Step: [600/6250], Loss: 1.2596 \n",
      "\n",
      "Epoch: [50/100], Step: [700/6250], Loss: 0.2791 \n",
      "\n",
      "Epoch: [50/100], Step: [800/6250], Loss: 1.0314 \n",
      "\n",
      "Epoch: [50/100], Step: [900/6250], Loss: 0.8043 \n",
      "\n",
      "Epoch: [50/100], Step: [1000/6250], Loss: 0.3670 \n",
      "\n",
      "Epoch: [50/100], Step: [1100/6250], Loss: 0.5738 \n",
      "\n",
      "Epoch: [50/100], Step: [1200/6250], Loss: 0.4007 \n",
      "\n",
      "Epoch: [50/100], Step: [1300/6250], Loss: 1.1865 \n",
      "\n",
      "Epoch: [50/100], Step: [1400/6250], Loss: 0.6594 \n",
      "\n",
      "Epoch: [50/100], Step: [1500/6250], Loss: 0.4651 \n",
      "\n",
      "Epoch: [50/100], Step: [1600/6250], Loss: 0.5254 \n",
      "\n",
      "Epoch: [50/100], Step: [1700/6250], Loss: 0.8205 \n",
      "\n",
      "Epoch: [50/100], Step: [1800/6250], Loss: 0.7246 \n",
      "\n",
      "Epoch: [50/100], Step: [1900/6250], Loss: 1.0544 \n",
      "\n",
      "Epoch: [50/100], Step: [2000/6250], Loss: 1.3685 \n",
      "\n",
      "Epoch: [50/100], Step: [2100/6250], Loss: 0.4399 \n",
      "\n",
      "Epoch: [50/100], Step: [2200/6250], Loss: 0.4367 \n",
      "\n",
      "Epoch: [50/100], Step: [2300/6250], Loss: 0.1301 \n",
      "\n",
      "Epoch: [50/100], Step: [2400/6250], Loss: 0.9658 \n",
      "\n",
      "Epoch: [50/100], Step: [2500/6250], Loss: 0.4826 \n",
      "\n",
      "Epoch: [50/100], Step: [2600/6250], Loss: 2.2695 \n",
      "\n",
      "Epoch: [50/100], Step: [2700/6250], Loss: 1.2970 \n",
      "\n",
      "Epoch: [50/100], Step: [2800/6250], Loss: 0.2022 \n",
      "\n",
      "Epoch: [50/100], Step: [2900/6250], Loss: 1.3215 \n",
      "\n",
      "Epoch: [50/100], Step: [3000/6250], Loss: 0.4928 \n",
      "\n",
      "Epoch: [50/100], Step: [3100/6250], Loss: 1.0056 \n",
      "\n",
      "Epoch: [50/100], Step: [3200/6250], Loss: 1.8378 \n",
      "\n",
      "Epoch: [50/100], Step: [3300/6250], Loss: 0.7208 \n",
      "\n",
      "Epoch: [50/100], Step: [3400/6250], Loss: 0.6834 \n",
      "\n",
      "Epoch: [50/100], Step: [3500/6250], Loss: 0.4218 \n",
      "\n",
      "Epoch: [50/100], Step: [3600/6250], Loss: 0.5520 \n",
      "\n",
      "Epoch: [50/100], Step: [3700/6250], Loss: 1.0616 \n",
      "\n",
      "Epoch: [50/100], Step: [3800/6250], Loss: 0.9430 \n",
      "\n",
      "Epoch: [50/100], Step: [3900/6250], Loss: 0.9490 \n",
      "\n",
      "Epoch: [50/100], Step: [4000/6250], Loss: 0.6470 \n",
      "\n",
      "Epoch: [50/100], Step: [4100/6250], Loss: 0.6193 \n",
      "\n",
      "Epoch: [50/100], Step: [4200/6250], Loss: 0.4949 \n",
      "\n",
      "Epoch: [50/100], Step: [4300/6250], Loss: 0.7149 \n",
      "\n",
      "Epoch: [50/100], Step: [4400/6250], Loss: 0.3528 \n",
      "\n",
      "Epoch: [50/100], Step: [4500/6250], Loss: 0.6416 \n",
      "\n",
      "Epoch: [50/100], Step: [4600/6250], Loss: 1.4298 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [50/100], Step: [4700/6250], Loss: 0.6921 \n",
      "\n",
      "Epoch: [50/100], Step: [4800/6250], Loss: 1.3175 \n",
      "\n",
      "Epoch: [50/100], Step: [4900/6250], Loss: 0.3076 \n",
      "\n",
      "Epoch: [50/100], Step: [5000/6250], Loss: 1.0083 \n",
      "\n",
      "Epoch: [50/100], Step: [5100/6250], Loss: 0.6508 \n",
      "\n",
      "Epoch: [50/100], Step: [5200/6250], Loss: 0.5530 \n",
      "\n",
      "Epoch: [50/100], Step: [5300/6250], Loss: 1.0771 \n",
      "\n",
      "Epoch: [50/100], Step: [5400/6250], Loss: 0.2606 \n",
      "\n",
      "Epoch: [50/100], Step: [5500/6250], Loss: 1.6495 \n",
      "\n",
      "Epoch: [50/100], Step: [5600/6250], Loss: 0.5086 \n",
      "\n",
      "Epoch: [50/100], Step: [5700/6250], Loss: 0.9369 \n",
      "\n",
      "Epoch: [50/100], Step: [5800/6250], Loss: 1.1044 \n",
      "\n",
      "Epoch: [50/100], Step: [5900/6250], Loss: 0.5785 \n",
      "\n",
      "Epoch: [50/100], Step: [6000/6250], Loss: 0.7418 \n",
      "\n",
      "Epoch: [50/100], Step: [6100/6250], Loss: 0.7916 \n",
      "\n",
      "Epoch: [50/100], Step: [6200/6250], Loss: 0.5056 \n",
      "\n",
      "Epoch: [51/100], Step: [100/6250], Loss: 0.5190 \n",
      "\n",
      "Epoch: [51/100], Step: [200/6250], Loss: 0.8111 \n",
      "\n",
      "Epoch: [51/100], Step: [300/6250], Loss: 0.9011 \n",
      "\n",
      "Epoch: [51/100], Step: [400/6250], Loss: 1.8912 \n",
      "\n",
      "Epoch: [51/100], Step: [500/6250], Loss: 0.5818 \n",
      "\n",
      "Epoch: [51/100], Step: [600/6250], Loss: 0.6404 \n",
      "\n",
      "Epoch: [51/100], Step: [700/6250], Loss: 0.6754 \n",
      "\n",
      "Epoch: [51/100], Step: [800/6250], Loss: 1.2724 \n",
      "\n",
      "Epoch: [51/100], Step: [900/6250], Loss: 1.0754 \n",
      "\n",
      "Epoch: [51/100], Step: [1000/6250], Loss: 0.2358 \n",
      "\n",
      "Epoch: [51/100], Step: [1100/6250], Loss: 1.1722 \n",
      "\n",
      "Epoch: [51/100], Step: [1200/6250], Loss: 0.3766 \n",
      "\n",
      "Epoch: [51/100], Step: [1300/6250], Loss: 1.5804 \n",
      "\n",
      "Epoch: [51/100], Step: [1400/6250], Loss: 0.1474 \n",
      "\n",
      "Epoch: [51/100], Step: [1500/6250], Loss: 0.6718 \n",
      "\n",
      "Epoch: [51/100], Step: [1600/6250], Loss: 1.2842 \n",
      "\n",
      "Epoch: [51/100], Step: [1700/6250], Loss: 0.2422 \n",
      "\n",
      "Epoch: [51/100], Step: [1800/6250], Loss: 0.6273 \n",
      "\n",
      "Epoch: [51/100], Step: [1900/6250], Loss: 0.1589 \n",
      "\n",
      "Epoch: [51/100], Step: [2000/6250], Loss: 0.5412 \n",
      "\n",
      "Epoch: [51/100], Step: [2100/6250], Loss: 0.6557 \n",
      "\n",
      "Epoch: [51/100], Step: [2200/6250], Loss: 0.8592 \n",
      "\n",
      "Epoch: [51/100], Step: [2300/6250], Loss: 0.7661 \n",
      "\n",
      "Epoch: [51/100], Step: [2400/6250], Loss: 0.3900 \n",
      "\n",
      "Epoch: [51/100], Step: [2500/6250], Loss: 0.4276 \n",
      "\n",
      "Epoch: [51/100], Step: [2600/6250], Loss: 1.2447 \n",
      "\n",
      "Epoch: [51/100], Step: [2700/6250], Loss: 1.1558 \n",
      "\n",
      "Epoch: [51/100], Step: [2800/6250], Loss: 0.5159 \n",
      "\n",
      "Epoch: [51/100], Step: [2900/6250], Loss: 0.5759 \n",
      "\n",
      "Epoch: [51/100], Step: [3000/6250], Loss: 0.7753 \n",
      "\n",
      "Epoch: [51/100], Step: [3100/6250], Loss: 0.6438 \n",
      "\n",
      "Epoch: [51/100], Step: [3200/6250], Loss: 0.7388 \n",
      "\n",
      "Epoch: [51/100], Step: [3300/6250], Loss: 0.9541 \n",
      "\n",
      "Epoch: [51/100], Step: [3400/6250], Loss: 0.7385 \n",
      "\n",
      "Epoch: [51/100], Step: [3500/6250], Loss: 0.4393 \n",
      "\n",
      "Epoch: [51/100], Step: [3600/6250], Loss: 1.3142 \n",
      "\n",
      "Epoch: [51/100], Step: [3700/6250], Loss: 0.4728 \n",
      "\n",
      "Epoch: [51/100], Step: [3800/6250], Loss: 0.6049 \n",
      "\n",
      "Epoch: [51/100], Step: [3900/6250], Loss: 1.1280 \n",
      "\n",
      "Epoch: [51/100], Step: [4000/6250], Loss: 0.8435 \n",
      "\n",
      "Epoch: [51/100], Step: [4100/6250], Loss: 0.6746 \n",
      "\n",
      "Epoch: [51/100], Step: [4200/6250], Loss: 0.8081 \n",
      "\n",
      "Epoch: [51/100], Step: [4300/6250], Loss: 1.0767 \n",
      "\n",
      "Epoch: [51/100], Step: [4400/6250], Loss: 0.2196 \n",
      "\n",
      "Epoch: [51/100], Step: [4500/6250], Loss: 0.6661 \n",
      "\n",
      "Epoch: [51/100], Step: [4600/6250], Loss: 0.9780 \n",
      "\n",
      "Epoch: [51/100], Step: [4700/6250], Loss: 1.4130 \n",
      "\n",
      "Epoch: [51/100], Step: [4800/6250], Loss: 0.5982 \n",
      "\n",
      "Epoch: [51/100], Step: [4900/6250], Loss: 1.5109 \n",
      "\n",
      "Epoch: [51/100], Step: [5000/6250], Loss: 0.4973 \n",
      "\n",
      "Epoch: [51/100], Step: [5100/6250], Loss: 0.5743 \n",
      "\n",
      "Epoch: [51/100], Step: [5200/6250], Loss: 0.4522 \n",
      "\n",
      "Epoch: [51/100], Step: [5300/6250], Loss: 0.2131 \n",
      "\n",
      "Epoch: [51/100], Step: [5400/6250], Loss: 0.5562 \n",
      "\n",
      "Epoch: [51/100], Step: [5500/6250], Loss: 1.2324 \n",
      "\n",
      "Epoch: [51/100], Step: [5600/6250], Loss: 0.7609 \n",
      "\n",
      "Epoch: [51/100], Step: [5700/6250], Loss: 0.4140 \n",
      "\n",
      "Epoch: [51/100], Step: [5800/6250], Loss: 0.7368 \n",
      "\n",
      "Epoch: [51/100], Step: [5900/6250], Loss: 0.8326 \n",
      "\n",
      "Epoch: [51/100], Step: [6000/6250], Loss: 0.7960 \n",
      "\n",
      "Epoch: [51/100], Step: [6100/6250], Loss: 0.9269 \n",
      "\n",
      "Epoch: [51/100], Step: [6200/6250], Loss: 1.3017 \n",
      "\n",
      "Epoch: [52/100], Step: [100/6250], Loss: 0.4937 \n",
      "\n",
      "Epoch: [52/100], Step: [200/6250], Loss: 0.9649 \n",
      "\n",
      "Epoch: [52/100], Step: [300/6250], Loss: 0.6001 \n",
      "\n",
      "Epoch: [52/100], Step: [400/6250], Loss: 0.6695 \n",
      "\n",
      "Epoch: [52/100], Step: [500/6250], Loss: 0.9735 \n",
      "\n",
      "Epoch: [52/100], Step: [600/6250], Loss: 0.5087 \n",
      "\n",
      "Epoch: [52/100], Step: [700/6250], Loss: 1.6833 \n",
      "\n",
      "Epoch: [52/100], Step: [800/6250], Loss: 0.8960 \n",
      "\n",
      "Epoch: [52/100], Step: [900/6250], Loss: 0.7517 \n",
      "\n",
      "Epoch: [52/100], Step: [1000/6250], Loss: 0.8488 \n",
      "\n",
      "Epoch: [52/100], Step: [1100/6250], Loss: 1.2533 \n",
      "\n",
      "Epoch: [52/100], Step: [1200/6250], Loss: 0.6519 \n",
      "\n",
      "Epoch: [52/100], Step: [1300/6250], Loss: 0.6634 \n",
      "\n",
      "Epoch: [52/100], Step: [1400/6250], Loss: 0.3184 \n",
      "\n",
      "Epoch: [52/100], Step: [1500/6250], Loss: 0.1932 \n",
      "\n",
      "Epoch: [52/100], Step: [1600/6250], Loss: 0.4147 \n",
      "\n",
      "Epoch: [52/100], Step: [1700/6250], Loss: 0.6368 \n",
      "\n",
      "Epoch: [52/100], Step: [1800/6250], Loss: 0.3179 \n",
      "\n",
      "Epoch: [52/100], Step: [1900/6250], Loss: 0.5533 \n",
      "\n",
      "Epoch: [52/100], Step: [2000/6250], Loss: 0.9851 \n",
      "\n",
      "Epoch: [52/100], Step: [2100/6250], Loss: 0.3904 \n",
      "\n",
      "Epoch: [52/100], Step: [2200/6250], Loss: 0.7837 \n",
      "\n",
      "Epoch: [52/100], Step: [2300/6250], Loss: 0.8247 \n",
      "\n",
      "Epoch: [52/100], Step: [2400/6250], Loss: 0.8463 \n",
      "\n",
      "Epoch: [52/100], Step: [2500/6250], Loss: 1.4421 \n",
      "\n",
      "Epoch: [52/100], Step: [2600/6250], Loss: 0.1885 \n",
      "\n",
      "Epoch: [52/100], Step: [2700/6250], Loss: 0.8802 \n",
      "\n",
      "Epoch: [52/100], Step: [2800/6250], Loss: 0.7939 \n",
      "\n",
      "Epoch: [52/100], Step: [2900/6250], Loss: 1.2006 \n",
      "\n",
      "Epoch: [52/100], Step: [3000/6250], Loss: 0.1589 \n",
      "\n",
      "Epoch: [52/100], Step: [3100/6250], Loss: 0.8962 \n",
      "\n",
      "Epoch: [52/100], Step: [3200/6250], Loss: 0.6904 \n",
      "\n",
      "Epoch: [52/100], Step: [3300/6250], Loss: 0.4505 \n",
      "\n",
      "Epoch: [52/100], Step: [3400/6250], Loss: 0.9195 \n",
      "\n",
      "Epoch: [52/100], Step: [3500/6250], Loss: 0.6005 \n",
      "\n",
      "Epoch: [52/100], Step: [3600/6250], Loss: 0.4731 \n",
      "\n",
      "Epoch: [52/100], Step: [3700/6250], Loss: 0.8910 \n",
      "\n",
      "Epoch: [52/100], Step: [3800/6250], Loss: 0.5969 \n",
      "\n",
      "Epoch: [52/100], Step: [3900/6250], Loss: 0.4763 \n",
      "\n",
      "Epoch: [52/100], Step: [4000/6250], Loss: 0.5181 \n",
      "\n",
      "Epoch: [52/100], Step: [4100/6250], Loss: 0.9059 \n",
      "\n",
      "Epoch: [52/100], Step: [4200/6250], Loss: 0.6945 \n",
      "\n",
      "Epoch: [52/100], Step: [4300/6250], Loss: 1.7307 \n",
      "\n",
      "Epoch: [52/100], Step: [4400/6250], Loss: 0.7494 \n",
      "\n",
      "Epoch: [52/100], Step: [4500/6250], Loss: 0.4279 \n",
      "\n",
      "Epoch: [52/100], Step: [4600/6250], Loss: 0.6043 \n",
      "\n",
      "Epoch: [52/100], Step: [4700/6250], Loss: 0.3756 \n",
      "\n",
      "Epoch: [52/100], Step: [4800/6250], Loss: 0.8562 \n",
      "\n",
      "Epoch: [52/100], Step: [4900/6250], Loss: 1.0432 \n",
      "\n",
      "Epoch: [52/100], Step: [5000/6250], Loss: 0.6173 \n",
      "\n",
      "Epoch: [52/100], Step: [5100/6250], Loss: 0.8866 \n",
      "\n",
      "Epoch: [52/100], Step: [5200/6250], Loss: 1.5356 \n",
      "\n",
      "Epoch: [52/100], Step: [5300/6250], Loss: 0.3063 \n",
      "\n",
      "Epoch: [52/100], Step: [5400/6250], Loss: 0.4037 \n",
      "\n",
      "Epoch: [52/100], Step: [5500/6250], Loss: 0.4705 \n",
      "\n",
      "Epoch: [52/100], Step: [5600/6250], Loss: 0.6577 \n",
      "\n",
      "Epoch: [52/100], Step: [5700/6250], Loss: 1.0675 \n",
      "\n",
      "Epoch: [52/100], Step: [5800/6250], Loss: 0.9000 \n",
      "\n",
      "Epoch: [52/100], Step: [5900/6250], Loss: 0.6845 \n",
      "\n",
      "Epoch: [52/100], Step: [6000/6250], Loss: 0.1359 \n",
      "\n",
      "Epoch: [52/100], Step: [6100/6250], Loss: 0.6210 \n",
      "\n",
      "Epoch: [52/100], Step: [6200/6250], Loss: 0.5140 \n",
      "\n",
      "Epoch: [53/100], Step: [100/6250], Loss: 1.0099 \n",
      "\n",
      "Epoch: [53/100], Step: [200/6250], Loss: 0.8492 \n",
      "\n",
      "Epoch: [53/100], Step: [300/6250], Loss: 0.3154 \n",
      "\n",
      "Epoch: [53/100], Step: [400/6250], Loss: 0.1360 \n",
      "\n",
      "Epoch: [53/100], Step: [500/6250], Loss: 0.8890 \n",
      "\n",
      "Epoch: [53/100], Step: [600/6250], Loss: 0.6854 \n",
      "\n",
      "Epoch: [53/100], Step: [700/6250], Loss: 1.6725 \n",
      "\n",
      "Epoch: [53/100], Step: [800/6250], Loss: 1.6988 \n",
      "\n",
      "Epoch: [53/100], Step: [900/6250], Loss: 0.5434 \n",
      "\n",
      "Epoch: [53/100], Step: [1000/6250], Loss: 0.5904 \n",
      "\n",
      "Epoch: [53/100], Step: [1100/6250], Loss: 0.5913 \n",
      "\n",
      "Epoch: [53/100], Step: [1200/6250], Loss: 0.6548 \n",
      "\n",
      "Epoch: [53/100], Step: [1300/6250], Loss: 1.2941 \n",
      "\n",
      "Epoch: [53/100], Step: [1400/6250], Loss: 0.6891 \n",
      "\n",
      "Epoch: [53/100], Step: [1500/6250], Loss: 1.0520 \n",
      "\n",
      "Epoch: [53/100], Step: [1600/6250], Loss: 0.6213 \n",
      "\n",
      "Epoch: [53/100], Step: [1700/6250], Loss: 1.5247 \n",
      "\n",
      "Epoch: [53/100], Step: [1800/6250], Loss: 0.5846 \n",
      "\n",
      "Epoch: [53/100], Step: [1900/6250], Loss: 0.6921 \n",
      "\n",
      "Epoch: [53/100], Step: [2000/6250], Loss: 0.5796 \n",
      "\n",
      "Epoch: [53/100], Step: [2100/6250], Loss: 1.8045 \n",
      "\n",
      "Epoch: [53/100], Step: [2200/6250], Loss: 0.2400 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [53/100], Step: [2300/6250], Loss: 1.0313 \n",
      "\n",
      "Epoch: [53/100], Step: [2400/6250], Loss: 0.6882 \n",
      "\n",
      "Epoch: [53/100], Step: [2500/6250], Loss: 0.6867 \n",
      "\n",
      "Epoch: [53/100], Step: [2600/6250], Loss: 0.2618 \n",
      "\n",
      "Epoch: [53/100], Step: [2700/6250], Loss: 1.2742 \n",
      "\n",
      "Epoch: [53/100], Step: [2800/6250], Loss: 0.4345 \n",
      "\n",
      "Epoch: [53/100], Step: [2900/6250], Loss: 0.5535 \n",
      "\n",
      "Epoch: [53/100], Step: [3000/6250], Loss: 1.1229 \n",
      "\n",
      "Epoch: [53/100], Step: [3100/6250], Loss: 1.0010 \n",
      "\n",
      "Epoch: [53/100], Step: [3200/6250], Loss: 0.3311 \n",
      "\n",
      "Epoch: [53/100], Step: [3300/6250], Loss: 0.3429 \n",
      "\n",
      "Epoch: [53/100], Step: [3400/6250], Loss: 0.8555 \n",
      "\n",
      "Epoch: [53/100], Step: [3500/6250], Loss: 0.7799 \n",
      "\n",
      "Epoch: [53/100], Step: [3600/6250], Loss: 0.4208 \n",
      "\n",
      "Epoch: [53/100], Step: [3700/6250], Loss: 0.4163 \n",
      "\n",
      "Epoch: [53/100], Step: [3800/6250], Loss: 1.7348 \n",
      "\n",
      "Epoch: [53/100], Step: [3900/6250], Loss: 0.3488 \n",
      "\n",
      "Epoch: [53/100], Step: [4000/6250], Loss: 1.4476 \n",
      "\n",
      "Epoch: [53/100], Step: [4100/6250], Loss: 1.0212 \n",
      "\n",
      "Epoch: [53/100], Step: [4200/6250], Loss: 1.1510 \n",
      "\n",
      "Epoch: [53/100], Step: [4300/6250], Loss: 0.6970 \n",
      "\n",
      "Epoch: [53/100], Step: [4400/6250], Loss: 0.2606 \n",
      "\n",
      "Epoch: [53/100], Step: [4500/6250], Loss: 0.9720 \n",
      "\n",
      "Epoch: [53/100], Step: [4600/6250], Loss: 0.8649 \n",
      "\n",
      "Epoch: [53/100], Step: [4700/6250], Loss: 0.9598 \n",
      "\n",
      "Epoch: [53/100], Step: [4800/6250], Loss: 0.6354 \n",
      "\n",
      "Epoch: [53/100], Step: [4900/6250], Loss: 1.2538 \n",
      "\n",
      "Epoch: [53/100], Step: [5000/6250], Loss: 1.0398 \n",
      "\n",
      "Epoch: [53/100], Step: [5100/6250], Loss: 0.8355 \n",
      "\n",
      "Epoch: [53/100], Step: [5200/6250], Loss: 0.8208 \n",
      "\n",
      "Epoch: [53/100], Step: [5300/6250], Loss: 0.2882 \n",
      "\n",
      "Epoch: [53/100], Step: [5400/6250], Loss: 0.2278 \n",
      "\n",
      "Epoch: [53/100], Step: [5500/6250], Loss: 1.1027 \n",
      "\n",
      "Epoch: [53/100], Step: [5600/6250], Loss: 0.6978 \n",
      "\n",
      "Epoch: [53/100], Step: [5700/6250], Loss: 0.2689 \n",
      "\n",
      "Epoch: [53/100], Step: [5800/6250], Loss: 0.9552 \n",
      "\n",
      "Epoch: [53/100], Step: [5900/6250], Loss: 0.2816 \n",
      "\n",
      "Epoch: [53/100], Step: [6000/6250], Loss: 0.2585 \n",
      "\n",
      "Epoch: [53/100], Step: [6100/6250], Loss: 0.7553 \n",
      "\n",
      "Epoch: [53/100], Step: [6200/6250], Loss: 0.4414 \n",
      "\n",
      "Epoch: [54/100], Step: [100/6250], Loss: 0.6856 \n",
      "\n",
      "Epoch: [54/100], Step: [200/6250], Loss: 1.0539 \n",
      "\n",
      "Epoch: [54/100], Step: [300/6250], Loss: 1.2068 \n",
      "\n",
      "Epoch: [54/100], Step: [400/6250], Loss: 1.0425 \n",
      "\n",
      "Epoch: [54/100], Step: [500/6250], Loss: 0.6259 \n",
      "\n",
      "Epoch: [54/100], Step: [600/6250], Loss: 0.6265 \n",
      "\n",
      "Epoch: [54/100], Step: [700/6250], Loss: 0.8621 \n",
      "\n",
      "Epoch: [54/100], Step: [800/6250], Loss: 0.5702 \n",
      "\n",
      "Epoch: [54/100], Step: [900/6250], Loss: 0.7154 \n",
      "\n",
      "Epoch: [54/100], Step: [1000/6250], Loss: 0.3122 \n",
      "\n",
      "Epoch: [54/100], Step: [1100/6250], Loss: 0.3714 \n",
      "\n",
      "Epoch: [54/100], Step: [1200/6250], Loss: 0.5261 \n",
      "\n",
      "Epoch: [54/100], Step: [1300/6250], Loss: 0.3967 \n",
      "\n",
      "Epoch: [54/100], Step: [1400/6250], Loss: 0.3506 \n",
      "\n",
      "Epoch: [54/100], Step: [1500/6250], Loss: 0.4495 \n",
      "\n",
      "Epoch: [54/100], Step: [1600/6250], Loss: 0.3037 \n",
      "\n",
      "Epoch: [54/100], Step: [1700/6250], Loss: 0.9547 \n",
      "\n",
      "Epoch: [54/100], Step: [1800/6250], Loss: 0.6462 \n",
      "\n",
      "Epoch: [54/100], Step: [1900/6250], Loss: 0.7515 \n",
      "\n",
      "Epoch: [54/100], Step: [2000/6250], Loss: 0.7636 \n",
      "\n",
      "Epoch: [54/100], Step: [2100/6250], Loss: 0.5052 \n",
      "\n",
      "Epoch: [54/100], Step: [2200/6250], Loss: 0.2455 \n",
      "\n",
      "Epoch: [54/100], Step: [2300/6250], Loss: 0.6442 \n",
      "\n",
      "Epoch: [54/100], Step: [2400/6250], Loss: 0.9436 \n",
      "\n",
      "Epoch: [54/100], Step: [2500/6250], Loss: 0.7215 \n",
      "\n",
      "Epoch: [54/100], Step: [2600/6250], Loss: 0.3310 \n",
      "\n",
      "Epoch: [54/100], Step: [2700/6250], Loss: 0.7621 \n",
      "\n",
      "Epoch: [54/100], Step: [2800/6250], Loss: 0.5058 \n",
      "\n",
      "Epoch: [54/100], Step: [2900/6250], Loss: 0.2403 \n",
      "\n",
      "Epoch: [54/100], Step: [3000/6250], Loss: 0.2013 \n",
      "\n",
      "Epoch: [54/100], Step: [3100/6250], Loss: 0.5620 \n",
      "\n",
      "Epoch: [54/100], Step: [3200/6250], Loss: 0.2009 \n",
      "\n",
      "Epoch: [54/100], Step: [3300/6250], Loss: 0.6181 \n",
      "\n",
      "Epoch: [54/100], Step: [3400/6250], Loss: 0.8075 \n",
      "\n",
      "Epoch: [54/100], Step: [3500/6250], Loss: 0.7442 \n",
      "\n",
      "Epoch: [54/100], Step: [3600/6250], Loss: 0.4120 \n",
      "\n",
      "Epoch: [54/100], Step: [3700/6250], Loss: 0.6377 \n",
      "\n",
      "Epoch: [54/100], Step: [3800/6250], Loss: 0.2906 \n",
      "\n",
      "Epoch: [54/100], Step: [3900/6250], Loss: 0.7427 \n",
      "\n",
      "Epoch: [54/100], Step: [4000/6250], Loss: 0.4884 \n",
      "\n",
      "Epoch: [54/100], Step: [4100/6250], Loss: 0.7776 \n",
      "\n",
      "Epoch: [54/100], Step: [4200/6250], Loss: 0.4615 \n",
      "\n",
      "Epoch: [54/100], Step: [4300/6250], Loss: 0.6921 \n",
      "\n",
      "Epoch: [54/100], Step: [4400/6250], Loss: 0.8885 \n",
      "\n",
      "Epoch: [54/100], Step: [4500/6250], Loss: 1.1448 \n",
      "\n",
      "Epoch: [54/100], Step: [4600/6250], Loss: 1.1256 \n",
      "\n",
      "Epoch: [54/100], Step: [4700/6250], Loss: 0.5217 \n",
      "\n",
      "Epoch: [54/100], Step: [4800/6250], Loss: 1.2030 \n",
      "\n",
      "Epoch: [54/100], Step: [4900/6250], Loss: 0.4226 \n",
      "\n",
      "Epoch: [54/100], Step: [5000/6250], Loss: 1.4818 \n",
      "\n",
      "Epoch: [54/100], Step: [5100/6250], Loss: 0.6034 \n",
      "\n",
      "Epoch: [54/100], Step: [5200/6250], Loss: 1.7602 \n",
      "\n",
      "Epoch: [54/100], Step: [5300/6250], Loss: 0.2552 \n",
      "\n",
      "Epoch: [54/100], Step: [5400/6250], Loss: 0.6334 \n",
      "\n",
      "Epoch: [54/100], Step: [5500/6250], Loss: 0.2999 \n",
      "\n",
      "Epoch: [54/100], Step: [5600/6250], Loss: 0.5006 \n",
      "\n",
      "Epoch: [54/100], Step: [5700/6250], Loss: 0.3570 \n",
      "\n",
      "Epoch: [54/100], Step: [5800/6250], Loss: 0.2559 \n",
      "\n",
      "Epoch: [54/100], Step: [5900/6250], Loss: 1.2620 \n",
      "\n",
      "Epoch: [54/100], Step: [6000/6250], Loss: 0.5378 \n",
      "\n",
      "Epoch: [54/100], Step: [6100/6250], Loss: 0.2976 \n",
      "\n",
      "Epoch: [54/100], Step: [6200/6250], Loss: 0.5522 \n",
      "\n",
      "Epoch: [55/100], Step: [100/6250], Loss: 0.3251 \n",
      "\n",
      "Epoch: [55/100], Step: [200/6250], Loss: 0.5161 \n",
      "\n",
      "Epoch: [55/100], Step: [300/6250], Loss: 0.4461 \n",
      "\n",
      "Epoch: [55/100], Step: [400/6250], Loss: 0.4350 \n",
      "\n",
      "Epoch: [55/100], Step: [500/6250], Loss: 1.0316 \n",
      "\n",
      "Epoch: [55/100], Step: [600/6250], Loss: 0.3341 \n",
      "\n",
      "Epoch: [55/100], Step: [700/6250], Loss: 0.2893 \n",
      "\n",
      "Epoch: [55/100], Step: [800/6250], Loss: 0.1557 \n",
      "\n",
      "Epoch: [55/100], Step: [900/6250], Loss: 0.3013 \n",
      "\n",
      "Epoch: [55/100], Step: [1000/6250], Loss: 0.6392 \n",
      "\n",
      "Epoch: [55/100], Step: [1100/6250], Loss: 0.8881 \n",
      "\n",
      "Epoch: [55/100], Step: [1200/6250], Loss: 0.1995 \n",
      "\n",
      "Epoch: [55/100], Step: [1300/6250], Loss: 0.7679 \n",
      "\n",
      "Epoch: [55/100], Step: [1400/6250], Loss: 0.6725 \n",
      "\n",
      "Epoch: [55/100], Step: [1500/6250], Loss: 0.9355 \n",
      "\n",
      "Epoch: [55/100], Step: [1600/6250], Loss: 0.2637 \n",
      "\n",
      "Epoch: [55/100], Step: [1700/6250], Loss: 0.8604 \n",
      "\n",
      "Epoch: [55/100], Step: [1800/6250], Loss: 0.2919 \n",
      "\n",
      "Epoch: [55/100], Step: [1900/6250], Loss: 0.7605 \n",
      "\n",
      "Epoch: [55/100], Step: [2000/6250], Loss: 0.2648 \n",
      "\n",
      "Epoch: [55/100], Step: [2100/6250], Loss: 0.5677 \n",
      "\n",
      "Epoch: [55/100], Step: [2200/6250], Loss: 0.8704 \n",
      "\n",
      "Epoch: [55/100], Step: [2300/6250], Loss: 0.9076 \n",
      "\n",
      "Epoch: [55/100], Step: [2400/6250], Loss: 0.5789 \n",
      "\n",
      "Epoch: [55/100], Step: [2500/6250], Loss: 0.6733 \n",
      "\n",
      "Epoch: [55/100], Step: [2600/6250], Loss: 0.6233 \n",
      "\n",
      "Epoch: [55/100], Step: [2700/6250], Loss: 0.6093 \n",
      "\n",
      "Epoch: [55/100], Step: [2800/6250], Loss: 0.3645 \n",
      "\n",
      "Epoch: [55/100], Step: [2900/6250], Loss: 0.4652 \n",
      "\n",
      "Epoch: [55/100], Step: [3000/6250], Loss: 0.4970 \n",
      "\n",
      "Epoch: [55/100], Step: [3100/6250], Loss: 0.7414 \n",
      "\n",
      "Epoch: [55/100], Step: [3200/6250], Loss: 0.8170 \n",
      "\n",
      "Epoch: [55/100], Step: [3300/6250], Loss: 1.8501 \n",
      "\n",
      "Epoch: [55/100], Step: [3400/6250], Loss: 0.5579 \n",
      "\n",
      "Epoch: [55/100], Step: [3500/6250], Loss: 0.2687 \n",
      "\n",
      "Epoch: [55/100], Step: [3600/6250], Loss: 1.7900 \n",
      "\n",
      "Epoch: [55/100], Step: [3700/6250], Loss: 1.1687 \n",
      "\n",
      "Epoch: [55/100], Step: [3800/6250], Loss: 0.5937 \n",
      "\n",
      "Epoch: [55/100], Step: [3900/6250], Loss: 0.1184 \n",
      "\n",
      "Epoch: [55/100], Step: [4000/6250], Loss: 0.5926 \n",
      "\n",
      "Epoch: [55/100], Step: [4100/6250], Loss: 1.4500 \n",
      "\n",
      "Epoch: [55/100], Step: [4200/6250], Loss: 0.8970 \n",
      "\n",
      "Epoch: [55/100], Step: [4300/6250], Loss: 1.0806 \n",
      "\n",
      "Epoch: [55/100], Step: [4400/6250], Loss: 0.7537 \n",
      "\n",
      "Epoch: [55/100], Step: [4500/6250], Loss: 0.2160 \n",
      "\n",
      "Epoch: [55/100], Step: [4600/6250], Loss: 0.7670 \n",
      "\n",
      "Epoch: [55/100], Step: [4700/6250], Loss: 0.5017 \n",
      "\n",
      "Epoch: [55/100], Step: [4800/6250], Loss: 0.7079 \n",
      "\n",
      "Epoch: [55/100], Step: [4900/6250], Loss: 1.1043 \n",
      "\n",
      "Epoch: [55/100], Step: [5000/6250], Loss: 0.6218 \n",
      "\n",
      "Epoch: [55/100], Step: [5100/6250], Loss: 0.7762 \n",
      "\n",
      "Epoch: [55/100], Step: [5200/6250], Loss: 0.5845 \n",
      "\n",
      "Epoch: [55/100], Step: [5300/6250], Loss: 0.6088 \n",
      "\n",
      "Epoch: [55/100], Step: [5400/6250], Loss: 0.8660 \n",
      "\n",
      "Epoch: [55/100], Step: [5500/6250], Loss: 0.2473 \n",
      "\n",
      "Epoch: [55/100], Step: [5600/6250], Loss: 0.8224 \n",
      "\n",
      "Epoch: [55/100], Step: [5700/6250], Loss: 0.4869 \n",
      "\n",
      "Epoch: [55/100], Step: [5800/6250], Loss: 0.2366 \n",
      "\n",
      "Epoch: [55/100], Step: [5900/6250], Loss: 0.8761 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [55/100], Step: [6000/6250], Loss: 0.2939 \n",
      "\n",
      "Epoch: [55/100], Step: [6100/6250], Loss: 0.8342 \n",
      "\n",
      "Epoch: [55/100], Step: [6200/6250], Loss: 0.1670 \n",
      "\n",
      "Epoch: [56/100], Step: [100/6250], Loss: 0.2723 \n",
      "\n",
      "Epoch: [56/100], Step: [200/6250], Loss: 0.6762 \n",
      "\n",
      "Epoch: [56/100], Step: [300/6250], Loss: 0.2918 \n",
      "\n",
      "Epoch: [56/100], Step: [400/6250], Loss: 0.5606 \n",
      "\n",
      "Epoch: [56/100], Step: [500/6250], Loss: 0.6383 \n",
      "\n",
      "Epoch: [56/100], Step: [600/6250], Loss: 0.5968 \n",
      "\n",
      "Epoch: [56/100], Step: [700/6250], Loss: 0.8880 \n",
      "\n",
      "Epoch: [56/100], Step: [800/6250], Loss: 0.7422 \n",
      "\n",
      "Epoch: [56/100], Step: [900/6250], Loss: 0.7336 \n",
      "\n",
      "Epoch: [56/100], Step: [1000/6250], Loss: 0.5436 \n",
      "\n",
      "Epoch: [56/100], Step: [1100/6250], Loss: 0.2099 \n",
      "\n",
      "Epoch: [56/100], Step: [1200/6250], Loss: 1.5770 \n",
      "\n",
      "Epoch: [56/100], Step: [1300/6250], Loss: 0.4041 \n",
      "\n",
      "Epoch: [56/100], Step: [1400/6250], Loss: 0.4400 \n",
      "\n",
      "Epoch: [56/100], Step: [1500/6250], Loss: 0.8369 \n",
      "\n",
      "Epoch: [56/100], Step: [1600/6250], Loss: 0.5902 \n",
      "\n",
      "Epoch: [56/100], Step: [1700/6250], Loss: 0.5198 \n",
      "\n",
      "Epoch: [56/100], Step: [1800/6250], Loss: 0.4889 \n",
      "\n",
      "Epoch: [56/100], Step: [1900/6250], Loss: 0.2923 \n",
      "\n",
      "Epoch: [56/100], Step: [2000/6250], Loss: 0.5075 \n",
      "\n",
      "Epoch: [56/100], Step: [2100/6250], Loss: 0.3308 \n",
      "\n",
      "Epoch: [56/100], Step: [2200/6250], Loss: 0.1366 \n",
      "\n",
      "Epoch: [56/100], Step: [2300/6250], Loss: 0.2954 \n",
      "\n",
      "Epoch: [56/100], Step: [2400/6250], Loss: 0.4535 \n",
      "\n",
      "Epoch: [56/100], Step: [2500/6250], Loss: 0.2098 \n",
      "\n",
      "Epoch: [56/100], Step: [2600/6250], Loss: 0.5677 \n",
      "\n",
      "Epoch: [56/100], Step: [2700/6250], Loss: 0.6517 \n",
      "\n",
      "Epoch: [56/100], Step: [2800/6250], Loss: 0.6557 \n",
      "\n",
      "Epoch: [56/100], Step: [2900/6250], Loss: 1.5254 \n",
      "\n",
      "Epoch: [56/100], Step: [3000/6250], Loss: 0.4787 \n",
      "\n",
      "Epoch: [56/100], Step: [3100/6250], Loss: 0.5645 \n",
      "\n",
      "Epoch: [56/100], Step: [3200/6250], Loss: 0.6249 \n",
      "\n",
      "Epoch: [56/100], Step: [3300/6250], Loss: 1.0212 \n",
      "\n",
      "Epoch: [56/100], Step: [3400/6250], Loss: 0.4506 \n",
      "\n",
      "Epoch: [56/100], Step: [3500/6250], Loss: 0.6615 \n",
      "\n",
      "Epoch: [56/100], Step: [3600/6250], Loss: 1.0127 \n",
      "\n",
      "Epoch: [56/100], Step: [3700/6250], Loss: 1.0550 \n",
      "\n",
      "Epoch: [56/100], Step: [3800/6250], Loss: 0.2751 \n",
      "\n",
      "Epoch: [56/100], Step: [3900/6250], Loss: 1.3514 \n",
      "\n",
      "Epoch: [56/100], Step: [4000/6250], Loss: 0.5534 \n",
      "\n",
      "Epoch: [56/100], Step: [4100/6250], Loss: 1.3458 \n",
      "\n",
      "Epoch: [56/100], Step: [4200/6250], Loss: 1.0891 \n",
      "\n",
      "Epoch: [56/100], Step: [4300/6250], Loss: 1.2947 \n",
      "\n",
      "Epoch: [56/100], Step: [4400/6250], Loss: 0.7349 \n",
      "\n",
      "Epoch: [56/100], Step: [4500/6250], Loss: 1.5578 \n",
      "\n",
      "Epoch: [56/100], Step: [4600/6250], Loss: 1.0793 \n",
      "\n",
      "Epoch: [56/100], Step: [4700/6250], Loss: 0.4044 \n",
      "\n",
      "Epoch: [56/100], Step: [4800/6250], Loss: 0.7963 \n",
      "\n",
      "Epoch: [56/100], Step: [4900/6250], Loss: 0.6177 \n",
      "\n",
      "Epoch: [56/100], Step: [5000/6250], Loss: 0.6490 \n",
      "\n",
      "Epoch: [56/100], Step: [5100/6250], Loss: 1.3257 \n",
      "\n",
      "Epoch: [56/100], Step: [5200/6250], Loss: 1.1150 \n",
      "\n",
      "Epoch: [56/100], Step: [5300/6250], Loss: 0.4684 \n",
      "\n",
      "Epoch: [56/100], Step: [5400/6250], Loss: 0.7853 \n",
      "\n",
      "Epoch: [56/100], Step: [5500/6250], Loss: 1.5402 \n",
      "\n",
      "Epoch: [56/100], Step: [5600/6250], Loss: 0.2325 \n",
      "\n",
      "Epoch: [56/100], Step: [5700/6250], Loss: 0.5590 \n",
      "\n",
      "Epoch: [56/100], Step: [5800/6250], Loss: 0.3780 \n",
      "\n",
      "Epoch: [56/100], Step: [5900/6250], Loss: 1.2289 \n",
      "\n",
      "Epoch: [56/100], Step: [6000/6250], Loss: 1.0872 \n",
      "\n",
      "Epoch: [56/100], Step: [6100/6250], Loss: 0.4046 \n",
      "\n",
      "Epoch: [56/100], Step: [6200/6250], Loss: 0.4687 \n",
      "\n",
      "Epoch: [57/100], Step: [100/6250], Loss: 0.8332 \n",
      "\n",
      "Epoch: [57/100], Step: [200/6250], Loss: 1.1693 \n",
      "\n",
      "Epoch: [57/100], Step: [300/6250], Loss: 0.3225 \n",
      "\n",
      "Epoch: [57/100], Step: [400/6250], Loss: 0.5024 \n",
      "\n",
      "Epoch: [57/100], Step: [500/6250], Loss: 0.8030 \n",
      "\n",
      "Epoch: [57/100], Step: [600/6250], Loss: 0.8649 \n",
      "\n",
      "Epoch: [57/100], Step: [700/6250], Loss: 0.2484 \n",
      "\n",
      "Epoch: [57/100], Step: [800/6250], Loss: 0.5253 \n",
      "\n",
      "Epoch: [57/100], Step: [900/6250], Loss: 1.0364 \n",
      "\n",
      "Epoch: [57/100], Step: [1000/6250], Loss: 0.6304 \n",
      "\n",
      "Epoch: [57/100], Step: [1100/6250], Loss: 0.5029 \n",
      "\n",
      "Epoch: [57/100], Step: [1200/6250], Loss: 0.5562 \n",
      "\n",
      "Epoch: [57/100], Step: [1300/6250], Loss: 0.6660 \n",
      "\n",
      "Epoch: [57/100], Step: [1400/6250], Loss: 0.3230 \n",
      "\n",
      "Epoch: [57/100], Step: [1500/6250], Loss: 0.3283 \n",
      "\n",
      "Epoch: [57/100], Step: [1600/6250], Loss: 1.2208 \n",
      "\n",
      "Epoch: [57/100], Step: [1700/6250], Loss: 0.6433 \n",
      "\n",
      "Epoch: [57/100], Step: [1800/6250], Loss: 0.6602 \n",
      "\n",
      "Epoch: [57/100], Step: [1900/6250], Loss: 0.4423 \n",
      "\n",
      "Epoch: [57/100], Step: [2000/6250], Loss: 0.6433 \n",
      "\n",
      "Epoch: [57/100], Step: [2100/6250], Loss: 0.4987 \n",
      "\n",
      "Epoch: [57/100], Step: [2200/6250], Loss: 0.7267 \n",
      "\n",
      "Epoch: [57/100], Step: [2300/6250], Loss: 1.1133 \n",
      "\n",
      "Epoch: [57/100], Step: [2400/6250], Loss: 0.9493 \n",
      "\n",
      "Epoch: [57/100], Step: [2500/6250], Loss: 0.9119 \n",
      "\n",
      "Epoch: [57/100], Step: [2600/6250], Loss: 1.0160 \n",
      "\n",
      "Epoch: [57/100], Step: [2700/6250], Loss: 0.2581 \n",
      "\n",
      "Epoch: [57/100], Step: [2800/6250], Loss: 0.6968 \n",
      "\n",
      "Epoch: [57/100], Step: [2900/6250], Loss: 0.5951 \n",
      "\n",
      "Epoch: [57/100], Step: [3000/6250], Loss: 0.4341 \n",
      "\n",
      "Epoch: [57/100], Step: [3100/6250], Loss: 0.2391 \n",
      "\n",
      "Epoch: [57/100], Step: [3200/6250], Loss: 0.5088 \n",
      "\n",
      "Epoch: [57/100], Step: [3300/6250], Loss: 0.9620 \n",
      "\n",
      "Epoch: [57/100], Step: [3400/6250], Loss: 0.6509 \n",
      "\n",
      "Epoch: [57/100], Step: [3500/6250], Loss: 0.2996 \n",
      "\n",
      "Epoch: [57/100], Step: [3600/6250], Loss: 0.2550 \n",
      "\n",
      "Epoch: [57/100], Step: [3700/6250], Loss: 0.5509 \n",
      "\n",
      "Epoch: [57/100], Step: [3800/6250], Loss: 0.1829 \n",
      "\n",
      "Epoch: [57/100], Step: [3900/6250], Loss: 1.0775 \n",
      "\n",
      "Epoch: [57/100], Step: [4000/6250], Loss: 0.3462 \n",
      "\n",
      "Epoch: [57/100], Step: [4100/6250], Loss: 0.8042 \n",
      "\n",
      "Epoch: [57/100], Step: [4200/6250], Loss: 0.4467 \n",
      "\n",
      "Epoch: [57/100], Step: [4300/6250], Loss: 0.9855 \n",
      "\n",
      "Epoch: [57/100], Step: [4400/6250], Loss: 0.7727 \n",
      "\n",
      "Epoch: [57/100], Step: [4500/6250], Loss: 0.2556 \n",
      "\n",
      "Epoch: [57/100], Step: [4600/6250], Loss: 0.7195 \n",
      "\n",
      "Epoch: [57/100], Step: [4700/6250], Loss: 1.5066 \n",
      "\n",
      "Epoch: [57/100], Step: [4800/6250], Loss: 0.9666 \n",
      "\n",
      "Epoch: [57/100], Step: [4900/6250], Loss: 0.2229 \n",
      "\n",
      "Epoch: [57/100], Step: [5000/6250], Loss: 0.7685 \n",
      "\n",
      "Epoch: [57/100], Step: [5100/6250], Loss: 1.3316 \n",
      "\n",
      "Epoch: [57/100], Step: [5200/6250], Loss: 0.6775 \n",
      "\n",
      "Epoch: [57/100], Step: [5300/6250], Loss: 0.5670 \n",
      "\n",
      "Epoch: [57/100], Step: [5400/6250], Loss: 0.3253 \n",
      "\n",
      "Epoch: [57/100], Step: [5500/6250], Loss: 1.3095 \n",
      "\n",
      "Epoch: [57/100], Step: [5600/6250], Loss: 0.8992 \n",
      "\n",
      "Epoch: [57/100], Step: [5700/6250], Loss: 0.1670 \n",
      "\n",
      "Epoch: [57/100], Step: [5800/6250], Loss: 0.2263 \n",
      "\n",
      "Epoch: [57/100], Step: [5900/6250], Loss: 1.4679 \n",
      "\n",
      "Epoch: [57/100], Step: [6000/6250], Loss: 0.3793 \n",
      "\n",
      "Epoch: [57/100], Step: [6100/6250], Loss: 0.4459 \n",
      "\n",
      "Epoch: [57/100], Step: [6200/6250], Loss: 0.7764 \n",
      "\n",
      "Epoch: [58/100], Step: [100/6250], Loss: 0.6511 \n",
      "\n",
      "Epoch: [58/100], Step: [200/6250], Loss: 0.4887 \n",
      "\n",
      "Epoch: [58/100], Step: [300/6250], Loss: 0.3381 \n",
      "\n",
      "Epoch: [58/100], Step: [400/6250], Loss: 0.8028 \n",
      "\n",
      "Epoch: [58/100], Step: [500/6250], Loss: 0.5191 \n",
      "\n",
      "Epoch: [58/100], Step: [600/6250], Loss: 0.5184 \n",
      "\n",
      "Epoch: [58/100], Step: [700/6250], Loss: 0.5108 \n",
      "\n",
      "Epoch: [58/100], Step: [800/6250], Loss: 0.6198 \n",
      "\n",
      "Epoch: [58/100], Step: [900/6250], Loss: 0.5832 \n",
      "\n",
      "Epoch: [58/100], Step: [1000/6250], Loss: 1.1191 \n",
      "\n",
      "Epoch: [58/100], Step: [1100/6250], Loss: 1.2275 \n",
      "\n",
      "Epoch: [58/100], Step: [1200/6250], Loss: 0.6918 \n",
      "\n",
      "Epoch: [58/100], Step: [1300/6250], Loss: 0.7899 \n",
      "\n",
      "Epoch: [58/100], Step: [1400/6250], Loss: 0.7195 \n",
      "\n",
      "Epoch: [58/100], Step: [1500/6250], Loss: 0.5920 \n",
      "\n",
      "Epoch: [58/100], Step: [1600/6250], Loss: 1.0310 \n",
      "\n",
      "Epoch: [58/100], Step: [1700/6250], Loss: 1.0696 \n",
      "\n",
      "Epoch: [58/100], Step: [1800/6250], Loss: 0.3203 \n",
      "\n",
      "Epoch: [58/100], Step: [1900/6250], Loss: 1.5803 \n",
      "\n",
      "Epoch: [58/100], Step: [2000/6250], Loss: 0.6784 \n",
      "\n",
      "Epoch: [58/100], Step: [2100/6250], Loss: 0.4426 \n",
      "\n",
      "Epoch: [58/100], Step: [2200/6250], Loss: 0.6203 \n",
      "\n",
      "Epoch: [58/100], Step: [2300/6250], Loss: 0.3988 \n",
      "\n",
      "Epoch: [58/100], Step: [2400/6250], Loss: 0.4296 \n",
      "\n",
      "Epoch: [58/100], Step: [2500/6250], Loss: 0.9265 \n",
      "\n",
      "Epoch: [58/100], Step: [2600/6250], Loss: 1.0514 \n",
      "\n",
      "Epoch: [58/100], Step: [2700/6250], Loss: 0.4895 \n",
      "\n",
      "Epoch: [58/100], Step: [2800/6250], Loss: 0.7529 \n",
      "\n",
      "Epoch: [58/100], Step: [2900/6250], Loss: 0.3339 \n",
      "\n",
      "Epoch: [58/100], Step: [3000/6250], Loss: 0.4693 \n",
      "\n",
      "Epoch: [58/100], Step: [3100/6250], Loss: 1.1912 \n",
      "\n",
      "Epoch: [58/100], Step: [3200/6250], Loss: 0.5510 \n",
      "\n",
      "Epoch: [58/100], Step: [3300/6250], Loss: 0.1858 \n",
      "\n",
      "Epoch: [58/100], Step: [3400/6250], Loss: 0.2781 \n",
      "\n",
      "Epoch: [58/100], Step: [3500/6250], Loss: 0.8419 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [58/100], Step: [3600/6250], Loss: 0.2143 \n",
      "\n",
      "Epoch: [58/100], Step: [3700/6250], Loss: 0.2866 \n",
      "\n",
      "Epoch: [58/100], Step: [3800/6250], Loss: 0.9713 \n",
      "\n",
      "Epoch: [58/100], Step: [3900/6250], Loss: 1.2248 \n",
      "\n",
      "Epoch: [58/100], Step: [4000/6250], Loss: 0.5641 \n",
      "\n",
      "Epoch: [58/100], Step: [4100/6250], Loss: 0.4703 \n",
      "\n",
      "Epoch: [58/100], Step: [4200/6250], Loss: 0.7014 \n",
      "\n",
      "Epoch: [58/100], Step: [4300/6250], Loss: 0.2847 \n",
      "\n",
      "Epoch: [58/100], Step: [4400/6250], Loss: 1.1201 \n",
      "\n",
      "Epoch: [58/100], Step: [4500/6250], Loss: 0.6489 \n",
      "\n",
      "Epoch: [58/100], Step: [4600/6250], Loss: 0.2795 \n",
      "\n",
      "Epoch: [58/100], Step: [4700/6250], Loss: 0.6733 \n",
      "\n",
      "Epoch: [58/100], Step: [4800/6250], Loss: 0.2738 \n",
      "\n",
      "Epoch: [58/100], Step: [4900/6250], Loss: 0.6710 \n",
      "\n",
      "Epoch: [58/100], Step: [5000/6250], Loss: 0.4793 \n",
      "\n",
      "Epoch: [58/100], Step: [5100/6250], Loss: 0.3982 \n",
      "\n",
      "Epoch: [58/100], Step: [5200/6250], Loss: 0.6276 \n",
      "\n",
      "Epoch: [58/100], Step: [5300/6250], Loss: 0.7253 \n",
      "\n",
      "Epoch: [58/100], Step: [5400/6250], Loss: 0.5321 \n",
      "\n",
      "Epoch: [58/100], Step: [5500/6250], Loss: 1.2587 \n",
      "\n",
      "Epoch: [58/100], Step: [5600/6250], Loss: 0.7823 \n",
      "\n",
      "Epoch: [58/100], Step: [5700/6250], Loss: 1.0756 \n",
      "\n",
      "Epoch: [58/100], Step: [5800/6250], Loss: 0.3746 \n",
      "\n",
      "Epoch: [58/100], Step: [5900/6250], Loss: 0.7886 \n",
      "\n",
      "Epoch: [58/100], Step: [6000/6250], Loss: 0.4000 \n",
      "\n",
      "Epoch: [58/100], Step: [6100/6250], Loss: 0.3285 \n",
      "\n",
      "Epoch: [58/100], Step: [6200/6250], Loss: 0.3214 \n",
      "\n",
      "Epoch: [59/100], Step: [100/6250], Loss: 0.3775 \n",
      "\n",
      "Epoch: [59/100], Step: [200/6250], Loss: 0.6692 \n",
      "\n",
      "Epoch: [59/100], Step: [300/6250], Loss: 0.7846 \n",
      "\n",
      "Epoch: [59/100], Step: [400/6250], Loss: 1.5167 \n",
      "\n",
      "Epoch: [59/100], Step: [500/6250], Loss: 0.7213 \n",
      "\n",
      "Epoch: [59/100], Step: [600/6250], Loss: 0.6263 \n",
      "\n",
      "Epoch: [59/100], Step: [700/6250], Loss: 0.3154 \n",
      "\n",
      "Epoch: [59/100], Step: [800/6250], Loss: 0.3844 \n",
      "\n",
      "Epoch: [59/100], Step: [900/6250], Loss: 0.8544 \n",
      "\n",
      "Epoch: [59/100], Step: [1000/6250], Loss: 0.1992 \n",
      "\n",
      "Epoch: [59/100], Step: [1100/6250], Loss: 0.3857 \n",
      "\n",
      "Epoch: [59/100], Step: [1200/6250], Loss: 1.0703 \n",
      "\n",
      "Epoch: [59/100], Step: [1300/6250], Loss: 0.6329 \n",
      "\n",
      "Epoch: [59/100], Step: [1400/6250], Loss: 0.4650 \n",
      "\n",
      "Epoch: [59/100], Step: [1500/6250], Loss: 0.3051 \n",
      "\n",
      "Epoch: [59/100], Step: [1600/6250], Loss: 0.8161 \n",
      "\n",
      "Epoch: [59/100], Step: [1700/6250], Loss: 0.3332 \n",
      "\n",
      "Epoch: [59/100], Step: [1800/6250], Loss: 1.0582 \n",
      "\n",
      "Epoch: [59/100], Step: [1900/6250], Loss: 0.4943 \n",
      "\n",
      "Epoch: [59/100], Step: [2000/6250], Loss: 0.6558 \n",
      "\n",
      "Epoch: [59/100], Step: [2100/6250], Loss: 0.6614 \n",
      "\n",
      "Epoch: [59/100], Step: [2200/6250], Loss: 0.1682 \n",
      "\n",
      "Epoch: [59/100], Step: [2300/6250], Loss: 0.5793 \n",
      "\n",
      "Epoch: [59/100], Step: [2400/6250], Loss: 0.5082 \n",
      "\n",
      "Epoch: [59/100], Step: [2500/6250], Loss: 1.2793 \n",
      "\n",
      "Epoch: [59/100], Step: [2600/6250], Loss: 0.5772 \n",
      "\n",
      "Epoch: [59/100], Step: [2700/6250], Loss: 0.4939 \n",
      "\n",
      "Epoch: [59/100], Step: [2800/6250], Loss: 0.6609 \n",
      "\n",
      "Epoch: [59/100], Step: [2900/6250], Loss: 1.0216 \n",
      "\n",
      "Epoch: [59/100], Step: [3000/6250], Loss: 0.9795 \n",
      "\n",
      "Epoch: [59/100], Step: [3100/6250], Loss: 0.8865 \n",
      "\n",
      "Epoch: [59/100], Step: [3200/6250], Loss: 0.6949 \n",
      "\n",
      "Epoch: [59/100], Step: [3300/6250], Loss: 1.2720 \n",
      "\n",
      "Epoch: [59/100], Step: [3400/6250], Loss: 0.2581 \n",
      "\n",
      "Epoch: [59/100], Step: [3500/6250], Loss: 1.7148 \n",
      "\n",
      "Epoch: [59/100], Step: [3600/6250], Loss: 0.6547 \n",
      "\n",
      "Epoch: [59/100], Step: [3700/6250], Loss: 0.5638 \n",
      "\n",
      "Epoch: [59/100], Step: [3800/6250], Loss: 0.9422 \n",
      "\n",
      "Epoch: [59/100], Step: [3900/6250], Loss: 1.0169 \n",
      "\n",
      "Epoch: [59/100], Step: [4000/6250], Loss: 0.3773 \n",
      "\n",
      "Epoch: [59/100], Step: [4100/6250], Loss: 0.5463 \n",
      "\n",
      "Epoch: [59/100], Step: [4200/6250], Loss: 0.4616 \n",
      "\n",
      "Epoch: [59/100], Step: [4300/6250], Loss: 0.4602 \n",
      "\n",
      "Epoch: [59/100], Step: [4400/6250], Loss: 1.0323 \n",
      "\n",
      "Epoch: [59/100], Step: [4500/6250], Loss: 1.3832 \n",
      "\n",
      "Epoch: [59/100], Step: [4600/6250], Loss: 0.0957 \n",
      "\n",
      "Epoch: [59/100], Step: [4700/6250], Loss: 0.7279 \n",
      "\n",
      "Epoch: [59/100], Step: [4800/6250], Loss: 1.1012 \n",
      "\n",
      "Epoch: [59/100], Step: [4900/6250], Loss: 1.2024 \n",
      "\n",
      "Epoch: [59/100], Step: [5000/6250], Loss: 0.1919 \n",
      "\n",
      "Epoch: [59/100], Step: [5100/6250], Loss: 0.5189 \n",
      "\n",
      "Epoch: [59/100], Step: [5200/6250], Loss: 1.2678 \n",
      "\n",
      "Epoch: [59/100], Step: [5300/6250], Loss: 0.6867 \n",
      "\n",
      "Epoch: [59/100], Step: [5400/6250], Loss: 0.6639 \n",
      "\n",
      "Epoch: [59/100], Step: [5500/6250], Loss: 0.3714 \n",
      "\n",
      "Epoch: [59/100], Step: [5600/6250], Loss: 1.0490 \n",
      "\n",
      "Epoch: [59/100], Step: [5700/6250], Loss: 0.6558 \n",
      "\n",
      "Epoch: [59/100], Step: [5800/6250], Loss: 0.3941 \n",
      "\n",
      "Epoch: [59/100], Step: [5900/6250], Loss: 0.4793 \n",
      "\n",
      "Epoch: [59/100], Step: [6000/6250], Loss: 0.3580 \n",
      "\n",
      "Epoch: [59/100], Step: [6100/6250], Loss: 0.6159 \n",
      "\n",
      "Epoch: [59/100], Step: [6200/6250], Loss: 0.3976 \n",
      "\n",
      "Epoch: [60/100], Step: [100/6250], Loss: 0.8682 \n",
      "\n",
      "Epoch: [60/100], Step: [200/6250], Loss: 0.2431 \n",
      "\n",
      "Epoch: [60/100], Step: [300/6250], Loss: 0.7599 \n",
      "\n",
      "Epoch: [60/100], Step: [400/6250], Loss: 0.4554 \n",
      "\n",
      "Epoch: [60/100], Step: [500/6250], Loss: 0.3252 \n",
      "\n",
      "Epoch: [60/100], Step: [600/6250], Loss: 0.1629 \n",
      "\n",
      "Epoch: [60/100], Step: [700/6250], Loss: 0.9843 \n",
      "\n",
      "Epoch: [60/100], Step: [800/6250], Loss: 1.1736 \n",
      "\n",
      "Epoch: [60/100], Step: [900/6250], Loss: 1.1921 \n",
      "\n",
      "Epoch: [60/100], Step: [1000/6250], Loss: 0.2626 \n",
      "\n",
      "Epoch: [60/100], Step: [1100/6250], Loss: 0.5574 \n",
      "\n",
      "Epoch: [60/100], Step: [1200/6250], Loss: 0.6215 \n",
      "\n",
      "Epoch: [60/100], Step: [1300/6250], Loss: 0.4082 \n",
      "\n",
      "Epoch: [60/100], Step: [1400/6250], Loss: 0.5493 \n",
      "\n",
      "Epoch: [60/100], Step: [1500/6250], Loss: 0.7462 \n",
      "\n",
      "Epoch: [60/100], Step: [1600/6250], Loss: 1.0316 \n",
      "\n",
      "Epoch: [60/100], Step: [1700/6250], Loss: 0.3288 \n",
      "\n",
      "Epoch: [60/100], Step: [1800/6250], Loss: 0.4783 \n",
      "\n",
      "Epoch: [60/100], Step: [1900/6250], Loss: 0.8420 \n",
      "\n",
      "Epoch: [60/100], Step: [2000/6250], Loss: 0.3073 \n",
      "\n",
      "Epoch: [60/100], Step: [2100/6250], Loss: 0.4758 \n",
      "\n",
      "Epoch: [60/100], Step: [2200/6250], Loss: 0.3610 \n",
      "\n",
      "Epoch: [60/100], Step: [2300/6250], Loss: 0.5932 \n",
      "\n",
      "Epoch: [60/100], Step: [2400/6250], Loss: 1.0928 \n",
      "\n",
      "Epoch: [60/100], Step: [2500/6250], Loss: 0.6990 \n",
      "\n",
      "Epoch: [60/100], Step: [2600/6250], Loss: 0.7090 \n",
      "\n",
      "Epoch: [60/100], Step: [2700/6250], Loss: 1.0464 \n",
      "\n",
      "Epoch: [60/100], Step: [2800/6250], Loss: 0.9068 \n",
      "\n",
      "Epoch: [60/100], Step: [2900/6250], Loss: 0.5368 \n",
      "\n",
      "Epoch: [60/100], Step: [3000/6250], Loss: 1.9793 \n",
      "\n",
      "Epoch: [60/100], Step: [3100/6250], Loss: 1.0483 \n",
      "\n",
      "Epoch: [60/100], Step: [3200/6250], Loss: 0.7145 \n",
      "\n",
      "Epoch: [60/100], Step: [3300/6250], Loss: 0.7913 \n",
      "\n",
      "Epoch: [60/100], Step: [3400/6250], Loss: 0.4081 \n",
      "\n",
      "Epoch: [60/100], Step: [3500/6250], Loss: 0.7853 \n",
      "\n",
      "Epoch: [60/100], Step: [3600/6250], Loss: 1.1944 \n",
      "\n",
      "Epoch: [60/100], Step: [3700/6250], Loss: 0.3289 \n",
      "\n",
      "Epoch: [60/100], Step: [3800/6250], Loss: 0.4194 \n",
      "\n",
      "Epoch: [60/100], Step: [3900/6250], Loss: 0.6780 \n",
      "\n",
      "Epoch: [60/100], Step: [4000/6250], Loss: 0.3574 \n",
      "\n",
      "Epoch: [60/100], Step: [4100/6250], Loss: 0.3292 \n",
      "\n",
      "Epoch: [60/100], Step: [4200/6250], Loss: 0.1751 \n",
      "\n",
      "Epoch: [60/100], Step: [4300/6250], Loss: 0.7196 \n",
      "\n",
      "Epoch: [60/100], Step: [4400/6250], Loss: 0.5114 \n",
      "\n",
      "Epoch: [60/100], Step: [4500/6250], Loss: 0.3110 \n",
      "\n",
      "Epoch: [60/100], Step: [4600/6250], Loss: 0.9383 \n",
      "\n",
      "Epoch: [60/100], Step: [4700/6250], Loss: 0.2692 \n",
      "\n",
      "Epoch: [60/100], Step: [4800/6250], Loss: 0.2639 \n",
      "\n",
      "Epoch: [60/100], Step: [4900/6250], Loss: 1.0740 \n",
      "\n",
      "Epoch: [60/100], Step: [5000/6250], Loss: 1.1054 \n",
      "\n",
      "Epoch: [60/100], Step: [5100/6250], Loss: 1.0304 \n",
      "\n",
      "Epoch: [60/100], Step: [5200/6250], Loss: 0.7967 \n",
      "\n",
      "Epoch: [60/100], Step: [5300/6250], Loss: 0.5395 \n",
      "\n",
      "Epoch: [60/100], Step: [5400/6250], Loss: 0.5581 \n",
      "\n",
      "Epoch: [60/100], Step: [5500/6250], Loss: 1.0311 \n",
      "\n",
      "Epoch: [60/100], Step: [5600/6250], Loss: 0.6918 \n",
      "\n",
      "Epoch: [60/100], Step: [5700/6250], Loss: 0.3422 \n",
      "\n",
      "Epoch: [60/100], Step: [5800/6250], Loss: 0.2484 \n",
      "\n",
      "Epoch: [60/100], Step: [5900/6250], Loss: 0.5428 \n",
      "\n",
      "Epoch: [60/100], Step: [6000/6250], Loss: 0.4675 \n",
      "\n",
      "Epoch: [60/100], Step: [6100/6250], Loss: 0.4842 \n",
      "\n",
      "Epoch: [60/100], Step: [6200/6250], Loss: 1.2469 \n",
      "\n",
      "Epoch: [61/100], Step: [100/6250], Loss: 0.2557 \n",
      "\n",
      "Epoch: [61/100], Step: [200/6250], Loss: 0.5256 \n",
      "\n",
      "Epoch: [61/100], Step: [300/6250], Loss: 0.9668 \n",
      "\n",
      "Epoch: [61/100], Step: [400/6250], Loss: 0.4494 \n",
      "\n",
      "Epoch: [61/100], Step: [500/6250], Loss: 0.2631 \n",
      "\n",
      "Epoch: [61/100], Step: [600/6250], Loss: 0.7044 \n",
      "\n",
      "Epoch: [61/100], Step: [700/6250], Loss: 0.3660 \n",
      "\n",
      "Epoch: [61/100], Step: [800/6250], Loss: 0.1727 \n",
      "\n",
      "Epoch: [61/100], Step: [900/6250], Loss: 1.3101 \n",
      "\n",
      "Epoch: [61/100], Step: [1000/6250], Loss: 0.3935 \n",
      "\n",
      "Epoch: [61/100], Step: [1100/6250], Loss: 0.4408 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [61/100], Step: [1200/6250], Loss: 0.3994 \n",
      "\n",
      "Epoch: [61/100], Step: [1300/6250], Loss: 0.9212 \n",
      "\n",
      "Epoch: [61/100], Step: [1400/6250], Loss: 0.0502 \n",
      "\n",
      "Epoch: [61/100], Step: [1500/6250], Loss: 0.9046 \n",
      "\n",
      "Epoch: [61/100], Step: [1600/6250], Loss: 0.8774 \n",
      "\n",
      "Epoch: [61/100], Step: [1700/6250], Loss: 0.9892 \n",
      "\n",
      "Epoch: [61/100], Step: [1800/6250], Loss: 0.7391 \n",
      "\n",
      "Epoch: [61/100], Step: [1900/6250], Loss: 0.7494 \n",
      "\n",
      "Epoch: [61/100], Step: [2000/6250], Loss: 0.3406 \n",
      "\n",
      "Epoch: [61/100], Step: [2100/6250], Loss: 0.3389 \n",
      "\n",
      "Epoch: [61/100], Step: [2200/6250], Loss: 0.4744 \n",
      "\n",
      "Epoch: [61/100], Step: [2300/6250], Loss: 0.6177 \n",
      "\n",
      "Epoch: [61/100], Step: [2400/6250], Loss: 0.3313 \n",
      "\n",
      "Epoch: [61/100], Step: [2500/6250], Loss: 1.2987 \n",
      "\n",
      "Epoch: [61/100], Step: [2600/6250], Loss: 0.3313 \n",
      "\n",
      "Epoch: [61/100], Step: [2700/6250], Loss: 0.1738 \n",
      "\n",
      "Epoch: [61/100], Step: [2800/6250], Loss: 0.7759 \n",
      "\n",
      "Epoch: [61/100], Step: [2900/6250], Loss: 1.2225 \n",
      "\n",
      "Epoch: [61/100], Step: [3000/6250], Loss: 0.4825 \n",
      "\n",
      "Epoch: [61/100], Step: [3100/6250], Loss: 0.9141 \n",
      "\n",
      "Epoch: [61/100], Step: [3200/6250], Loss: 0.3835 \n",
      "\n",
      "Epoch: [61/100], Step: [3300/6250], Loss: 0.6321 \n",
      "\n",
      "Epoch: [61/100], Step: [3400/6250], Loss: 0.3231 \n",
      "\n",
      "Epoch: [61/100], Step: [3500/6250], Loss: 0.9017 \n",
      "\n",
      "Epoch: [61/100], Step: [3600/6250], Loss: 0.6826 \n",
      "\n",
      "Epoch: [61/100], Step: [3700/6250], Loss: 0.4205 \n",
      "\n",
      "Epoch: [61/100], Step: [3800/6250], Loss: 0.5925 \n",
      "\n",
      "Epoch: [61/100], Step: [3900/6250], Loss: 0.7780 \n",
      "\n",
      "Epoch: [61/100], Step: [4000/6250], Loss: 0.3816 \n",
      "\n",
      "Epoch: [61/100], Step: [4100/6250], Loss: 0.3210 \n",
      "\n",
      "Epoch: [61/100], Step: [4200/6250], Loss: 0.7715 \n",
      "\n",
      "Epoch: [61/100], Step: [4300/6250], Loss: 0.4590 \n",
      "\n",
      "Epoch: [61/100], Step: [4400/6250], Loss: 1.3441 \n",
      "\n",
      "Epoch: [61/100], Step: [4500/6250], Loss: 0.2605 \n",
      "\n",
      "Epoch: [61/100], Step: [4600/6250], Loss: 0.8426 \n",
      "\n",
      "Epoch: [61/100], Step: [4700/6250], Loss: 0.7422 \n",
      "\n",
      "Epoch: [61/100], Step: [4800/6250], Loss: 0.5756 \n",
      "\n",
      "Epoch: [61/100], Step: [4900/6250], Loss: 1.0511 \n",
      "\n",
      "Epoch: [61/100], Step: [5000/6250], Loss: 1.1458 \n",
      "\n",
      "Epoch: [61/100], Step: [5100/6250], Loss: 0.6856 \n",
      "\n",
      "Epoch: [61/100], Step: [5200/6250], Loss: 0.5543 \n",
      "\n",
      "Epoch: [61/100], Step: [5300/6250], Loss: 0.1382 \n",
      "\n",
      "Epoch: [61/100], Step: [5400/6250], Loss: 0.9566 \n",
      "\n",
      "Epoch: [61/100], Step: [5500/6250], Loss: 0.3269 \n",
      "\n",
      "Epoch: [61/100], Step: [5600/6250], Loss: 0.9555 \n",
      "\n",
      "Epoch: [61/100], Step: [5700/6250], Loss: 0.7759 \n",
      "\n",
      "Epoch: [61/100], Step: [5800/6250], Loss: 0.5190 \n",
      "\n",
      "Epoch: [61/100], Step: [5900/6250], Loss: 0.7097 \n",
      "\n",
      "Epoch: [61/100], Step: [6000/6250], Loss: 0.5260 \n",
      "\n",
      "Epoch: [61/100], Step: [6100/6250], Loss: 0.5244 \n",
      "\n",
      "Epoch: [61/100], Step: [6200/6250], Loss: 1.1142 \n",
      "\n",
      "Epoch: [62/100], Step: [100/6250], Loss: 1.1930 \n",
      "\n",
      "Epoch: [62/100], Step: [200/6250], Loss: 0.1897 \n",
      "\n",
      "Epoch: [62/100], Step: [300/6250], Loss: 0.6578 \n",
      "\n",
      "Epoch: [62/100], Step: [400/6250], Loss: 0.5437 \n",
      "\n",
      "Epoch: [62/100], Step: [500/6250], Loss: 0.6983 \n",
      "\n",
      "Epoch: [62/100], Step: [600/6250], Loss: 1.2934 \n",
      "\n",
      "Epoch: [62/100], Step: [700/6250], Loss: 0.3582 \n",
      "\n",
      "Epoch: [62/100], Step: [800/6250], Loss: 0.8258 \n",
      "\n",
      "Epoch: [62/100], Step: [900/6250], Loss: 0.8704 \n",
      "\n",
      "Epoch: [62/100], Step: [1000/6250], Loss: 0.8010 \n",
      "\n",
      "Epoch: [62/100], Step: [1100/6250], Loss: 0.5200 \n",
      "\n",
      "Epoch: [62/100], Step: [1200/6250], Loss: 0.8310 \n",
      "\n",
      "Epoch: [62/100], Step: [1300/6250], Loss: 0.9044 \n",
      "\n",
      "Epoch: [62/100], Step: [1400/6250], Loss: 0.6343 \n",
      "\n",
      "Epoch: [62/100], Step: [1500/6250], Loss: 0.4531 \n",
      "\n",
      "Epoch: [62/100], Step: [1600/6250], Loss: 0.2950 \n",
      "\n",
      "Epoch: [62/100], Step: [1700/6250], Loss: 0.7951 \n",
      "\n",
      "Epoch: [62/100], Step: [1800/6250], Loss: 0.6072 \n",
      "\n",
      "Epoch: [62/100], Step: [1900/6250], Loss: 0.5243 \n",
      "\n",
      "Epoch: [62/100], Step: [2000/6250], Loss: 0.3173 \n",
      "\n",
      "Epoch: [62/100], Step: [2100/6250], Loss: 0.5483 \n",
      "\n",
      "Epoch: [62/100], Step: [2200/6250], Loss: 0.3695 \n",
      "\n",
      "Epoch: [62/100], Step: [2300/6250], Loss: 0.5359 \n",
      "\n",
      "Epoch: [62/100], Step: [2400/6250], Loss: 0.5364 \n",
      "\n",
      "Epoch: [62/100], Step: [2500/6250], Loss: 1.0778 \n",
      "\n",
      "Epoch: [62/100], Step: [2600/6250], Loss: 1.5510 \n",
      "\n",
      "Epoch: [62/100], Step: [2700/6250], Loss: 0.7345 \n",
      "\n",
      "Epoch: [62/100], Step: [2800/6250], Loss: 0.4870 \n",
      "\n",
      "Epoch: [62/100], Step: [2900/6250], Loss: 0.2766 \n",
      "\n",
      "Epoch: [62/100], Step: [3000/6250], Loss: 0.6122 \n",
      "\n",
      "Epoch: [62/100], Step: [3100/6250], Loss: 0.4659 \n",
      "\n",
      "Epoch: [62/100], Step: [3200/6250], Loss: 0.9686 \n",
      "\n",
      "Epoch: [62/100], Step: [3300/6250], Loss: 0.5509 \n",
      "\n",
      "Epoch: [62/100], Step: [3400/6250], Loss: 0.6086 \n",
      "\n",
      "Epoch: [62/100], Step: [3500/6250], Loss: 0.5574 \n",
      "\n",
      "Epoch: [62/100], Step: [3600/6250], Loss: 0.1268 \n",
      "\n",
      "Epoch: [62/100], Step: [3700/6250], Loss: 0.2076 \n",
      "\n",
      "Epoch: [62/100], Step: [3800/6250], Loss: 0.4670 \n",
      "\n",
      "Epoch: [62/100], Step: [3900/6250], Loss: 0.9721 \n",
      "\n",
      "Epoch: [62/100], Step: [4000/6250], Loss: 1.6185 \n",
      "\n",
      "Epoch: [62/100], Step: [4100/6250], Loss: 0.2782 \n",
      "\n",
      "Epoch: [62/100], Step: [4200/6250], Loss: 0.4733 \n",
      "\n",
      "Epoch: [62/100], Step: [4300/6250], Loss: 0.3840 \n",
      "\n",
      "Epoch: [62/100], Step: [4400/6250], Loss: 0.6245 \n",
      "\n",
      "Epoch: [62/100], Step: [4500/6250], Loss: 1.1393 \n",
      "\n",
      "Epoch: [62/100], Step: [4600/6250], Loss: 0.7635 \n",
      "\n",
      "Epoch: [62/100], Step: [4700/6250], Loss: 0.3654 \n",
      "\n",
      "Epoch: [62/100], Step: [4800/6250], Loss: 0.6253 \n",
      "\n",
      "Epoch: [62/100], Step: [4900/6250], Loss: 0.3354 \n",
      "\n",
      "Epoch: [62/100], Step: [5000/6250], Loss: 0.8320 \n",
      "\n",
      "Epoch: [62/100], Step: [5100/6250], Loss: 0.6537 \n",
      "\n",
      "Epoch: [62/100], Step: [5200/6250], Loss: 0.3766 \n",
      "\n",
      "Epoch: [62/100], Step: [5300/6250], Loss: 0.5978 \n",
      "\n",
      "Epoch: [62/100], Step: [5400/6250], Loss: 0.4610 \n",
      "\n",
      "Epoch: [62/100], Step: [5500/6250], Loss: 0.5310 \n",
      "\n",
      "Epoch: [62/100], Step: [5600/6250], Loss: 1.0106 \n",
      "\n",
      "Epoch: [62/100], Step: [5700/6250], Loss: 0.7566 \n",
      "\n",
      "Epoch: [62/100], Step: [5800/6250], Loss: 0.7255 \n",
      "\n",
      "Epoch: [62/100], Step: [5900/6250], Loss: 0.7409 \n",
      "\n",
      "Epoch: [62/100], Step: [6000/6250], Loss: 0.4783 \n",
      "\n",
      "Epoch: [62/100], Step: [6100/6250], Loss: 1.0879 \n",
      "\n",
      "Epoch: [62/100], Step: [6200/6250], Loss: 0.6560 \n",
      "\n",
      "Epoch: [63/100], Step: [100/6250], Loss: 0.5871 \n",
      "\n",
      "Epoch: [63/100], Step: [200/6250], Loss: 0.6727 \n",
      "\n",
      "Epoch: [63/100], Step: [300/6250], Loss: 0.4740 \n",
      "\n",
      "Epoch: [63/100], Step: [400/6250], Loss: 0.6298 \n",
      "\n",
      "Epoch: [63/100], Step: [500/6250], Loss: 1.0066 \n",
      "\n",
      "Epoch: [63/100], Step: [600/6250], Loss: 0.9276 \n",
      "\n",
      "Epoch: [63/100], Step: [700/6250], Loss: 0.4626 \n",
      "\n",
      "Epoch: [63/100], Step: [800/6250], Loss: 0.2352 \n",
      "\n",
      "Epoch: [63/100], Step: [900/6250], Loss: 0.1562 \n",
      "\n",
      "Epoch: [63/100], Step: [1000/6250], Loss: 0.5286 \n",
      "\n",
      "Epoch: [63/100], Step: [1100/6250], Loss: 0.5753 \n",
      "\n",
      "Epoch: [63/100], Step: [1200/6250], Loss: 0.6037 \n",
      "\n",
      "Epoch: [63/100], Step: [1300/6250], Loss: 0.4860 \n",
      "\n",
      "Epoch: [63/100], Step: [1400/6250], Loss: 0.7479 \n",
      "\n",
      "Epoch: [63/100], Step: [1500/6250], Loss: 0.3171 \n",
      "\n",
      "Epoch: [63/100], Step: [1600/6250], Loss: 0.6923 \n",
      "\n",
      "Epoch: [63/100], Step: [1700/6250], Loss: 0.4227 \n",
      "\n",
      "Epoch: [63/100], Step: [1800/6250], Loss: 0.6340 \n",
      "\n",
      "Epoch: [63/100], Step: [1900/6250], Loss: 0.2521 \n",
      "\n",
      "Epoch: [63/100], Step: [2000/6250], Loss: 0.2302 \n",
      "\n",
      "Epoch: [63/100], Step: [2100/6250], Loss: 0.1098 \n",
      "\n",
      "Epoch: [63/100], Step: [2200/6250], Loss: 0.1993 \n",
      "\n",
      "Epoch: [63/100], Step: [2300/6250], Loss: 0.3342 \n",
      "\n",
      "Epoch: [63/100], Step: [2400/6250], Loss: 0.7048 \n",
      "\n",
      "Epoch: [63/100], Step: [2500/6250], Loss: 0.7006 \n",
      "\n",
      "Epoch: [63/100], Step: [2600/6250], Loss: 0.9196 \n",
      "\n",
      "Epoch: [63/100], Step: [2700/6250], Loss: 0.3635 \n",
      "\n",
      "Epoch: [63/100], Step: [2800/6250], Loss: 0.7916 \n",
      "\n",
      "Epoch: [63/100], Step: [2900/6250], Loss: 0.3329 \n",
      "\n",
      "Epoch: [63/100], Step: [3000/6250], Loss: 0.6979 \n",
      "\n",
      "Epoch: [63/100], Step: [3100/6250], Loss: 0.4656 \n",
      "\n",
      "Epoch: [63/100], Step: [3200/6250], Loss: 0.2570 \n",
      "\n",
      "Epoch: [63/100], Step: [3300/6250], Loss: 0.9334 \n",
      "\n",
      "Epoch: [63/100], Step: [3400/6250], Loss: 0.8500 \n",
      "\n",
      "Epoch: [63/100], Step: [3500/6250], Loss: 0.2482 \n",
      "\n",
      "Epoch: [63/100], Step: [3600/6250], Loss: 1.0443 \n",
      "\n",
      "Epoch: [63/100], Step: [3700/6250], Loss: 0.8495 \n",
      "\n",
      "Epoch: [63/100], Step: [3800/6250], Loss: 0.5934 \n",
      "\n",
      "Epoch: [63/100], Step: [3900/6250], Loss: 0.6427 \n",
      "\n",
      "Epoch: [63/100], Step: [4000/6250], Loss: 0.3623 \n",
      "\n",
      "Epoch: [63/100], Step: [4100/6250], Loss: 0.9967 \n",
      "\n",
      "Epoch: [63/100], Step: [4200/6250], Loss: 0.4038 \n",
      "\n",
      "Epoch: [63/100], Step: [4300/6250], Loss: 0.3433 \n",
      "\n",
      "Epoch: [63/100], Step: [4400/6250], Loss: 0.5936 \n",
      "\n",
      "Epoch: [63/100], Step: [4500/6250], Loss: 0.5303 \n",
      "\n",
      "Epoch: [63/100], Step: [4600/6250], Loss: 1.2482 \n",
      "\n",
      "Epoch: [63/100], Step: [4700/6250], Loss: 0.8147 \n",
      "\n",
      "Epoch: [63/100], Step: [4800/6250], Loss: 0.3523 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [63/100], Step: [4900/6250], Loss: 0.8427 \n",
      "\n",
      "Epoch: [63/100], Step: [5000/6250], Loss: 0.3014 \n",
      "\n",
      "Epoch: [63/100], Step: [5100/6250], Loss: 0.5071 \n",
      "\n",
      "Epoch: [63/100], Step: [5200/6250], Loss: 0.4612 \n",
      "\n",
      "Epoch: [63/100], Step: [5300/6250], Loss: 0.5928 \n",
      "\n",
      "Epoch: [63/100], Step: [5400/6250], Loss: 1.0171 \n",
      "\n",
      "Epoch: [63/100], Step: [5500/6250], Loss: 0.5480 \n",
      "\n",
      "Epoch: [63/100], Step: [5600/6250], Loss: 0.4364 \n",
      "\n",
      "Epoch: [63/100], Step: [5700/6250], Loss: 1.1314 \n",
      "\n",
      "Epoch: [63/100], Step: [5800/6250], Loss: 1.0050 \n",
      "\n",
      "Epoch: [63/100], Step: [5900/6250], Loss: 0.7222 \n",
      "\n",
      "Epoch: [63/100], Step: [6000/6250], Loss: 0.2348 \n",
      "\n",
      "Epoch: [63/100], Step: [6100/6250], Loss: 0.4313 \n",
      "\n",
      "Epoch: [63/100], Step: [6200/6250], Loss: 1.5343 \n",
      "\n",
      "Epoch: [64/100], Step: [100/6250], Loss: 0.3241 \n",
      "\n",
      "Epoch: [64/100], Step: [200/6250], Loss: 0.9445 \n",
      "\n",
      "Epoch: [64/100], Step: [300/6250], Loss: 0.2888 \n",
      "\n",
      "Epoch: [64/100], Step: [400/6250], Loss: 0.5903 \n",
      "\n",
      "Epoch: [64/100], Step: [500/6250], Loss: 0.8192 \n",
      "\n",
      "Epoch: [64/100], Step: [600/6250], Loss: 0.2466 \n",
      "\n",
      "Epoch: [64/100], Step: [700/6250], Loss: 0.3065 \n",
      "\n",
      "Epoch: [64/100], Step: [800/6250], Loss: 0.5557 \n",
      "\n",
      "Epoch: [64/100], Step: [900/6250], Loss: 0.5121 \n",
      "\n",
      "Epoch: [64/100], Step: [1000/6250], Loss: 0.5486 \n",
      "\n",
      "Epoch: [64/100], Step: [1100/6250], Loss: 0.2667 \n",
      "\n",
      "Epoch: [64/100], Step: [1200/6250], Loss: 0.5446 \n",
      "\n",
      "Epoch: [64/100], Step: [1300/6250], Loss: 0.5337 \n",
      "\n",
      "Epoch: [64/100], Step: [1400/6250], Loss: 0.5862 \n",
      "\n",
      "Epoch: [64/100], Step: [1500/6250], Loss: 0.6365 \n",
      "\n",
      "Epoch: [64/100], Step: [1600/6250], Loss: 0.6167 \n",
      "\n",
      "Epoch: [64/100], Step: [1700/6250], Loss: 1.0756 \n",
      "\n",
      "Epoch: [64/100], Step: [1800/6250], Loss: 0.6330 \n",
      "\n",
      "Epoch: [64/100], Step: [1900/6250], Loss: 0.4961 \n",
      "\n",
      "Epoch: [64/100], Step: [2000/6250], Loss: 0.7571 \n",
      "\n",
      "Epoch: [64/100], Step: [2100/6250], Loss: 0.2274 \n",
      "\n",
      "Epoch: [64/100], Step: [2200/6250], Loss: 0.1929 \n",
      "\n",
      "Epoch: [64/100], Step: [2300/6250], Loss: 0.5204 \n",
      "\n",
      "Epoch: [64/100], Step: [2400/6250], Loss: 0.5579 \n",
      "\n",
      "Epoch: [64/100], Step: [2500/6250], Loss: 0.1799 \n",
      "\n",
      "Epoch: [64/100], Step: [2600/6250], Loss: 0.6735 \n",
      "\n",
      "Epoch: [64/100], Step: [2700/6250], Loss: 0.2204 \n",
      "\n",
      "Epoch: [64/100], Step: [2800/6250], Loss: 0.5283 \n",
      "\n",
      "Epoch: [64/100], Step: [2900/6250], Loss: 0.3987 \n",
      "\n",
      "Epoch: [64/100], Step: [3000/6250], Loss: 0.5384 \n",
      "\n",
      "Epoch: [64/100], Step: [3100/6250], Loss: 0.8291 \n",
      "\n",
      "Epoch: [64/100], Step: [3200/6250], Loss: 0.3615 \n",
      "\n",
      "Epoch: [64/100], Step: [3300/6250], Loss: 0.9950 \n",
      "\n",
      "Epoch: [64/100], Step: [3400/6250], Loss: 0.4534 \n",
      "\n",
      "Epoch: [64/100], Step: [3500/6250], Loss: 0.1405 \n",
      "\n",
      "Epoch: [64/100], Step: [3600/6250], Loss: 0.5810 \n",
      "\n",
      "Epoch: [64/100], Step: [3700/6250], Loss: 0.3685 \n",
      "\n",
      "Epoch: [64/100], Step: [3800/6250], Loss: 0.2799 \n",
      "\n",
      "Epoch: [64/100], Step: [3900/6250], Loss: 0.6716 \n",
      "\n",
      "Epoch: [64/100], Step: [4000/6250], Loss: 0.2247 \n",
      "\n",
      "Epoch: [64/100], Step: [4100/6250], Loss: 0.5465 \n",
      "\n",
      "Epoch: [64/100], Step: [4200/6250], Loss: 0.6228 \n",
      "\n",
      "Epoch: [64/100], Step: [4300/6250], Loss: 0.4553 \n",
      "\n",
      "Epoch: [64/100], Step: [4400/6250], Loss: 0.6416 \n",
      "\n",
      "Epoch: [64/100], Step: [4500/6250], Loss: 0.4519 \n",
      "\n",
      "Epoch: [64/100], Step: [4600/6250], Loss: 0.2852 \n",
      "\n",
      "Epoch: [64/100], Step: [4700/6250], Loss: 1.0127 \n",
      "\n",
      "Epoch: [64/100], Step: [4800/6250], Loss: 0.3742 \n",
      "\n",
      "Epoch: [64/100], Step: [4900/6250], Loss: 0.2073 \n",
      "\n",
      "Epoch: [64/100], Step: [5000/6250], Loss: 0.5479 \n",
      "\n",
      "Epoch: [64/100], Step: [5100/6250], Loss: 0.0578 \n",
      "\n",
      "Epoch: [64/100], Step: [5200/6250], Loss: 0.6194 \n",
      "\n",
      "Epoch: [64/100], Step: [5300/6250], Loss: 0.5724 \n",
      "\n",
      "Epoch: [64/100], Step: [5400/6250], Loss: 0.2855 \n",
      "\n",
      "Epoch: [64/100], Step: [5500/6250], Loss: 0.8982 \n",
      "\n",
      "Epoch: [64/100], Step: [5600/6250], Loss: 0.4916 \n",
      "\n",
      "Epoch: [64/100], Step: [5700/6250], Loss: 1.1393 \n",
      "\n",
      "Epoch: [64/100], Step: [5800/6250], Loss: 1.2091 \n",
      "\n",
      "Epoch: [64/100], Step: [5900/6250], Loss: 1.0569 \n",
      "\n",
      "Epoch: [64/100], Step: [6000/6250], Loss: 0.2896 \n",
      "\n",
      "Epoch: [64/100], Step: [6100/6250], Loss: 0.7609 \n",
      "\n",
      "Epoch: [64/100], Step: [6200/6250], Loss: 1.6271 \n",
      "\n",
      "Epoch: [65/100], Step: [100/6250], Loss: 0.6875 \n",
      "\n",
      "Epoch: [65/100], Step: [200/6250], Loss: 1.1059 \n",
      "\n",
      "Epoch: [65/100], Step: [300/6250], Loss: 0.5721 \n",
      "\n",
      "Epoch: [65/100], Step: [400/6250], Loss: 0.5007 \n",
      "\n",
      "Epoch: [65/100], Step: [500/6250], Loss: 0.9508 \n",
      "\n",
      "Epoch: [65/100], Step: [600/6250], Loss: 0.1729 \n",
      "\n",
      "Epoch: [65/100], Step: [700/6250], Loss: 0.3346 \n",
      "\n",
      "Epoch: [65/100], Step: [800/6250], Loss: 0.4193 \n",
      "\n",
      "Epoch: [65/100], Step: [900/6250], Loss: 0.4167 \n",
      "\n",
      "Epoch: [65/100], Step: [1000/6250], Loss: 0.2675 \n",
      "\n",
      "Epoch: [65/100], Step: [1100/6250], Loss: 0.7890 \n",
      "\n",
      "Epoch: [65/100], Step: [1200/6250], Loss: 0.9330 \n",
      "\n",
      "Epoch: [65/100], Step: [1300/6250], Loss: 0.7568 \n",
      "\n",
      "Epoch: [65/100], Step: [1400/6250], Loss: 0.3661 \n",
      "\n",
      "Epoch: [65/100], Step: [1500/6250], Loss: 0.4016 \n",
      "\n",
      "Epoch: [65/100], Step: [1600/6250], Loss: 1.2873 \n",
      "\n",
      "Epoch: [65/100], Step: [1700/6250], Loss: 0.6225 \n",
      "\n",
      "Epoch: [65/100], Step: [1800/6250], Loss: 1.2122 \n",
      "\n",
      "Epoch: [65/100], Step: [1900/6250], Loss: 0.4558 \n",
      "\n",
      "Epoch: [65/100], Step: [2000/6250], Loss: 0.9382 \n",
      "\n",
      "Epoch: [65/100], Step: [2100/6250], Loss: 0.2779 \n",
      "\n",
      "Epoch: [65/100], Step: [2200/6250], Loss: 0.5614 \n",
      "\n",
      "Epoch: [65/100], Step: [2300/6250], Loss: 0.6102 \n",
      "\n",
      "Epoch: [65/100], Step: [2400/6250], Loss: 0.2160 \n",
      "\n",
      "Epoch: [65/100], Step: [2500/6250], Loss: 0.7285 \n",
      "\n",
      "Epoch: [65/100], Step: [2600/6250], Loss: 0.3725 \n",
      "\n",
      "Epoch: [65/100], Step: [2700/6250], Loss: 0.2626 \n",
      "\n",
      "Epoch: [65/100], Step: [2800/6250], Loss: 0.4581 \n",
      "\n",
      "Epoch: [65/100], Step: [2900/6250], Loss: 0.4914 \n",
      "\n",
      "Epoch: [65/100], Step: [3000/6250], Loss: 0.2702 \n",
      "\n",
      "Epoch: [65/100], Step: [3100/6250], Loss: 0.9817 \n",
      "\n",
      "Epoch: [65/100], Step: [3200/6250], Loss: 1.1670 \n",
      "\n",
      "Epoch: [65/100], Step: [3300/6250], Loss: 1.3014 \n",
      "\n",
      "Epoch: [65/100], Step: [3400/6250], Loss: 0.6031 \n",
      "\n",
      "Epoch: [65/100], Step: [3500/6250], Loss: 0.9084 \n",
      "\n",
      "Epoch: [65/100], Step: [3600/6250], Loss: 0.1103 \n",
      "\n",
      "Epoch: [65/100], Step: [3700/6250], Loss: 0.3754 \n",
      "\n",
      "Epoch: [65/100], Step: [3800/6250], Loss: 0.1935 \n",
      "\n",
      "Epoch: [65/100], Step: [3900/6250], Loss: 0.4586 \n",
      "\n",
      "Epoch: [65/100], Step: [4000/6250], Loss: 0.1846 \n",
      "\n",
      "Epoch: [65/100], Step: [4100/6250], Loss: 0.2438 \n",
      "\n",
      "Epoch: [65/100], Step: [4200/6250], Loss: 0.9822 \n",
      "\n",
      "Epoch: [65/100], Step: [4300/6250], Loss: 0.6115 \n",
      "\n",
      "Epoch: [65/100], Step: [4400/6250], Loss: 0.6162 \n",
      "\n",
      "Epoch: [65/100], Step: [4500/6250], Loss: 0.8574 \n",
      "\n",
      "Epoch: [65/100], Step: [4600/6250], Loss: 0.1860 \n",
      "\n",
      "Epoch: [65/100], Step: [4700/6250], Loss: 0.7761 \n",
      "\n",
      "Epoch: [65/100], Step: [4800/6250], Loss: 0.7781 \n",
      "\n",
      "Epoch: [65/100], Step: [4900/6250], Loss: 0.2164 \n",
      "\n",
      "Epoch: [65/100], Step: [5000/6250], Loss: 0.6055 \n",
      "\n",
      "Epoch: [65/100], Step: [5100/6250], Loss: 0.4387 \n",
      "\n",
      "Epoch: [65/100], Step: [5200/6250], Loss: 0.5365 \n",
      "\n",
      "Epoch: [65/100], Step: [5300/6250], Loss: 0.4259 \n",
      "\n",
      "Epoch: [65/100], Step: [5400/6250], Loss: 0.3784 \n",
      "\n",
      "Epoch: [65/100], Step: [5500/6250], Loss: 0.1784 \n",
      "\n",
      "Epoch: [65/100], Step: [5600/6250], Loss: 0.5062 \n",
      "\n",
      "Epoch: [65/100], Step: [5700/6250], Loss: 0.5474 \n",
      "\n",
      "Epoch: [65/100], Step: [5800/6250], Loss: 1.0549 \n",
      "\n",
      "Epoch: [65/100], Step: [5900/6250], Loss: 1.2224 \n",
      "\n",
      "Epoch: [65/100], Step: [6000/6250], Loss: 0.3189 \n",
      "\n",
      "Epoch: [65/100], Step: [6100/6250], Loss: 0.1819 \n",
      "\n",
      "Epoch: [65/100], Step: [6200/6250], Loss: 1.0579 \n",
      "\n",
      "Epoch: [66/100], Step: [100/6250], Loss: 0.4628 \n",
      "\n",
      "Epoch: [66/100], Step: [200/6250], Loss: 0.6256 \n",
      "\n",
      "Epoch: [66/100], Step: [300/6250], Loss: 0.2955 \n",
      "\n",
      "Epoch: [66/100], Step: [400/6250], Loss: 1.1842 \n",
      "\n",
      "Epoch: [66/100], Step: [500/6250], Loss: 0.3647 \n",
      "\n",
      "Epoch: [66/100], Step: [600/6250], Loss: 0.3469 \n",
      "\n",
      "Epoch: [66/100], Step: [700/6250], Loss: 0.1631 \n",
      "\n",
      "Epoch: [66/100], Step: [800/6250], Loss: 0.6337 \n",
      "\n",
      "Epoch: [66/100], Step: [900/6250], Loss: 0.3563 \n",
      "\n",
      "Epoch: [66/100], Step: [1000/6250], Loss: 0.3521 \n",
      "\n",
      "Epoch: [66/100], Step: [1100/6250], Loss: 0.5900 \n",
      "\n",
      "Epoch: [66/100], Step: [1200/6250], Loss: 0.7763 \n",
      "\n",
      "Epoch: [66/100], Step: [1300/6250], Loss: 1.4937 \n",
      "\n",
      "Epoch: [66/100], Step: [1400/6250], Loss: 0.2946 \n",
      "\n",
      "Epoch: [66/100], Step: [1500/6250], Loss: 0.2782 \n",
      "\n",
      "Epoch: [66/100], Step: [1600/6250], Loss: 0.6856 \n",
      "\n",
      "Epoch: [66/100], Step: [1700/6250], Loss: 1.2388 \n",
      "\n",
      "Epoch: [66/100], Step: [1800/6250], Loss: 0.6714 \n",
      "\n",
      "Epoch: [66/100], Step: [1900/6250], Loss: 0.3157 \n",
      "\n",
      "Epoch: [66/100], Step: [2000/6250], Loss: 1.2802 \n",
      "\n",
      "Epoch: [66/100], Step: [2100/6250], Loss: 0.6902 \n",
      "\n",
      "Epoch: [66/100], Step: [2200/6250], Loss: 1.3545 \n",
      "\n",
      "Epoch: [66/100], Step: [2300/6250], Loss: 0.6155 \n",
      "\n",
      "Epoch: [66/100], Step: [2400/6250], Loss: 0.9224 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [66/100], Step: [2500/6250], Loss: 0.3292 \n",
      "\n",
      "Epoch: [66/100], Step: [2600/6250], Loss: 0.8741 \n",
      "\n",
      "Epoch: [66/100], Step: [2700/6250], Loss: 0.5953 \n",
      "\n",
      "Epoch: [66/100], Step: [2800/6250], Loss: 0.4349 \n",
      "\n",
      "Epoch: [66/100], Step: [2900/6250], Loss: 0.2105 \n",
      "\n",
      "Epoch: [66/100], Step: [3000/6250], Loss: 0.4291 \n",
      "\n",
      "Epoch: [66/100], Step: [3100/6250], Loss: 0.1929 \n",
      "\n",
      "Epoch: [66/100], Step: [3200/6250], Loss: 0.7253 \n",
      "\n",
      "Epoch: [66/100], Step: [3300/6250], Loss: 0.9200 \n",
      "\n",
      "Epoch: [66/100], Step: [3400/6250], Loss: 0.3225 \n",
      "\n",
      "Epoch: [66/100], Step: [3500/6250], Loss: 0.2013 \n",
      "\n",
      "Epoch: [66/100], Step: [3600/6250], Loss: 0.6583 \n",
      "\n",
      "Epoch: [66/100], Step: [3700/6250], Loss: 0.3241 \n",
      "\n",
      "Epoch: [66/100], Step: [3800/6250], Loss: 0.9043 \n",
      "\n",
      "Epoch: [66/100], Step: [3900/6250], Loss: 0.1361 \n",
      "\n",
      "Epoch: [66/100], Step: [4000/6250], Loss: 0.6123 \n",
      "\n",
      "Epoch: [66/100], Step: [4100/6250], Loss: 0.4529 \n",
      "\n",
      "Epoch: [66/100], Step: [4200/6250], Loss: 0.6925 \n",
      "\n",
      "Epoch: [66/100], Step: [4300/6250], Loss: 0.2842 \n",
      "\n",
      "Epoch: [66/100], Step: [4400/6250], Loss: 0.5361 \n",
      "\n",
      "Epoch: [66/100], Step: [4500/6250], Loss: 0.6282 \n",
      "\n",
      "Epoch: [66/100], Step: [4600/6250], Loss: 0.9943 \n",
      "\n",
      "Epoch: [66/100], Step: [4700/6250], Loss: 0.2304 \n",
      "\n",
      "Epoch: [66/100], Step: [4800/6250], Loss: 2.0239 \n",
      "\n",
      "Epoch: [66/100], Step: [4900/6250], Loss: 0.8945 \n",
      "\n",
      "Epoch: [66/100], Step: [5000/6250], Loss: 0.9213 \n",
      "\n",
      "Epoch: [66/100], Step: [5100/6250], Loss: 0.6055 \n",
      "\n",
      "Epoch: [66/100], Step: [5200/6250], Loss: 0.5800 \n",
      "\n",
      "Epoch: [66/100], Step: [5300/6250], Loss: 0.7229 \n",
      "\n",
      "Epoch: [66/100], Step: [5400/6250], Loss: 0.3685 \n",
      "\n",
      "Epoch: [66/100], Step: [5500/6250], Loss: 0.7103 \n",
      "\n",
      "Epoch: [66/100], Step: [5600/6250], Loss: 1.8548 \n",
      "\n",
      "Epoch: [66/100], Step: [5700/6250], Loss: 0.6105 \n",
      "\n",
      "Epoch: [66/100], Step: [5800/6250], Loss: 0.2912 \n",
      "\n",
      "Epoch: [66/100], Step: [5900/6250], Loss: 0.6869 \n",
      "\n",
      "Epoch: [66/100], Step: [6000/6250], Loss: 0.4641 \n",
      "\n",
      "Epoch: [66/100], Step: [6100/6250], Loss: 0.4327 \n",
      "\n",
      "Epoch: [66/100], Step: [6200/6250], Loss: 0.3139 \n",
      "\n",
      "Epoch: [67/100], Step: [100/6250], Loss: 0.3725 \n",
      "\n",
      "Epoch: [67/100], Step: [200/6250], Loss: 0.2613 \n",
      "\n",
      "Epoch: [67/100], Step: [300/6250], Loss: 0.6407 \n",
      "\n",
      "Epoch: [67/100], Step: [400/6250], Loss: 0.3425 \n",
      "\n",
      "Epoch: [67/100], Step: [500/6250], Loss: 0.8561 \n",
      "\n",
      "Epoch: [67/100], Step: [600/6250], Loss: 0.6063 \n",
      "\n",
      "Epoch: [67/100], Step: [700/6250], Loss: 0.2425 \n",
      "\n",
      "Epoch: [67/100], Step: [800/6250], Loss: 0.0696 \n",
      "\n",
      "Epoch: [67/100], Step: [900/6250], Loss: 1.1119 \n",
      "\n",
      "Epoch: [67/100], Step: [1000/6250], Loss: 0.2063 \n",
      "\n",
      "Epoch: [67/100], Step: [1100/6250], Loss: 0.2977 \n",
      "\n",
      "Epoch: [67/100], Step: [1200/6250], Loss: 0.4179 \n",
      "\n",
      "Epoch: [67/100], Step: [1300/6250], Loss: 0.8084 \n",
      "\n",
      "Epoch: [67/100], Step: [1400/6250], Loss: 0.4444 \n",
      "\n",
      "Epoch: [67/100], Step: [1500/6250], Loss: 0.1508 \n",
      "\n",
      "Epoch: [67/100], Step: [1600/6250], Loss: 0.2836 \n",
      "\n",
      "Epoch: [67/100], Step: [1700/6250], Loss: 0.3938 \n",
      "\n",
      "Epoch: [67/100], Step: [1800/6250], Loss: 0.5996 \n",
      "\n",
      "Epoch: [67/100], Step: [1900/6250], Loss: 0.6998 \n",
      "\n",
      "Epoch: [67/100], Step: [2000/6250], Loss: 0.1349 \n",
      "\n",
      "Epoch: [67/100], Step: [2100/6250], Loss: 0.4534 \n",
      "\n",
      "Epoch: [67/100], Step: [2200/6250], Loss: 0.0725 \n",
      "\n",
      "Epoch: [67/100], Step: [2300/6250], Loss: 0.3295 \n",
      "\n",
      "Epoch: [67/100], Step: [2400/6250], Loss: 1.1200 \n",
      "\n",
      "Epoch: [67/100], Step: [2500/6250], Loss: 0.3686 \n",
      "\n",
      "Epoch: [67/100], Step: [2600/6250], Loss: 0.9422 \n",
      "\n",
      "Epoch: [67/100], Step: [2700/6250], Loss: 0.6291 \n",
      "\n",
      "Epoch: [67/100], Step: [2800/6250], Loss: 0.1644 \n",
      "\n",
      "Epoch: [67/100], Step: [2900/6250], Loss: 0.9084 \n",
      "\n",
      "Epoch: [67/100], Step: [3000/6250], Loss: 0.5849 \n",
      "\n",
      "Epoch: [67/100], Step: [3100/6250], Loss: 0.4432 \n",
      "\n",
      "Epoch: [67/100], Step: [3200/6250], Loss: 0.4464 \n",
      "\n",
      "Epoch: [67/100], Step: [3300/6250], Loss: 0.3475 \n",
      "\n",
      "Epoch: [67/100], Step: [3400/6250], Loss: 0.9765 \n",
      "\n",
      "Epoch: [67/100], Step: [3500/6250], Loss: 1.2115 \n",
      "\n",
      "Epoch: [67/100], Step: [3600/6250], Loss: 0.2861 \n",
      "\n",
      "Epoch: [67/100], Step: [3700/6250], Loss: 0.3107 \n",
      "\n",
      "Epoch: [67/100], Step: [3800/6250], Loss: 0.3304 \n",
      "\n",
      "Epoch: [67/100], Step: [3900/6250], Loss: 0.7195 \n",
      "\n",
      "Epoch: [67/100], Step: [4000/6250], Loss: 1.0751 \n",
      "\n",
      "Epoch: [67/100], Step: [4100/6250], Loss: 0.1228 \n",
      "\n",
      "Epoch: [67/100], Step: [4200/6250], Loss: 0.8826 \n",
      "\n",
      "Epoch: [67/100], Step: [4300/6250], Loss: 0.7506 \n",
      "\n",
      "Epoch: [67/100], Step: [4400/6250], Loss: 0.8151 \n",
      "\n",
      "Epoch: [67/100], Step: [4500/6250], Loss: 0.3995 \n",
      "\n",
      "Epoch: [67/100], Step: [4600/6250], Loss: 0.2689 \n",
      "\n",
      "Epoch: [67/100], Step: [4700/6250], Loss: 0.6307 \n",
      "\n",
      "Epoch: [67/100], Step: [4800/6250], Loss: 0.8484 \n",
      "\n",
      "Epoch: [67/100], Step: [4900/6250], Loss: 0.6255 \n",
      "\n",
      "Epoch: [67/100], Step: [5000/6250], Loss: 0.5448 \n",
      "\n",
      "Epoch: [67/100], Step: [5100/6250], Loss: 0.3610 \n",
      "\n",
      "Epoch: [67/100], Step: [5200/6250], Loss: 0.2789 \n",
      "\n",
      "Epoch: [67/100], Step: [5300/6250], Loss: 0.8437 \n",
      "\n",
      "Epoch: [67/100], Step: [5400/6250], Loss: 0.3733 \n",
      "\n",
      "Epoch: [67/100], Step: [5500/6250], Loss: 0.5751 \n",
      "\n",
      "Epoch: [67/100], Step: [5600/6250], Loss: 1.0841 \n",
      "\n",
      "Epoch: [67/100], Step: [5700/6250], Loss: 0.1326 \n",
      "\n",
      "Epoch: [67/100], Step: [5800/6250], Loss: 0.0988 \n",
      "\n",
      "Epoch: [67/100], Step: [5900/6250], Loss: 0.5546 \n",
      "\n",
      "Epoch: [67/100], Step: [6000/6250], Loss: 0.9893 \n",
      "\n",
      "Epoch: [67/100], Step: [6100/6250], Loss: 0.9797 \n",
      "\n",
      "Epoch: [67/100], Step: [6200/6250], Loss: 0.6493 \n",
      "\n",
      "Epoch: [68/100], Step: [100/6250], Loss: 0.2118 \n",
      "\n",
      "Epoch: [68/100], Step: [200/6250], Loss: 0.2870 \n",
      "\n",
      "Epoch: [68/100], Step: [300/6250], Loss: 1.0249 \n",
      "\n",
      "Epoch: [68/100], Step: [400/6250], Loss: 1.0838 \n",
      "\n",
      "Epoch: [68/100], Step: [500/6250], Loss: 0.7448 \n",
      "\n",
      "Epoch: [68/100], Step: [600/6250], Loss: 0.1065 \n",
      "\n",
      "Epoch: [68/100], Step: [700/6250], Loss: 0.6209 \n",
      "\n",
      "Epoch: [68/100], Step: [800/6250], Loss: 0.7873 \n",
      "\n",
      "Epoch: [68/100], Step: [900/6250], Loss: 0.2278 \n",
      "\n",
      "Epoch: [68/100], Step: [1000/6250], Loss: 1.0599 \n",
      "\n",
      "Epoch: [68/100], Step: [1100/6250], Loss: 0.6422 \n",
      "\n",
      "Epoch: [68/100], Step: [1200/6250], Loss: 0.3377 \n",
      "\n",
      "Epoch: [68/100], Step: [1300/6250], Loss: 0.5631 \n",
      "\n",
      "Epoch: [68/100], Step: [1400/6250], Loss: 0.5182 \n",
      "\n",
      "Epoch: [68/100], Step: [1500/6250], Loss: 0.5119 \n",
      "\n",
      "Epoch: [68/100], Step: [1600/6250], Loss: 0.0641 \n",
      "\n",
      "Epoch: [68/100], Step: [1700/6250], Loss: 0.4970 \n",
      "\n",
      "Epoch: [68/100], Step: [1800/6250], Loss: 0.5480 \n",
      "\n",
      "Epoch: [68/100], Step: [1900/6250], Loss: 0.0331 \n",
      "\n",
      "Epoch: [68/100], Step: [2000/6250], Loss: 0.5390 \n",
      "\n",
      "Epoch: [68/100], Step: [2100/6250], Loss: 0.5478 \n",
      "\n",
      "Epoch: [68/100], Step: [2200/6250], Loss: 0.6408 \n",
      "\n",
      "Epoch: [68/100], Step: [2300/6250], Loss: 0.8728 \n",
      "\n",
      "Epoch: [68/100], Step: [2400/6250], Loss: 0.3250 \n",
      "\n",
      "Epoch: [68/100], Step: [2500/6250], Loss: 0.7061 \n",
      "\n",
      "Epoch: [68/100], Step: [2600/6250], Loss: 1.1736 \n",
      "\n",
      "Epoch: [68/100], Step: [2700/6250], Loss: 0.5805 \n",
      "\n",
      "Epoch: [68/100], Step: [2800/6250], Loss: 1.1799 \n",
      "\n",
      "Epoch: [68/100], Step: [2900/6250], Loss: 0.5306 \n",
      "\n",
      "Epoch: [68/100], Step: [3000/6250], Loss: 0.3023 \n",
      "\n",
      "Epoch: [68/100], Step: [3100/6250], Loss: 0.8948 \n",
      "\n",
      "Epoch: [68/100], Step: [3200/6250], Loss: 0.1476 \n",
      "\n",
      "Epoch: [68/100], Step: [3300/6250], Loss: 0.7518 \n",
      "\n",
      "Epoch: [68/100], Step: [3400/6250], Loss: 0.9828 \n",
      "\n",
      "Epoch: [68/100], Step: [3500/6250], Loss: 0.2116 \n",
      "\n",
      "Epoch: [68/100], Step: [3600/6250], Loss: 0.1986 \n",
      "\n",
      "Epoch: [68/100], Step: [3700/6250], Loss: 1.0371 \n",
      "\n",
      "Epoch: [68/100], Step: [3800/6250], Loss: 1.3904 \n",
      "\n",
      "Epoch: [68/100], Step: [3900/6250], Loss: 0.7791 \n",
      "\n",
      "Epoch: [68/100], Step: [4000/6250], Loss: 0.6640 \n",
      "\n",
      "Epoch: [68/100], Step: [4100/6250], Loss: 0.4483 \n",
      "\n",
      "Epoch: [68/100], Step: [4200/6250], Loss: 1.1513 \n",
      "\n",
      "Epoch: [68/100], Step: [4300/6250], Loss: 0.4122 \n",
      "\n",
      "Epoch: [68/100], Step: [4400/6250], Loss: 0.8907 \n",
      "\n",
      "Epoch: [68/100], Step: [4500/6250], Loss: 0.7801 \n",
      "\n",
      "Epoch: [68/100], Step: [4600/6250], Loss: 0.5204 \n",
      "\n",
      "Epoch: [68/100], Step: [4700/6250], Loss: 0.1294 \n",
      "\n",
      "Epoch: [68/100], Step: [4800/6250], Loss: 0.9565 \n",
      "\n",
      "Epoch: [68/100], Step: [4900/6250], Loss: 0.3180 \n",
      "\n",
      "Epoch: [68/100], Step: [5000/6250], Loss: 0.2652 \n",
      "\n",
      "Epoch: [68/100], Step: [5100/6250], Loss: 0.2730 \n",
      "\n",
      "Epoch: [68/100], Step: [5200/6250], Loss: 0.8124 \n",
      "\n",
      "Epoch: [68/100], Step: [5300/6250], Loss: 1.1825 \n",
      "\n",
      "Epoch: [68/100], Step: [5400/6250], Loss: 0.1579 \n",
      "\n",
      "Epoch: [68/100], Step: [5500/6250], Loss: 0.2334 \n",
      "\n",
      "Epoch: [68/100], Step: [5600/6250], Loss: 0.3036 \n",
      "\n",
      "Epoch: [68/100], Step: [5700/6250], Loss: 0.2187 \n",
      "\n",
      "Epoch: [68/100], Step: [5800/6250], Loss: 0.2981 \n",
      "\n",
      "Epoch: [68/100], Step: [5900/6250], Loss: 0.6303 \n",
      "\n",
      "Epoch: [68/100], Step: [6000/6250], Loss: 0.5945 \n",
      "\n",
      "Epoch: [68/100], Step: [6100/6250], Loss: 0.7977 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [68/100], Step: [6200/6250], Loss: 0.0857 \n",
      "\n",
      "Epoch: [69/100], Step: [100/6250], Loss: 1.3313 \n",
      "\n",
      "Epoch: [69/100], Step: [200/6250], Loss: 0.6592 \n",
      "\n",
      "Epoch: [69/100], Step: [300/6250], Loss: 0.8496 \n",
      "\n",
      "Epoch: [69/100], Step: [400/6250], Loss: 0.7756 \n",
      "\n",
      "Epoch: [69/100], Step: [500/6250], Loss: 0.9011 \n",
      "\n",
      "Epoch: [69/100], Step: [600/6250], Loss: 0.3035 \n",
      "\n",
      "Epoch: [69/100], Step: [700/6250], Loss: 0.3278 \n",
      "\n",
      "Epoch: [69/100], Step: [800/6250], Loss: 0.2336 \n",
      "\n",
      "Epoch: [69/100], Step: [900/6250], Loss: 0.5997 \n",
      "\n",
      "Epoch: [69/100], Step: [1000/6250], Loss: 0.1181 \n",
      "\n",
      "Epoch: [69/100], Step: [1100/6250], Loss: 0.4878 \n",
      "\n",
      "Epoch: [69/100], Step: [1200/6250], Loss: 0.5321 \n",
      "\n",
      "Epoch: [69/100], Step: [1300/6250], Loss: 0.4043 \n",
      "\n",
      "Epoch: [69/100], Step: [1400/6250], Loss: 0.4953 \n",
      "\n",
      "Epoch: [69/100], Step: [1500/6250], Loss: 0.3007 \n",
      "\n",
      "Epoch: [69/100], Step: [1600/6250], Loss: 0.2865 \n",
      "\n",
      "Epoch: [69/100], Step: [1700/6250], Loss: 0.7410 \n",
      "\n",
      "Epoch: [69/100], Step: [1800/6250], Loss: 0.7024 \n",
      "\n",
      "Epoch: [69/100], Step: [1900/6250], Loss: 0.4732 \n",
      "\n",
      "Epoch: [69/100], Step: [2000/6250], Loss: 0.1722 \n",
      "\n",
      "Epoch: [69/100], Step: [2100/6250], Loss: 0.3582 \n",
      "\n",
      "Epoch: [69/100], Step: [2200/6250], Loss: 0.5189 \n",
      "\n",
      "Epoch: [69/100], Step: [2300/6250], Loss: 0.4640 \n",
      "\n",
      "Epoch: [69/100], Step: [2400/6250], Loss: 0.5828 \n",
      "\n",
      "Epoch: [69/100], Step: [2500/6250], Loss: 1.3848 \n",
      "\n",
      "Epoch: [69/100], Step: [2600/6250], Loss: 0.4484 \n",
      "\n",
      "Epoch: [69/100], Step: [2700/6250], Loss: 0.1740 \n",
      "\n",
      "Epoch: [69/100], Step: [2800/6250], Loss: 0.2752 \n",
      "\n",
      "Epoch: [69/100], Step: [2900/6250], Loss: 0.5988 \n",
      "\n",
      "Epoch: [69/100], Step: [3000/6250], Loss: 0.6104 \n",
      "\n",
      "Epoch: [69/100], Step: [3100/6250], Loss: 0.2846 \n",
      "\n",
      "Epoch: [69/100], Step: [3200/6250], Loss: 0.7866 \n",
      "\n",
      "Epoch: [69/100], Step: [3300/6250], Loss: 0.8824 \n",
      "\n",
      "Epoch: [69/100], Step: [3400/6250], Loss: 0.8876 \n",
      "\n",
      "Epoch: [69/100], Step: [3500/6250], Loss: 0.7314 \n",
      "\n",
      "Epoch: [69/100], Step: [3600/6250], Loss: 0.3071 \n",
      "\n",
      "Epoch: [69/100], Step: [3700/6250], Loss: 0.4427 \n",
      "\n",
      "Epoch: [69/100], Step: [3800/6250], Loss: 0.7095 \n",
      "\n",
      "Epoch: [69/100], Step: [3900/6250], Loss: 0.5749 \n",
      "\n",
      "Epoch: [69/100], Step: [4000/6250], Loss: 0.4879 \n",
      "\n",
      "Epoch: [69/100], Step: [4100/6250], Loss: 0.3206 \n",
      "\n",
      "Epoch: [69/100], Step: [4200/6250], Loss: 0.8774 \n",
      "\n",
      "Epoch: [69/100], Step: [4300/6250], Loss: 0.6218 \n",
      "\n",
      "Epoch: [69/100], Step: [4400/6250], Loss: 0.7401 \n",
      "\n",
      "Epoch: [69/100], Step: [4500/6250], Loss: 0.4361 \n",
      "\n",
      "Epoch: [69/100], Step: [4600/6250], Loss: 1.0445 \n",
      "\n",
      "Epoch: [69/100], Step: [4700/6250], Loss: 0.3091 \n",
      "\n",
      "Epoch: [69/100], Step: [4800/6250], Loss: 0.3079 \n",
      "\n",
      "Epoch: [69/100], Step: [4900/6250], Loss: 0.7015 \n",
      "\n",
      "Epoch: [69/100], Step: [5000/6250], Loss: 0.5735 \n",
      "\n",
      "Epoch: [69/100], Step: [5100/6250], Loss: 0.6535 \n",
      "\n",
      "Epoch: [69/100], Step: [5200/6250], Loss: 1.0722 \n",
      "\n",
      "Epoch: [69/100], Step: [5300/6250], Loss: 0.4965 \n",
      "\n",
      "Epoch: [69/100], Step: [5400/6250], Loss: 0.6822 \n",
      "\n",
      "Epoch: [69/100], Step: [5500/6250], Loss: 0.6558 \n",
      "\n",
      "Epoch: [69/100], Step: [5600/6250], Loss: 0.2884 \n",
      "\n",
      "Epoch: [69/100], Step: [5700/6250], Loss: 0.8662 \n",
      "\n",
      "Epoch: [69/100], Step: [5800/6250], Loss: 0.7407 \n",
      "\n",
      "Epoch: [69/100], Step: [5900/6250], Loss: 0.5438 \n",
      "\n",
      "Epoch: [69/100], Step: [6000/6250], Loss: 0.3360 \n",
      "\n",
      "Epoch: [69/100], Step: [6100/6250], Loss: 0.3941 \n",
      "\n",
      "Epoch: [69/100], Step: [6200/6250], Loss: 0.5619 \n",
      "\n",
      "Epoch: [70/100], Step: [100/6250], Loss: 0.5008 \n",
      "\n",
      "Epoch: [70/100], Step: [200/6250], Loss: 0.6395 \n",
      "\n",
      "Epoch: [70/100], Step: [300/6250], Loss: 0.6893 \n",
      "\n",
      "Epoch: [70/100], Step: [400/6250], Loss: 0.4855 \n",
      "\n",
      "Epoch: [70/100], Step: [500/6250], Loss: 0.8521 \n",
      "\n",
      "Epoch: [70/100], Step: [600/6250], Loss: 0.7432 \n",
      "\n",
      "Epoch: [70/100], Step: [700/6250], Loss: 0.8909 \n",
      "\n",
      "Epoch: [70/100], Step: [800/6250], Loss: 0.4150 \n",
      "\n",
      "Epoch: [70/100], Step: [900/6250], Loss: 0.4029 \n",
      "\n",
      "Epoch: [70/100], Step: [1000/6250], Loss: 0.6164 \n",
      "\n",
      "Epoch: [70/100], Step: [1100/6250], Loss: 0.4769 \n",
      "\n",
      "Epoch: [70/100], Step: [1200/6250], Loss: 0.6454 \n",
      "\n",
      "Epoch: [70/100], Step: [1300/6250], Loss: 0.6676 \n",
      "\n",
      "Epoch: [70/100], Step: [1400/6250], Loss: 1.0461 \n",
      "\n",
      "Epoch: [70/100], Step: [1500/6250], Loss: 0.1110 \n",
      "\n",
      "Epoch: [70/100], Step: [1600/6250], Loss: 0.7228 \n",
      "\n",
      "Epoch: [70/100], Step: [1700/6250], Loss: 0.5696 \n",
      "\n",
      "Epoch: [70/100], Step: [1800/6250], Loss: 0.1991 \n",
      "\n",
      "Epoch: [70/100], Step: [1900/6250], Loss: 0.5882 \n",
      "\n",
      "Epoch: [70/100], Step: [2000/6250], Loss: 0.5688 \n",
      "\n",
      "Epoch: [70/100], Step: [2100/6250], Loss: 0.2867 \n",
      "\n",
      "Epoch: [70/100], Step: [2200/6250], Loss: 0.2643 \n",
      "\n",
      "Epoch: [70/100], Step: [2300/6250], Loss: 0.2768 \n",
      "\n",
      "Epoch: [70/100], Step: [2400/6250], Loss: 0.2117 \n",
      "\n",
      "Epoch: [70/100], Step: [2500/6250], Loss: 0.7093 \n",
      "\n",
      "Epoch: [70/100], Step: [2600/6250], Loss: 0.9781 \n",
      "\n",
      "Epoch: [70/100], Step: [2700/6250], Loss: 1.0551 \n",
      "\n",
      "Epoch: [70/100], Step: [2800/6250], Loss: 0.6502 \n",
      "\n",
      "Epoch: [70/100], Step: [2900/6250], Loss: 0.9412 \n",
      "\n",
      "Epoch: [70/100], Step: [3000/6250], Loss: 1.0668 \n",
      "\n",
      "Epoch: [70/100], Step: [3100/6250], Loss: 0.2556 \n",
      "\n",
      "Epoch: [70/100], Step: [3200/6250], Loss: 0.3334 \n",
      "\n",
      "Epoch: [70/100], Step: [3300/6250], Loss: 0.8136 \n",
      "\n",
      "Epoch: [70/100], Step: [3400/6250], Loss: 0.7309 \n",
      "\n",
      "Epoch: [70/100], Step: [3500/6250], Loss: 0.8850 \n",
      "\n",
      "Epoch: [70/100], Step: [3600/6250], Loss: 1.0783 \n",
      "\n",
      "Epoch: [70/100], Step: [3700/6250], Loss: 1.3111 \n",
      "\n",
      "Epoch: [70/100], Step: [3800/6250], Loss: 0.6569 \n",
      "\n",
      "Epoch: [70/100], Step: [3900/6250], Loss: 0.5027 \n",
      "\n",
      "Epoch: [70/100], Step: [4000/6250], Loss: 0.5298 \n",
      "\n",
      "Epoch: [70/100], Step: [4100/6250], Loss: 0.3290 \n",
      "\n",
      "Epoch: [70/100], Step: [4200/6250], Loss: 0.1701 \n",
      "\n",
      "Epoch: [70/100], Step: [4300/6250], Loss: 0.2603 \n",
      "\n",
      "Epoch: [70/100], Step: [4400/6250], Loss: 0.5729 \n",
      "\n",
      "Epoch: [70/100], Step: [4500/6250], Loss: 0.9770 \n",
      "\n",
      "Epoch: [70/100], Step: [4600/6250], Loss: 1.1423 \n",
      "\n",
      "Epoch: [70/100], Step: [4700/6250], Loss: 0.4221 \n",
      "\n",
      "Epoch: [70/100], Step: [4800/6250], Loss: 0.6101 \n",
      "\n",
      "Epoch: [70/100], Step: [4900/6250], Loss: 1.1567 \n",
      "\n",
      "Epoch: [70/100], Step: [5000/6250], Loss: 0.6172 \n",
      "\n",
      "Epoch: [70/100], Step: [5100/6250], Loss: 0.1092 \n",
      "\n",
      "Epoch: [70/100], Step: [5200/6250], Loss: 0.4083 \n",
      "\n",
      "Epoch: [70/100], Step: [5300/6250], Loss: 1.1683 \n",
      "\n",
      "Epoch: [70/100], Step: [5400/6250], Loss: 0.4423 \n",
      "\n",
      "Epoch: [70/100], Step: [5500/6250], Loss: 0.4323 \n",
      "\n",
      "Epoch: [70/100], Step: [5600/6250], Loss: 0.2523 \n",
      "\n",
      "Epoch: [70/100], Step: [5700/6250], Loss: 0.4396 \n",
      "\n",
      "Epoch: [70/100], Step: [5800/6250], Loss: 0.5485 \n",
      "\n",
      "Epoch: [70/100], Step: [5900/6250], Loss: 1.1770 \n",
      "\n",
      "Epoch: [70/100], Step: [6000/6250], Loss: 0.5973 \n",
      "\n",
      "Epoch: [70/100], Step: [6100/6250], Loss: 0.3036 \n",
      "\n",
      "Epoch: [70/100], Step: [6200/6250], Loss: 0.1665 \n",
      "\n",
      "Epoch: [71/100], Step: [100/6250], Loss: 0.5498 \n",
      "\n",
      "Epoch: [71/100], Step: [200/6250], Loss: 0.4472 \n",
      "\n",
      "Epoch: [71/100], Step: [300/6250], Loss: 1.0998 \n",
      "\n",
      "Epoch: [71/100], Step: [400/6250], Loss: 0.6951 \n",
      "\n",
      "Epoch: [71/100], Step: [500/6250], Loss: 0.2044 \n",
      "\n",
      "Epoch: [71/100], Step: [600/6250], Loss: 0.0768 \n",
      "\n",
      "Epoch: [71/100], Step: [700/6250], Loss: 0.1438 \n",
      "\n",
      "Epoch: [71/100], Step: [800/6250], Loss: 0.3091 \n",
      "\n",
      "Epoch: [71/100], Step: [900/6250], Loss: 0.2734 \n",
      "\n",
      "Epoch: [71/100], Step: [1000/6250], Loss: 0.1430 \n",
      "\n",
      "Epoch: [71/100], Step: [1100/6250], Loss: 0.3688 \n",
      "\n",
      "Epoch: [71/100], Step: [1200/6250], Loss: 0.3311 \n",
      "\n",
      "Epoch: [71/100], Step: [1300/6250], Loss: 0.4960 \n",
      "\n",
      "Epoch: [71/100], Step: [1400/6250], Loss: 0.6859 \n",
      "\n",
      "Epoch: [71/100], Step: [1500/6250], Loss: 0.7621 \n",
      "\n",
      "Epoch: [71/100], Step: [1600/6250], Loss: 0.4400 \n",
      "\n",
      "Epoch: [71/100], Step: [1700/6250], Loss: 0.8228 \n",
      "\n",
      "Epoch: [71/100], Step: [1800/6250], Loss: 0.2610 \n",
      "\n",
      "Epoch: [71/100], Step: [1900/6250], Loss: 0.6775 \n",
      "\n",
      "Epoch: [71/100], Step: [2000/6250], Loss: 1.0551 \n",
      "\n",
      "Epoch: [71/100], Step: [2100/6250], Loss: 1.2361 \n",
      "\n",
      "Epoch: [71/100], Step: [2200/6250], Loss: 0.1395 \n",
      "\n",
      "Epoch: [71/100], Step: [2300/6250], Loss: 0.3652 \n",
      "\n",
      "Epoch: [71/100], Step: [2400/6250], Loss: 0.5525 \n",
      "\n",
      "Epoch: [71/100], Step: [2500/6250], Loss: 0.2405 \n",
      "\n",
      "Epoch: [71/100], Step: [2600/6250], Loss: 0.0593 \n",
      "\n",
      "Epoch: [71/100], Step: [2700/6250], Loss: 0.0868 \n",
      "\n",
      "Epoch: [71/100], Step: [2800/6250], Loss: 0.8836 \n",
      "\n",
      "Epoch: [71/100], Step: [2900/6250], Loss: 0.7278 \n",
      "\n",
      "Epoch: [71/100], Step: [3000/6250], Loss: 0.4104 \n",
      "\n",
      "Epoch: [71/100], Step: [3100/6250], Loss: 0.5580 \n",
      "\n",
      "Epoch: [71/100], Step: [3200/6250], Loss: 0.5536 \n",
      "\n",
      "Epoch: [71/100], Step: [3300/6250], Loss: 0.5669 \n",
      "\n",
      "Epoch: [71/100], Step: [3400/6250], Loss: 0.4959 \n",
      "\n",
      "Epoch: [71/100], Step: [3500/6250], Loss: 0.6432 \n",
      "\n",
      "Epoch: [71/100], Step: [3600/6250], Loss: 0.9449 \n",
      "\n",
      "Epoch: [71/100], Step: [3700/6250], Loss: 0.3935 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [71/100], Step: [3800/6250], Loss: 0.8112 \n",
      "\n",
      "Epoch: [71/100], Step: [3900/6250], Loss: 0.9741 \n",
      "\n",
      "Epoch: [71/100], Step: [4000/6250], Loss: 1.6133 \n",
      "\n",
      "Epoch: [71/100], Step: [4100/6250], Loss: 0.2044 \n",
      "\n",
      "Epoch: [71/100], Step: [4200/6250], Loss: 0.4801 \n",
      "\n",
      "Epoch: [71/100], Step: [4300/6250], Loss: 0.9558 \n",
      "\n",
      "Epoch: [71/100], Step: [4400/6250], Loss: 0.9357 \n",
      "\n",
      "Epoch: [71/100], Step: [4500/6250], Loss: 0.5095 \n",
      "\n",
      "Epoch: [71/100], Step: [4600/6250], Loss: 0.6725 \n",
      "\n",
      "Epoch: [71/100], Step: [4700/6250], Loss: 0.8100 \n",
      "\n",
      "Epoch: [71/100], Step: [4800/6250], Loss: 0.2656 \n",
      "\n",
      "Epoch: [71/100], Step: [4900/6250], Loss: 0.8240 \n",
      "\n",
      "Epoch: [71/100], Step: [5000/6250], Loss: 1.1529 \n",
      "\n",
      "Epoch: [71/100], Step: [5100/6250], Loss: 0.4119 \n",
      "\n",
      "Epoch: [71/100], Step: [5200/6250], Loss: 0.6736 \n",
      "\n",
      "Epoch: [71/100], Step: [5300/6250], Loss: 0.8820 \n",
      "\n",
      "Epoch: [71/100], Step: [5400/6250], Loss: 0.8574 \n",
      "\n",
      "Epoch: [71/100], Step: [5500/6250], Loss: 0.3716 \n",
      "\n",
      "Epoch: [71/100], Step: [5600/6250], Loss: 0.3572 \n",
      "\n",
      "Epoch: [71/100], Step: [5700/6250], Loss: 0.5350 \n",
      "\n",
      "Epoch: [71/100], Step: [5800/6250], Loss: 0.5049 \n",
      "\n",
      "Epoch: [71/100], Step: [5900/6250], Loss: 0.5899 \n",
      "\n",
      "Epoch: [71/100], Step: [6000/6250], Loss: 0.2002 \n",
      "\n",
      "Epoch: [71/100], Step: [6100/6250], Loss: 0.5773 \n",
      "\n",
      "Epoch: [71/100], Step: [6200/6250], Loss: 0.3053 \n",
      "\n",
      "Epoch: [72/100], Step: [100/6250], Loss: 0.0999 \n",
      "\n",
      "Epoch: [72/100], Step: [200/6250], Loss: 0.6303 \n",
      "\n",
      "Epoch: [72/100], Step: [300/6250], Loss: 0.3156 \n",
      "\n",
      "Epoch: [72/100], Step: [400/6250], Loss: 0.8150 \n",
      "\n",
      "Epoch: [72/100], Step: [500/6250], Loss: 0.1217 \n",
      "\n",
      "Epoch: [72/100], Step: [600/6250], Loss: 0.4048 \n",
      "\n",
      "Epoch: [72/100], Step: [700/6250], Loss: 0.1084 \n",
      "\n",
      "Epoch: [72/100], Step: [800/6250], Loss: 0.2009 \n",
      "\n",
      "Epoch: [72/100], Step: [900/6250], Loss: 0.3379 \n",
      "\n",
      "Epoch: [72/100], Step: [1000/6250], Loss: 0.4800 \n",
      "\n",
      "Epoch: [72/100], Step: [1100/6250], Loss: 1.1095 \n",
      "\n",
      "Epoch: [72/100], Step: [1200/6250], Loss: 0.4410 \n",
      "\n",
      "Epoch: [72/100], Step: [1300/6250], Loss: 1.7833 \n",
      "\n",
      "Epoch: [72/100], Step: [1400/6250], Loss: 0.3086 \n",
      "\n",
      "Epoch: [72/100], Step: [1500/6250], Loss: 0.6324 \n",
      "\n",
      "Epoch: [72/100], Step: [1600/6250], Loss: 0.7113 \n",
      "\n",
      "Epoch: [72/100], Step: [1700/6250], Loss: 1.0794 \n",
      "\n",
      "Epoch: [72/100], Step: [1800/6250], Loss: 0.1665 \n",
      "\n",
      "Epoch: [72/100], Step: [1900/6250], Loss: 0.5233 \n",
      "\n",
      "Epoch: [72/100], Step: [2000/6250], Loss: 0.5681 \n",
      "\n",
      "Epoch: [72/100], Step: [2100/6250], Loss: 0.5521 \n",
      "\n",
      "Epoch: [72/100], Step: [2200/6250], Loss: 1.0519 \n",
      "\n",
      "Epoch: [72/100], Step: [2300/6250], Loss: 0.7598 \n",
      "\n",
      "Epoch: [72/100], Step: [2400/6250], Loss: 0.6020 \n",
      "\n",
      "Epoch: [72/100], Step: [2500/6250], Loss: 0.6074 \n",
      "\n",
      "Epoch: [72/100], Step: [2600/6250], Loss: 0.6591 \n",
      "\n",
      "Epoch: [72/100], Step: [2700/6250], Loss: 0.3330 \n",
      "\n",
      "Epoch: [72/100], Step: [2800/6250], Loss: 0.4103 \n",
      "\n",
      "Epoch: [72/100], Step: [2900/6250], Loss: 1.2735 \n",
      "\n",
      "Epoch: [72/100], Step: [3000/6250], Loss: 0.3288 \n",
      "\n",
      "Epoch: [72/100], Step: [3100/6250], Loss: 0.2703 \n",
      "\n",
      "Epoch: [72/100], Step: [3200/6250], Loss: 0.3562 \n",
      "\n",
      "Epoch: [72/100], Step: [3300/6250], Loss: 0.8144 \n",
      "\n",
      "Epoch: [72/100], Step: [3400/6250], Loss: 0.7511 \n",
      "\n",
      "Epoch: [72/100], Step: [3500/6250], Loss: 0.2718 \n",
      "\n",
      "Epoch: [72/100], Step: [3600/6250], Loss: 1.0347 \n",
      "\n",
      "Epoch: [72/100], Step: [3700/6250], Loss: 1.4378 \n",
      "\n",
      "Epoch: [72/100], Step: [3800/6250], Loss: 0.2182 \n",
      "\n",
      "Epoch: [72/100], Step: [3900/6250], Loss: 0.4058 \n",
      "\n",
      "Epoch: [72/100], Step: [4000/6250], Loss: 1.3441 \n",
      "\n",
      "Epoch: [72/100], Step: [4100/6250], Loss: 1.3001 \n",
      "\n",
      "Epoch: [72/100], Step: [4200/6250], Loss: 0.5596 \n",
      "\n",
      "Epoch: [72/100], Step: [4300/6250], Loss: 0.6826 \n",
      "\n",
      "Epoch: [72/100], Step: [4400/6250], Loss: 0.5098 \n",
      "\n",
      "Epoch: [72/100], Step: [4500/6250], Loss: 0.4081 \n",
      "\n",
      "Epoch: [72/100], Step: [4600/6250], Loss: 0.4240 \n",
      "\n",
      "Epoch: [72/100], Step: [4700/6250], Loss: 0.5360 \n",
      "\n",
      "Epoch: [72/100], Step: [4800/6250], Loss: 0.9417 \n",
      "\n",
      "Epoch: [72/100], Step: [4900/6250], Loss: 0.8551 \n",
      "\n",
      "Epoch: [72/100], Step: [5000/6250], Loss: 0.1466 \n",
      "\n",
      "Epoch: [72/100], Step: [5100/6250], Loss: 0.6266 \n",
      "\n",
      "Epoch: [72/100], Step: [5200/6250], Loss: 0.3202 \n",
      "\n",
      "Epoch: [72/100], Step: [5300/6250], Loss: 0.3957 \n",
      "\n",
      "Epoch: [72/100], Step: [5400/6250], Loss: 0.3640 \n",
      "\n",
      "Epoch: [72/100], Step: [5500/6250], Loss: 0.3663 \n",
      "\n",
      "Epoch: [72/100], Step: [5600/6250], Loss: 0.8585 \n",
      "\n",
      "Epoch: [72/100], Step: [5700/6250], Loss: 0.6956 \n",
      "\n",
      "Epoch: [72/100], Step: [5800/6250], Loss: 0.3307 \n",
      "\n",
      "Epoch: [72/100], Step: [5900/6250], Loss: 0.5564 \n",
      "\n",
      "Epoch: [72/100], Step: [6000/6250], Loss: 0.4416 \n",
      "\n",
      "Epoch: [72/100], Step: [6100/6250], Loss: 0.9470 \n",
      "\n",
      "Epoch: [72/100], Step: [6200/6250], Loss: 0.2668 \n",
      "\n",
      "Epoch: [73/100], Step: [100/6250], Loss: 0.3657 \n",
      "\n",
      "Epoch: [73/100], Step: [200/6250], Loss: 0.3340 \n",
      "\n",
      "Epoch: [73/100], Step: [300/6250], Loss: 0.3732 \n",
      "\n",
      "Epoch: [73/100], Step: [400/6250], Loss: 0.2954 \n",
      "\n",
      "Epoch: [73/100], Step: [500/6250], Loss: 1.3672 \n",
      "\n",
      "Epoch: [73/100], Step: [600/6250], Loss: 0.2968 \n",
      "\n",
      "Epoch: [73/100], Step: [700/6250], Loss: 0.6384 \n",
      "\n",
      "Epoch: [73/100], Step: [800/6250], Loss: 0.2712 \n",
      "\n",
      "Epoch: [73/100], Step: [900/6250], Loss: 0.1620 \n",
      "\n",
      "Epoch: [73/100], Step: [1000/6250], Loss: 0.6948 \n",
      "\n",
      "Epoch: [73/100], Step: [1100/6250], Loss: 0.8120 \n",
      "\n",
      "Epoch: [73/100], Step: [1200/6250], Loss: 0.9301 \n",
      "\n",
      "Epoch: [73/100], Step: [1300/6250], Loss: 0.3003 \n",
      "\n",
      "Epoch: [73/100], Step: [1400/6250], Loss: 0.3322 \n",
      "\n",
      "Epoch: [73/100], Step: [1500/6250], Loss: 0.2125 \n",
      "\n",
      "Epoch: [73/100], Step: [1600/6250], Loss: 0.5115 \n",
      "\n",
      "Epoch: [73/100], Step: [1700/6250], Loss: 0.3390 \n",
      "\n",
      "Epoch: [73/100], Step: [1800/6250], Loss: 0.3798 \n",
      "\n",
      "Epoch: [73/100], Step: [1900/6250], Loss: 0.5120 \n",
      "\n",
      "Epoch: [73/100], Step: [2000/6250], Loss: 0.3483 \n",
      "\n",
      "Epoch: [73/100], Step: [2100/6250], Loss: 0.4005 \n",
      "\n",
      "Epoch: [73/100], Step: [2200/6250], Loss: 0.6946 \n",
      "\n",
      "Epoch: [73/100], Step: [2300/6250], Loss: 0.3168 \n",
      "\n",
      "Epoch: [73/100], Step: [2400/6250], Loss: 0.5175 \n",
      "\n",
      "Epoch: [73/100], Step: [2500/6250], Loss: 0.7954 \n",
      "\n",
      "Epoch: [73/100], Step: [2600/6250], Loss: 0.4336 \n",
      "\n",
      "Epoch: [73/100], Step: [2700/6250], Loss: 0.7905 \n",
      "\n",
      "Epoch: [73/100], Step: [2800/6250], Loss: 0.4018 \n",
      "\n",
      "Epoch: [73/100], Step: [2900/6250], Loss: 0.5267 \n",
      "\n",
      "Epoch: [73/100], Step: [3000/6250], Loss: 0.5748 \n",
      "\n",
      "Epoch: [73/100], Step: [3100/6250], Loss: 0.4193 \n",
      "\n",
      "Epoch: [73/100], Step: [3200/6250], Loss: 0.2523 \n",
      "\n",
      "Epoch: [73/100], Step: [3300/6250], Loss: 0.9986 \n",
      "\n",
      "Epoch: [73/100], Step: [3400/6250], Loss: 0.9195 \n",
      "\n",
      "Epoch: [73/100], Step: [3500/6250], Loss: 0.2052 \n",
      "\n",
      "Epoch: [73/100], Step: [3600/6250], Loss: 0.3533 \n",
      "\n",
      "Epoch: [73/100], Step: [3700/6250], Loss: 0.8741 \n",
      "\n",
      "Epoch: [73/100], Step: [3800/6250], Loss: 0.8203 \n",
      "\n",
      "Epoch: [73/100], Step: [3900/6250], Loss: 0.6416 \n",
      "\n",
      "Epoch: [73/100], Step: [4000/6250], Loss: 0.2311 \n",
      "\n",
      "Epoch: [73/100], Step: [4100/6250], Loss: 0.7063 \n",
      "\n",
      "Epoch: [73/100], Step: [4200/6250], Loss: 0.6045 \n",
      "\n",
      "Epoch: [73/100], Step: [4300/6250], Loss: 0.3127 \n",
      "\n",
      "Epoch: [73/100], Step: [4400/6250], Loss: 0.3672 \n",
      "\n",
      "Epoch: [73/100], Step: [4500/6250], Loss: 0.5813 \n",
      "\n",
      "Epoch: [73/100], Step: [4600/6250], Loss: 0.3288 \n",
      "\n",
      "Epoch: [73/100], Step: [4700/6250], Loss: 0.0646 \n",
      "\n",
      "Epoch: [73/100], Step: [4800/6250], Loss: 0.1479 \n",
      "\n",
      "Epoch: [73/100], Step: [4900/6250], Loss: 0.1715 \n",
      "\n",
      "Epoch: [73/100], Step: [5000/6250], Loss: 0.7095 \n",
      "\n",
      "Epoch: [73/100], Step: [5100/6250], Loss: 0.5260 \n",
      "\n",
      "Epoch: [73/100], Step: [5200/6250], Loss: 0.2222 \n",
      "\n",
      "Epoch: [73/100], Step: [5300/6250], Loss: 0.6872 \n",
      "\n",
      "Epoch: [73/100], Step: [5400/6250], Loss: 0.5898 \n",
      "\n",
      "Epoch: [73/100], Step: [5500/6250], Loss: 0.9316 \n",
      "\n",
      "Epoch: [73/100], Step: [5600/6250], Loss: 0.3010 \n",
      "\n",
      "Epoch: [73/100], Step: [5700/6250], Loss: 0.9277 \n",
      "\n",
      "Epoch: [73/100], Step: [5800/6250], Loss: 0.5986 \n",
      "\n",
      "Epoch: [73/100], Step: [5900/6250], Loss: 0.7113 \n",
      "\n",
      "Epoch: [73/100], Step: [6000/6250], Loss: 0.0611 \n",
      "\n",
      "Epoch: [73/100], Step: [6100/6250], Loss: 1.1206 \n",
      "\n",
      "Epoch: [73/100], Step: [6200/6250], Loss: 0.2982 \n",
      "\n",
      "Epoch: [74/100], Step: [100/6250], Loss: 0.2232 \n",
      "\n",
      "Epoch: [74/100], Step: [200/6250], Loss: 0.4569 \n",
      "\n",
      "Epoch: [74/100], Step: [300/6250], Loss: 0.5260 \n",
      "\n",
      "Epoch: [74/100], Step: [400/6250], Loss: 0.1998 \n",
      "\n",
      "Epoch: [74/100], Step: [500/6250], Loss: 0.1483 \n",
      "\n",
      "Epoch: [74/100], Step: [600/6250], Loss: 0.6806 \n",
      "\n",
      "Epoch: [74/100], Step: [700/6250], Loss: 0.1160 \n",
      "\n",
      "Epoch: [74/100], Step: [800/6250], Loss: 1.6503 \n",
      "\n",
      "Epoch: [74/100], Step: [900/6250], Loss: 0.3625 \n",
      "\n",
      "Epoch: [74/100], Step: [1000/6250], Loss: 0.3907 \n",
      "\n",
      "Epoch: [74/100], Step: [1100/6250], Loss: 0.2401 \n",
      "\n",
      "Epoch: [74/100], Step: [1200/6250], Loss: 0.7928 \n",
      "\n",
      "Epoch: [74/100], Step: [1300/6250], Loss: 0.8217 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [74/100], Step: [1400/6250], Loss: 0.1633 \n",
      "\n",
      "Epoch: [74/100], Step: [1500/6250], Loss: 0.3711 \n",
      "\n",
      "Epoch: [74/100], Step: [1600/6250], Loss: 0.5379 \n",
      "\n",
      "Epoch: [74/100], Step: [1700/6250], Loss: 0.9605 \n",
      "\n",
      "Epoch: [74/100], Step: [1800/6250], Loss: 0.9105 \n",
      "\n",
      "Epoch: [74/100], Step: [1900/6250], Loss: 0.4083 \n",
      "\n",
      "Epoch: [74/100], Step: [2000/6250], Loss: 1.4992 \n",
      "\n",
      "Epoch: [74/100], Step: [2100/6250], Loss: 0.3036 \n",
      "\n",
      "Epoch: [74/100], Step: [2200/6250], Loss: 0.6738 \n",
      "\n",
      "Epoch: [74/100], Step: [2300/6250], Loss: 0.4971 \n",
      "\n",
      "Epoch: [74/100], Step: [2400/6250], Loss: 0.9447 \n",
      "\n",
      "Epoch: [74/100], Step: [2500/6250], Loss: 1.3642 \n",
      "\n",
      "Epoch: [74/100], Step: [2600/6250], Loss: 0.4890 \n",
      "\n",
      "Epoch: [74/100], Step: [2700/6250], Loss: 0.3841 \n",
      "\n",
      "Epoch: [74/100], Step: [2800/6250], Loss: 0.8525 \n",
      "\n",
      "Epoch: [74/100], Step: [2900/6250], Loss: 0.1471 \n",
      "\n",
      "Epoch: [74/100], Step: [3000/6250], Loss: 0.4093 \n",
      "\n",
      "Epoch: [74/100], Step: [3100/6250], Loss: 0.2497 \n",
      "\n",
      "Epoch: [74/100], Step: [3200/6250], Loss: 0.7862 \n",
      "\n",
      "Epoch: [74/100], Step: [3300/6250], Loss: 0.4983 \n",
      "\n",
      "Epoch: [74/100], Step: [3400/6250], Loss: 0.7271 \n",
      "\n",
      "Epoch: [74/100], Step: [3500/6250], Loss: 1.2153 \n",
      "\n",
      "Epoch: [74/100], Step: [3600/6250], Loss: 0.5934 \n",
      "\n",
      "Epoch: [74/100], Step: [3700/6250], Loss: 0.3781 \n",
      "\n",
      "Epoch: [74/100], Step: [3800/6250], Loss: 0.2978 \n",
      "\n",
      "Epoch: [74/100], Step: [3900/6250], Loss: 0.6799 \n",
      "\n",
      "Epoch: [74/100], Step: [4000/6250], Loss: 0.7410 \n",
      "\n",
      "Epoch: [74/100], Step: [4100/6250], Loss: 0.6596 \n",
      "\n",
      "Epoch: [74/100], Step: [4200/6250], Loss: 0.4287 \n",
      "\n",
      "Epoch: [74/100], Step: [4300/6250], Loss: 0.3492 \n",
      "\n",
      "Epoch: [74/100], Step: [4400/6250], Loss: 0.3503 \n",
      "\n",
      "Epoch: [74/100], Step: [4500/6250], Loss: 0.2374 \n",
      "\n",
      "Epoch: [74/100], Step: [4600/6250], Loss: 0.1825 \n",
      "\n",
      "Epoch: [74/100], Step: [4700/6250], Loss: 0.5952 \n",
      "\n",
      "Epoch: [74/100], Step: [4800/6250], Loss: 0.4773 \n",
      "\n",
      "Epoch: [74/100], Step: [4900/6250], Loss: 0.5283 \n",
      "\n",
      "Epoch: [74/100], Step: [5000/6250], Loss: 0.6311 \n",
      "\n",
      "Epoch: [74/100], Step: [5100/6250], Loss: 0.1733 \n",
      "\n",
      "Epoch: [74/100], Step: [5200/6250], Loss: 0.4449 \n",
      "\n",
      "Epoch: [74/100], Step: [5300/6250], Loss: 0.3322 \n",
      "\n",
      "Epoch: [74/100], Step: [5400/6250], Loss: 0.4036 \n",
      "\n",
      "Epoch: [74/100], Step: [5500/6250], Loss: 0.1617 \n",
      "\n",
      "Epoch: [74/100], Step: [5600/6250], Loss: 0.2442 \n",
      "\n",
      "Epoch: [74/100], Step: [5700/6250], Loss: 0.6281 \n",
      "\n",
      "Epoch: [74/100], Step: [5800/6250], Loss: 0.5405 \n",
      "\n",
      "Epoch: [74/100], Step: [5900/6250], Loss: 0.0957 \n",
      "\n",
      "Epoch: [74/100], Step: [6000/6250], Loss: 0.4529 \n",
      "\n",
      "Epoch: [74/100], Step: [6100/6250], Loss: 0.1836 \n",
      "\n",
      "Epoch: [74/100], Step: [6200/6250], Loss: 0.3736 \n",
      "\n",
      "Epoch: [75/100], Step: [100/6250], Loss: 0.2673 \n",
      "\n",
      "Epoch: [75/100], Step: [200/6250], Loss: 0.4210 \n",
      "\n",
      "Epoch: [75/100], Step: [300/6250], Loss: 0.2502 \n",
      "\n",
      "Epoch: [75/100], Step: [400/6250], Loss: 0.3973 \n",
      "\n",
      "Epoch: [75/100], Step: [500/6250], Loss: 1.4766 \n",
      "\n",
      "Epoch: [75/100], Step: [600/6250], Loss: 0.3665 \n",
      "\n",
      "Epoch: [75/100], Step: [700/6250], Loss: 0.3866 \n",
      "\n",
      "Epoch: [75/100], Step: [800/6250], Loss: 0.6523 \n",
      "\n",
      "Epoch: [75/100], Step: [900/6250], Loss: 0.2749 \n",
      "\n",
      "Epoch: [75/100], Step: [1000/6250], Loss: 0.7649 \n",
      "\n",
      "Epoch: [75/100], Step: [1100/6250], Loss: 0.4512 \n",
      "\n",
      "Epoch: [75/100], Step: [1200/6250], Loss: 0.3255 \n",
      "\n",
      "Epoch: [75/100], Step: [1300/6250], Loss: 0.5636 \n",
      "\n",
      "Epoch: [75/100], Step: [1400/6250], Loss: 0.3938 \n",
      "\n",
      "Epoch: [75/100], Step: [1500/6250], Loss: 2.6942 \n",
      "\n",
      "Epoch: [75/100], Step: [1600/6250], Loss: 0.5058 \n",
      "\n",
      "Epoch: [75/100], Step: [1700/6250], Loss: 0.6754 \n",
      "\n",
      "Epoch: [75/100], Step: [1800/6250], Loss: 0.7157 \n",
      "\n",
      "Epoch: [75/100], Step: [1900/6250], Loss: 0.2395 \n",
      "\n",
      "Epoch: [75/100], Step: [2000/6250], Loss: 0.6658 \n",
      "\n",
      "Epoch: [75/100], Step: [2100/6250], Loss: 0.4085 \n",
      "\n",
      "Epoch: [75/100], Step: [2200/6250], Loss: 0.7427 \n",
      "\n",
      "Epoch: [75/100], Step: [2300/6250], Loss: 0.3074 \n",
      "\n",
      "Epoch: [75/100], Step: [2400/6250], Loss: 0.2603 \n",
      "\n",
      "Epoch: [75/100], Step: [2500/6250], Loss: 0.0493 \n",
      "\n",
      "Epoch: [75/100], Step: [2600/6250], Loss: 0.6022 \n",
      "\n",
      "Epoch: [75/100], Step: [2700/6250], Loss: 0.4528 \n",
      "\n",
      "Epoch: [75/100], Step: [2800/6250], Loss: 0.3385 \n",
      "\n",
      "Epoch: [75/100], Step: [2900/6250], Loss: 0.1726 \n",
      "\n",
      "Epoch: [75/100], Step: [3000/6250], Loss: 0.3021 \n",
      "\n",
      "Epoch: [75/100], Step: [3100/6250], Loss: 0.6446 \n",
      "\n",
      "Epoch: [75/100], Step: [3200/6250], Loss: 0.3067 \n",
      "\n",
      "Epoch: [75/100], Step: [3300/6250], Loss: 0.5325 \n",
      "\n",
      "Epoch: [75/100], Step: [3400/6250], Loss: 1.2627 \n",
      "\n",
      "Epoch: [75/100], Step: [3500/6250], Loss: 0.3360 \n",
      "\n",
      "Epoch: [75/100], Step: [3600/6250], Loss: 1.3024 \n",
      "\n",
      "Epoch: [75/100], Step: [3700/6250], Loss: 0.3384 \n",
      "\n",
      "Epoch: [75/100], Step: [3800/6250], Loss: 0.3555 \n",
      "\n",
      "Epoch: [75/100], Step: [3900/6250], Loss: 0.4534 \n",
      "\n",
      "Epoch: [75/100], Step: [4000/6250], Loss: 0.2797 \n",
      "\n",
      "Epoch: [75/100], Step: [4100/6250], Loss: 1.2877 \n",
      "\n",
      "Epoch: [75/100], Step: [4200/6250], Loss: 0.3234 \n",
      "\n",
      "Epoch: [75/100], Step: [4300/6250], Loss: 0.3646 \n",
      "\n",
      "Epoch: [75/100], Step: [4400/6250], Loss: 0.7270 \n",
      "\n",
      "Epoch: [75/100], Step: [4500/6250], Loss: 0.6307 \n",
      "\n",
      "Epoch: [75/100], Step: [4600/6250], Loss: 0.6704 \n",
      "\n",
      "Epoch: [75/100], Step: [4700/6250], Loss: 1.0691 \n",
      "\n",
      "Epoch: [75/100], Step: [4800/6250], Loss: 0.4981 \n",
      "\n",
      "Epoch: [75/100], Step: [4900/6250], Loss: 0.7570 \n",
      "\n",
      "Epoch: [75/100], Step: [5000/6250], Loss: 0.4442 \n",
      "\n",
      "Epoch: [75/100], Step: [5100/6250], Loss: 0.9621 \n",
      "\n",
      "Epoch: [75/100], Step: [5200/6250], Loss: 0.3033 \n",
      "\n",
      "Epoch: [75/100], Step: [5300/6250], Loss: 0.8110 \n",
      "\n",
      "Epoch: [75/100], Step: [5400/6250], Loss: 0.6792 \n",
      "\n",
      "Epoch: [75/100], Step: [5500/6250], Loss: 0.5150 \n",
      "\n",
      "Epoch: [75/100], Step: [5600/6250], Loss: 0.2414 \n",
      "\n",
      "Epoch: [75/100], Step: [5700/6250], Loss: 1.2587 \n",
      "\n",
      "Epoch: [75/100], Step: [5800/6250], Loss: 0.1976 \n",
      "\n",
      "Epoch: [75/100], Step: [5900/6250], Loss: 0.2130 \n",
      "\n",
      "Epoch: [75/100], Step: [6000/6250], Loss: 0.5220 \n",
      "\n",
      "Epoch: [75/100], Step: [6100/6250], Loss: 0.6299 \n",
      "\n",
      "Epoch: [75/100], Step: [6200/6250], Loss: 0.9586 \n",
      "\n",
      "Epoch: [76/100], Step: [100/6250], Loss: 0.3920 \n",
      "\n",
      "Epoch: [76/100], Step: [200/6250], Loss: 0.3091 \n",
      "\n",
      "Epoch: [76/100], Step: [300/6250], Loss: 0.2778 \n",
      "\n",
      "Epoch: [76/100], Step: [400/6250], Loss: 0.1501 \n",
      "\n",
      "Epoch: [76/100], Step: [500/6250], Loss: 0.5428 \n",
      "\n",
      "Epoch: [76/100], Step: [600/6250], Loss: 0.1449 \n",
      "\n",
      "Epoch: [76/100], Step: [700/6250], Loss: 0.5554 \n",
      "\n",
      "Epoch: [76/100], Step: [800/6250], Loss: 0.4856 \n",
      "\n",
      "Epoch: [76/100], Step: [900/6250], Loss: 0.8238 \n",
      "\n",
      "Epoch: [76/100], Step: [1000/6250], Loss: 0.3524 \n",
      "\n",
      "Epoch: [76/100], Step: [1100/6250], Loss: 0.3148 \n",
      "\n",
      "Epoch: [76/100], Step: [1200/6250], Loss: 0.3811 \n",
      "\n",
      "Epoch: [76/100], Step: [1300/6250], Loss: 0.9394 \n",
      "\n",
      "Epoch: [76/100], Step: [1400/6250], Loss: 0.4151 \n",
      "\n",
      "Epoch: [76/100], Step: [1500/6250], Loss: 0.2184 \n",
      "\n",
      "Epoch: [76/100], Step: [1600/6250], Loss: 0.2806 \n",
      "\n",
      "Epoch: [76/100], Step: [1700/6250], Loss: 0.9553 \n",
      "\n",
      "Epoch: [76/100], Step: [1800/6250], Loss: 0.5208 \n",
      "\n",
      "Epoch: [76/100], Step: [1900/6250], Loss: 0.3250 \n",
      "\n",
      "Epoch: [76/100], Step: [2000/6250], Loss: 0.5740 \n",
      "\n",
      "Epoch: [76/100], Step: [2100/6250], Loss: 1.1376 \n",
      "\n",
      "Epoch: [76/100], Step: [2200/6250], Loss: 0.2342 \n",
      "\n",
      "Epoch: [76/100], Step: [2300/6250], Loss: 0.4590 \n",
      "\n",
      "Epoch: [76/100], Step: [2400/6250], Loss: 0.1671 \n",
      "\n",
      "Epoch: [76/100], Step: [2500/6250], Loss: 1.3910 \n",
      "\n",
      "Epoch: [76/100], Step: [2600/6250], Loss: 0.2456 \n",
      "\n",
      "Epoch: [76/100], Step: [2700/6250], Loss: 0.1657 \n",
      "\n",
      "Epoch: [76/100], Step: [2800/6250], Loss: 0.5309 \n",
      "\n",
      "Epoch: [76/100], Step: [2900/6250], Loss: 0.5825 \n",
      "\n",
      "Epoch: [76/100], Step: [3000/6250], Loss: 0.1095 \n",
      "\n",
      "Epoch: [76/100], Step: [3100/6250], Loss: 0.3720 \n",
      "\n",
      "Epoch: [76/100], Step: [3200/6250], Loss: 0.2560 \n",
      "\n",
      "Epoch: [76/100], Step: [3300/6250], Loss: 0.8326 \n",
      "\n",
      "Epoch: [76/100], Step: [3400/6250], Loss: 0.5450 \n",
      "\n",
      "Epoch: [76/100], Step: [3500/6250], Loss: 0.3551 \n",
      "\n",
      "Epoch: [76/100], Step: [3600/6250], Loss: 0.3546 \n",
      "\n",
      "Epoch: [76/100], Step: [3700/6250], Loss: 0.5001 \n",
      "\n",
      "Epoch: [76/100], Step: [3800/6250], Loss: 0.4185 \n",
      "\n",
      "Epoch: [76/100], Step: [3900/6250], Loss: 0.5961 \n",
      "\n",
      "Epoch: [76/100], Step: [4000/6250], Loss: 0.3158 \n",
      "\n",
      "Epoch: [76/100], Step: [4100/6250], Loss: 0.3622 \n",
      "\n",
      "Epoch: [76/100], Step: [4200/6250], Loss: 0.5607 \n",
      "\n",
      "Epoch: [76/100], Step: [4300/6250], Loss: 0.3814 \n",
      "\n",
      "Epoch: [76/100], Step: [4400/6250], Loss: 0.8191 \n",
      "\n",
      "Epoch: [76/100], Step: [4500/6250], Loss: 0.1755 \n",
      "\n",
      "Epoch: [76/100], Step: [4600/6250], Loss: 1.2449 \n",
      "\n",
      "Epoch: [76/100], Step: [4700/6250], Loss: 0.5560 \n",
      "\n",
      "Epoch: [76/100], Step: [4800/6250], Loss: 0.3359 \n",
      "\n",
      "Epoch: [76/100], Step: [4900/6250], Loss: 0.3575 \n",
      "\n",
      "Epoch: [76/100], Step: [5000/6250], Loss: 0.6801 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [76/100], Step: [5100/6250], Loss: 0.6436 \n",
      "\n",
      "Epoch: [76/100], Step: [5200/6250], Loss: 0.3571 \n",
      "\n",
      "Epoch: [76/100], Step: [5300/6250], Loss: 1.0287 \n",
      "\n",
      "Epoch: [76/100], Step: [5400/6250], Loss: 0.1472 \n",
      "\n",
      "Epoch: [76/100], Step: [5500/6250], Loss: 0.4827 \n",
      "\n",
      "Epoch: [76/100], Step: [5600/6250], Loss: 0.4205 \n",
      "\n",
      "Epoch: [76/100], Step: [5700/6250], Loss: 0.5444 \n",
      "\n",
      "Epoch: [76/100], Step: [5800/6250], Loss: 0.1952 \n",
      "\n",
      "Epoch: [76/100], Step: [5900/6250], Loss: 0.3402 \n",
      "\n",
      "Epoch: [76/100], Step: [6000/6250], Loss: 0.7427 \n",
      "\n",
      "Epoch: [76/100], Step: [6100/6250], Loss: 0.3533 \n",
      "\n",
      "Epoch: [76/100], Step: [6200/6250], Loss: 0.3866 \n",
      "\n",
      "Epoch: [77/100], Step: [100/6250], Loss: 0.2770 \n",
      "\n",
      "Epoch: [77/100], Step: [200/6250], Loss: 0.2376 \n",
      "\n",
      "Epoch: [77/100], Step: [300/6250], Loss: 0.9919 \n",
      "\n",
      "Epoch: [77/100], Step: [400/6250], Loss: 0.6145 \n",
      "\n",
      "Epoch: [77/100], Step: [500/6250], Loss: 0.3288 \n",
      "\n",
      "Epoch: [77/100], Step: [600/6250], Loss: 1.0801 \n",
      "\n",
      "Epoch: [77/100], Step: [700/6250], Loss: 0.2911 \n",
      "\n",
      "Epoch: [77/100], Step: [800/6250], Loss: 0.3559 \n",
      "\n",
      "Epoch: [77/100], Step: [900/6250], Loss: 0.4988 \n",
      "\n",
      "Epoch: [77/100], Step: [1000/6250], Loss: 0.2941 \n",
      "\n",
      "Epoch: [77/100], Step: [1100/6250], Loss: 0.1292 \n",
      "\n",
      "Epoch: [77/100], Step: [1200/6250], Loss: 0.2616 \n",
      "\n",
      "Epoch: [77/100], Step: [1300/6250], Loss: 0.5297 \n",
      "\n",
      "Epoch: [77/100], Step: [1400/6250], Loss: 0.3833 \n",
      "\n",
      "Epoch: [77/100], Step: [1500/6250], Loss: 1.7404 \n",
      "\n",
      "Epoch: [77/100], Step: [1600/6250], Loss: 0.7115 \n",
      "\n",
      "Epoch: [77/100], Step: [1700/6250], Loss: 1.3992 \n",
      "\n",
      "Epoch: [77/100], Step: [1800/6250], Loss: 0.5677 \n",
      "\n",
      "Epoch: [77/100], Step: [1900/6250], Loss: 0.1453 \n",
      "\n",
      "Epoch: [77/100], Step: [2000/6250], Loss: 0.7032 \n",
      "\n",
      "Epoch: [77/100], Step: [2100/6250], Loss: 0.9900 \n",
      "\n",
      "Epoch: [77/100], Step: [2200/6250], Loss: 1.2608 \n",
      "\n",
      "Epoch: [77/100], Step: [2300/6250], Loss: 0.7389 \n",
      "\n",
      "Epoch: [77/100], Step: [2400/6250], Loss: 1.1732 \n",
      "\n",
      "Epoch: [77/100], Step: [2500/6250], Loss: 0.6405 \n",
      "\n",
      "Epoch: [77/100], Step: [2600/6250], Loss: 0.3407 \n",
      "\n",
      "Epoch: [77/100], Step: [2700/6250], Loss: 0.3480 \n",
      "\n",
      "Epoch: [77/100], Step: [2800/6250], Loss: 0.1239 \n",
      "\n",
      "Epoch: [77/100], Step: [2900/6250], Loss: 1.1989 \n",
      "\n",
      "Epoch: [77/100], Step: [3000/6250], Loss: 0.7501 \n",
      "\n",
      "Epoch: [77/100], Step: [3100/6250], Loss: 0.6945 \n",
      "\n",
      "Epoch: [77/100], Step: [3200/6250], Loss: 0.1569 \n",
      "\n",
      "Epoch: [77/100], Step: [3300/6250], Loss: 0.9601 \n",
      "\n",
      "Epoch: [77/100], Step: [3400/6250], Loss: 0.2391 \n",
      "\n",
      "Epoch: [77/100], Step: [3500/6250], Loss: 0.4518 \n",
      "\n",
      "Epoch: [77/100], Step: [3600/6250], Loss: 0.7137 \n",
      "\n",
      "Epoch: [77/100], Step: [3700/6250], Loss: 0.1137 \n",
      "\n",
      "Epoch: [77/100], Step: [3800/6250], Loss: 1.0091 \n",
      "\n",
      "Epoch: [77/100], Step: [3900/6250], Loss: 0.9327 \n",
      "\n",
      "Epoch: [77/100], Step: [4000/6250], Loss: 0.7040 \n",
      "\n",
      "Epoch: [77/100], Step: [4100/6250], Loss: 0.2375 \n",
      "\n",
      "Epoch: [77/100], Step: [4200/6250], Loss: 0.3493 \n",
      "\n",
      "Epoch: [77/100], Step: [4300/6250], Loss: 0.6838 \n",
      "\n",
      "Epoch: [77/100], Step: [4400/6250], Loss: 1.0190 \n",
      "\n",
      "Epoch: [77/100], Step: [4500/6250], Loss: 0.7265 \n",
      "\n",
      "Epoch: [77/100], Step: [4600/6250], Loss: 0.4313 \n",
      "\n",
      "Epoch: [77/100], Step: [4700/6250], Loss: 0.8287 \n",
      "\n",
      "Epoch: [77/100], Step: [4800/6250], Loss: 0.2335 \n",
      "\n",
      "Epoch: [77/100], Step: [4900/6250], Loss: 0.2003 \n",
      "\n",
      "Epoch: [77/100], Step: [5000/6250], Loss: 0.2604 \n",
      "\n",
      "Epoch: [77/100], Step: [5100/6250], Loss: 1.3263 \n",
      "\n",
      "Epoch: [77/100], Step: [5200/6250], Loss: 0.5505 \n",
      "\n",
      "Epoch: [77/100], Step: [5300/6250], Loss: 0.9406 \n",
      "\n",
      "Epoch: [77/100], Step: [5400/6250], Loss: 0.5200 \n",
      "\n",
      "Epoch: [77/100], Step: [5500/6250], Loss: 0.7269 \n",
      "\n",
      "Epoch: [77/100], Step: [5600/6250], Loss: 0.3983 \n",
      "\n",
      "Epoch: [77/100], Step: [5700/6250], Loss: 0.1330 \n",
      "\n",
      "Epoch: [77/100], Step: [5800/6250], Loss: 0.4382 \n",
      "\n",
      "Epoch: [77/100], Step: [5900/6250], Loss: 1.1343 \n",
      "\n",
      "Epoch: [77/100], Step: [6000/6250], Loss: 0.8998 \n",
      "\n",
      "Epoch: [77/100], Step: [6100/6250], Loss: 0.2056 \n",
      "\n",
      "Epoch: [77/100], Step: [6200/6250], Loss: 0.2180 \n",
      "\n",
      "Epoch: [78/100], Step: [100/6250], Loss: 0.2172 \n",
      "\n",
      "Epoch: [78/100], Step: [200/6250], Loss: 0.8788 \n",
      "\n",
      "Epoch: [78/100], Step: [300/6250], Loss: 0.2165 \n",
      "\n",
      "Epoch: [78/100], Step: [400/6250], Loss: 0.4881 \n",
      "\n",
      "Epoch: [78/100], Step: [500/6250], Loss: 0.2944 \n",
      "\n",
      "Epoch: [78/100], Step: [600/6250], Loss: 0.2452 \n",
      "\n",
      "Epoch: [78/100], Step: [700/6250], Loss: 0.4447 \n",
      "\n",
      "Epoch: [78/100], Step: [800/6250], Loss: 0.3276 \n",
      "\n",
      "Epoch: [78/100], Step: [900/6250], Loss: 0.1023 \n",
      "\n",
      "Epoch: [78/100], Step: [1000/6250], Loss: 0.1895 \n",
      "\n",
      "Epoch: [78/100], Step: [1100/6250], Loss: 0.7333 \n",
      "\n",
      "Epoch: [78/100], Step: [1200/6250], Loss: 1.2974 \n",
      "\n",
      "Epoch: [78/100], Step: [1300/6250], Loss: 0.5611 \n",
      "\n",
      "Epoch: [78/100], Step: [1400/6250], Loss: 0.2925 \n",
      "\n",
      "Epoch: [78/100], Step: [1500/6250], Loss: 0.5323 \n",
      "\n",
      "Epoch: [78/100], Step: [1600/6250], Loss: 0.2177 \n",
      "\n",
      "Epoch: [78/100], Step: [1700/6250], Loss: 0.4840 \n",
      "\n",
      "Epoch: [78/100], Step: [1800/6250], Loss: 1.3585 \n",
      "\n",
      "Epoch: [78/100], Step: [1900/6250], Loss: 0.3245 \n",
      "\n",
      "Epoch: [78/100], Step: [2000/6250], Loss: 0.7214 \n",
      "\n",
      "Epoch: [78/100], Step: [2100/6250], Loss: 1.0076 \n",
      "\n",
      "Epoch: [78/100], Step: [2200/6250], Loss: 0.3263 \n",
      "\n",
      "Epoch: [78/100], Step: [2300/6250], Loss: 0.1236 \n",
      "\n",
      "Epoch: [78/100], Step: [2400/6250], Loss: 0.6345 \n",
      "\n",
      "Epoch: [78/100], Step: [2500/6250], Loss: 0.6399 \n",
      "\n",
      "Epoch: [78/100], Step: [2600/6250], Loss: 0.4036 \n",
      "\n",
      "Epoch: [78/100], Step: [2700/6250], Loss: 0.1171 \n",
      "\n",
      "Epoch: [78/100], Step: [2800/6250], Loss: 0.3917 \n",
      "\n",
      "Epoch: [78/100], Step: [2900/6250], Loss: 1.0198 \n",
      "\n",
      "Epoch: [78/100], Step: [3000/6250], Loss: 0.9985 \n",
      "\n",
      "Epoch: [78/100], Step: [3100/6250], Loss: 0.9100 \n",
      "\n",
      "Epoch: [78/100], Step: [3200/6250], Loss: 0.3533 \n",
      "\n",
      "Epoch: [78/100], Step: [3300/6250], Loss: 0.4016 \n",
      "\n",
      "Epoch: [78/100], Step: [3400/6250], Loss: 0.3611 \n",
      "\n",
      "Epoch: [78/100], Step: [3500/6250], Loss: 0.2090 \n",
      "\n",
      "Epoch: [78/100], Step: [3600/6250], Loss: 0.6865 \n",
      "\n",
      "Epoch: [78/100], Step: [3700/6250], Loss: 0.5416 \n",
      "\n",
      "Epoch: [78/100], Step: [3800/6250], Loss: 0.1511 \n",
      "\n",
      "Epoch: [78/100], Step: [3900/6250], Loss: 0.4245 \n",
      "\n",
      "Epoch: [78/100], Step: [4000/6250], Loss: 0.3247 \n",
      "\n",
      "Epoch: [78/100], Step: [4100/6250], Loss: 0.4452 \n",
      "\n",
      "Epoch: [78/100], Step: [4200/6250], Loss: 0.6688 \n",
      "\n",
      "Epoch: [78/100], Step: [4300/6250], Loss: 0.2324 \n",
      "\n",
      "Epoch: [78/100], Step: [4400/6250], Loss: 1.0604 \n",
      "\n",
      "Epoch: [78/100], Step: [4500/6250], Loss: 0.0287 \n",
      "\n",
      "Epoch: [78/100], Step: [4600/6250], Loss: 0.5059 \n",
      "\n",
      "Epoch: [78/100], Step: [4700/6250], Loss: 1.2083 \n",
      "\n",
      "Epoch: [78/100], Step: [4800/6250], Loss: 0.4627 \n",
      "\n",
      "Epoch: [78/100], Step: [4900/6250], Loss: 0.4698 \n",
      "\n",
      "Epoch: [78/100], Step: [5000/6250], Loss: 0.6880 \n",
      "\n",
      "Epoch: [78/100], Step: [5100/6250], Loss: 0.9345 \n",
      "\n",
      "Epoch: [78/100], Step: [5200/6250], Loss: 0.3261 \n",
      "\n",
      "Epoch: [78/100], Step: [5300/6250], Loss: 0.2745 \n",
      "\n",
      "Epoch: [78/100], Step: [5400/6250], Loss: 0.5908 \n",
      "\n",
      "Epoch: [78/100], Step: [5500/6250], Loss: 0.2384 \n",
      "\n",
      "Epoch: [78/100], Step: [5600/6250], Loss: 0.4602 \n",
      "\n",
      "Epoch: [78/100], Step: [5700/6250], Loss: 0.7419 \n",
      "\n",
      "Epoch: [78/100], Step: [5800/6250], Loss: 0.2105 \n",
      "\n",
      "Epoch: [78/100], Step: [5900/6250], Loss: 0.6913 \n",
      "\n",
      "Epoch: [78/100], Step: [6000/6250], Loss: 0.3601 \n",
      "\n",
      "Epoch: [78/100], Step: [6100/6250], Loss: 0.5768 \n",
      "\n",
      "Epoch: [78/100], Step: [6200/6250], Loss: 0.2852 \n",
      "\n",
      "Epoch: [79/100], Step: [100/6250], Loss: 0.3574 \n",
      "\n",
      "Epoch: [79/100], Step: [200/6250], Loss: 0.3523 \n",
      "\n",
      "Epoch: [79/100], Step: [300/6250], Loss: 0.2670 \n",
      "\n",
      "Epoch: [79/100], Step: [400/6250], Loss: 0.1183 \n",
      "\n",
      "Epoch: [79/100], Step: [500/6250], Loss: 0.5129 \n",
      "\n",
      "Epoch: [79/100], Step: [600/6250], Loss: 0.5521 \n",
      "\n",
      "Epoch: [79/100], Step: [700/6250], Loss: 0.3980 \n",
      "\n",
      "Epoch: [79/100], Step: [800/6250], Loss: 0.3009 \n",
      "\n",
      "Epoch: [79/100], Step: [900/6250], Loss: 1.1293 \n",
      "\n",
      "Epoch: [79/100], Step: [1000/6250], Loss: 0.2287 \n",
      "\n",
      "Epoch: [79/100], Step: [1100/6250], Loss: 0.9512 \n",
      "\n",
      "Epoch: [79/100], Step: [1200/6250], Loss: 0.4091 \n",
      "\n",
      "Epoch: [79/100], Step: [1300/6250], Loss: 0.6019 \n",
      "\n",
      "Epoch: [79/100], Step: [1400/6250], Loss: 0.6511 \n",
      "\n",
      "Epoch: [79/100], Step: [1500/6250], Loss: 0.6400 \n",
      "\n",
      "Epoch: [79/100], Step: [1600/6250], Loss: 0.0227 \n",
      "\n",
      "Epoch: [79/100], Step: [1700/6250], Loss: 0.2541 \n",
      "\n",
      "Epoch: [79/100], Step: [1800/6250], Loss: 0.8872 \n",
      "\n",
      "Epoch: [79/100], Step: [1900/6250], Loss: 0.8824 \n",
      "\n",
      "Epoch: [79/100], Step: [2000/6250], Loss: 1.0884 \n",
      "\n",
      "Epoch: [79/100], Step: [2100/6250], Loss: 0.1827 \n",
      "\n",
      "Epoch: [79/100], Step: [2200/6250], Loss: 0.6262 \n",
      "\n",
      "Epoch: [79/100], Step: [2300/6250], Loss: 0.2148 \n",
      "\n",
      "Epoch: [79/100], Step: [2400/6250], Loss: 0.1501 \n",
      "\n",
      "Epoch: [79/100], Step: [2500/6250], Loss: 0.6029 \n",
      "\n",
      "Epoch: [79/100], Step: [2600/6250], Loss: 0.4717 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [79/100], Step: [2700/6250], Loss: 0.1053 \n",
      "\n",
      "Epoch: [79/100], Step: [2800/6250], Loss: 0.2376 \n",
      "\n",
      "Epoch: [79/100], Step: [2900/6250], Loss: 0.4576 \n",
      "\n",
      "Epoch: [79/100], Step: [3000/6250], Loss: 1.0634 \n",
      "\n",
      "Epoch: [79/100], Step: [3100/6250], Loss: 0.3748 \n",
      "\n",
      "Epoch: [79/100], Step: [3200/6250], Loss: 0.6585 \n",
      "\n",
      "Epoch: [79/100], Step: [3300/6250], Loss: 0.3499 \n",
      "\n",
      "Epoch: [79/100], Step: [3400/6250], Loss: 0.3646 \n",
      "\n",
      "Epoch: [79/100], Step: [3500/6250], Loss: 0.3331 \n",
      "\n",
      "Epoch: [79/100], Step: [3600/6250], Loss: 0.5749 \n",
      "\n",
      "Epoch: [79/100], Step: [3700/6250], Loss: 0.5876 \n",
      "\n",
      "Epoch: [79/100], Step: [3800/6250], Loss: 0.0943 \n",
      "\n",
      "Epoch: [79/100], Step: [3900/6250], Loss: 0.7715 \n",
      "\n",
      "Epoch: [79/100], Step: [4000/6250], Loss: 1.4726 \n",
      "\n",
      "Epoch: [79/100], Step: [4100/6250], Loss: 0.6284 \n",
      "\n",
      "Epoch: [79/100], Step: [4200/6250], Loss: 0.4694 \n",
      "\n",
      "Epoch: [79/100], Step: [4300/6250], Loss: 0.6936 \n",
      "\n",
      "Epoch: [79/100], Step: [4400/6250], Loss: 0.5279 \n",
      "\n",
      "Epoch: [79/100], Step: [4500/6250], Loss: 1.5834 \n",
      "\n",
      "Epoch: [79/100], Step: [4600/6250], Loss: 0.9955 \n",
      "\n",
      "Epoch: [79/100], Step: [4700/6250], Loss: 0.6515 \n",
      "\n",
      "Epoch: [79/100], Step: [4800/6250], Loss: 0.6145 \n",
      "\n",
      "Epoch: [79/100], Step: [4900/6250], Loss: 0.2914 \n",
      "\n",
      "Epoch: [79/100], Step: [5000/6250], Loss: 0.5039 \n",
      "\n",
      "Epoch: [79/100], Step: [5100/6250], Loss: 0.4123 \n",
      "\n",
      "Epoch: [79/100], Step: [5200/6250], Loss: 0.8770 \n",
      "\n",
      "Epoch: [79/100], Step: [5300/6250], Loss: 0.3214 \n",
      "\n",
      "Epoch: [79/100], Step: [5400/6250], Loss: 0.4336 \n",
      "\n",
      "Epoch: [79/100], Step: [5500/6250], Loss: 0.0923 \n",
      "\n",
      "Epoch: [79/100], Step: [5600/6250], Loss: 0.4048 \n",
      "\n",
      "Epoch: [79/100], Step: [5700/6250], Loss: 0.2884 \n",
      "\n",
      "Epoch: [79/100], Step: [5800/6250], Loss: 0.9520 \n",
      "\n",
      "Epoch: [79/100], Step: [5900/6250], Loss: 0.7096 \n",
      "\n",
      "Epoch: [79/100], Step: [6000/6250], Loss: 0.4701 \n",
      "\n",
      "Epoch: [79/100], Step: [6100/6250], Loss: 0.3399 \n",
      "\n",
      "Epoch: [79/100], Step: [6200/6250], Loss: 0.6359 \n",
      "\n",
      "Epoch: [80/100], Step: [100/6250], Loss: 0.8412 \n",
      "\n",
      "Epoch: [80/100], Step: [200/6250], Loss: 0.3446 \n",
      "\n",
      "Epoch: [80/100], Step: [300/6250], Loss: 0.5794 \n",
      "\n",
      "Epoch: [80/100], Step: [400/6250], Loss: 0.6276 \n",
      "\n",
      "Epoch: [80/100], Step: [500/6250], Loss: 0.1996 \n",
      "\n",
      "Epoch: [80/100], Step: [600/6250], Loss: 0.4314 \n",
      "\n",
      "Epoch: [80/100], Step: [700/6250], Loss: 0.2652 \n",
      "\n",
      "Epoch: [80/100], Step: [800/6250], Loss: 0.3334 \n",
      "\n",
      "Epoch: [80/100], Step: [900/6250], Loss: 0.2411 \n",
      "\n",
      "Epoch: [80/100], Step: [1000/6250], Loss: 0.2719 \n",
      "\n",
      "Epoch: [80/100], Step: [1100/6250], Loss: 0.4210 \n",
      "\n",
      "Epoch: [80/100], Step: [1200/6250], Loss: 0.8596 \n",
      "\n",
      "Epoch: [80/100], Step: [1300/6250], Loss: 0.5174 \n",
      "\n",
      "Epoch: [80/100], Step: [1400/6250], Loss: 0.8203 \n",
      "\n",
      "Epoch: [80/100], Step: [1500/6250], Loss: 0.3959 \n",
      "\n",
      "Epoch: [80/100], Step: [1600/6250], Loss: 0.6284 \n",
      "\n",
      "Epoch: [80/100], Step: [1700/6250], Loss: 0.4947 \n",
      "\n",
      "Epoch: [80/100], Step: [1800/6250], Loss: 1.4189 \n",
      "\n",
      "Epoch: [80/100], Step: [1900/6250], Loss: 0.2309 \n",
      "\n",
      "Epoch: [80/100], Step: [2000/6250], Loss: 0.8785 \n",
      "\n",
      "Epoch: [80/100], Step: [2100/6250], Loss: 0.1639 \n",
      "\n",
      "Epoch: [80/100], Step: [2200/6250], Loss: 0.4331 \n",
      "\n",
      "Epoch: [80/100], Step: [2300/6250], Loss: 0.3932 \n",
      "\n",
      "Epoch: [80/100], Step: [2400/6250], Loss: 0.3235 \n",
      "\n",
      "Epoch: [80/100], Step: [2500/6250], Loss: 0.0874 \n",
      "\n",
      "Epoch: [80/100], Step: [2600/6250], Loss: 0.3963 \n",
      "\n",
      "Epoch: [80/100], Step: [2700/6250], Loss: 0.3481 \n",
      "\n",
      "Epoch: [80/100], Step: [2800/6250], Loss: 0.3613 \n",
      "\n",
      "Epoch: [80/100], Step: [2900/6250], Loss: 0.1897 \n",
      "\n",
      "Epoch: [80/100], Step: [3000/6250], Loss: 0.3188 \n",
      "\n",
      "Epoch: [80/100], Step: [3100/6250], Loss: 0.0386 \n",
      "\n",
      "Epoch: [80/100], Step: [3200/6250], Loss: 0.9471 \n",
      "\n",
      "Epoch: [80/100], Step: [3300/6250], Loss: 0.0562 \n",
      "\n",
      "Epoch: [80/100], Step: [3400/6250], Loss: 0.4592 \n",
      "\n",
      "Epoch: [80/100], Step: [3500/6250], Loss: 0.6099 \n",
      "\n",
      "Epoch: [80/100], Step: [3600/6250], Loss: 0.8514 \n",
      "\n",
      "Epoch: [80/100], Step: [3700/6250], Loss: 0.5151 \n",
      "\n",
      "Epoch: [80/100], Step: [3800/6250], Loss: 0.3089 \n",
      "\n",
      "Epoch: [80/100], Step: [3900/6250], Loss: 0.8493 \n",
      "\n",
      "Epoch: [80/100], Step: [4000/6250], Loss: 0.1799 \n",
      "\n",
      "Epoch: [80/100], Step: [4100/6250], Loss: 0.3912 \n",
      "\n",
      "Epoch: [80/100], Step: [4200/6250], Loss: 0.5356 \n",
      "\n",
      "Epoch: [80/100], Step: [4300/6250], Loss: 0.5252 \n",
      "\n",
      "Epoch: [80/100], Step: [4400/6250], Loss: 1.1004 \n",
      "\n",
      "Epoch: [80/100], Step: [4500/6250], Loss: 0.4349 \n",
      "\n",
      "Epoch: [80/100], Step: [4600/6250], Loss: 0.2914 \n",
      "\n",
      "Epoch: [80/100], Step: [4700/6250], Loss: 0.1987 \n",
      "\n",
      "Epoch: [80/100], Step: [4800/6250], Loss: 0.1701 \n",
      "\n",
      "Epoch: [80/100], Step: [4900/6250], Loss: 0.4051 \n",
      "\n",
      "Epoch: [80/100], Step: [5000/6250], Loss: 1.1024 \n",
      "\n",
      "Epoch: [80/100], Step: [5100/6250], Loss: 0.1232 \n",
      "\n",
      "Epoch: [80/100], Step: [5200/6250], Loss: 0.5953 \n",
      "\n",
      "Epoch: [80/100], Step: [5300/6250], Loss: 0.8434 \n",
      "\n",
      "Epoch: [80/100], Step: [5400/6250], Loss: 0.3547 \n",
      "\n",
      "Epoch: [80/100], Step: [5500/6250], Loss: 0.1996 \n",
      "\n",
      "Epoch: [80/100], Step: [5600/6250], Loss: 0.0476 \n",
      "\n",
      "Epoch: [80/100], Step: [5700/6250], Loss: 1.7534 \n",
      "\n",
      "Epoch: [80/100], Step: [5800/6250], Loss: 0.9833 \n",
      "\n",
      "Epoch: [80/100], Step: [5900/6250], Loss: 0.5898 \n",
      "\n",
      "Epoch: [80/100], Step: [6000/6250], Loss: 1.0985 \n",
      "\n",
      "Epoch: [80/100], Step: [6100/6250], Loss: 0.3157 \n",
      "\n",
      "Epoch: [80/100], Step: [6200/6250], Loss: 0.5350 \n",
      "\n",
      "Epoch: [81/100], Step: [100/6250], Loss: 0.7091 \n",
      "\n",
      "Epoch: [81/100], Step: [200/6250], Loss: 0.6253 \n",
      "\n",
      "Epoch: [81/100], Step: [300/6250], Loss: 0.3617 \n",
      "\n",
      "Epoch: [81/100], Step: [400/6250], Loss: 0.3690 \n",
      "\n",
      "Epoch: [81/100], Step: [500/6250], Loss: 0.5762 \n",
      "\n",
      "Epoch: [81/100], Step: [600/6250], Loss: 0.1530 \n",
      "\n",
      "Epoch: [81/100], Step: [700/6250], Loss: 0.4675 \n",
      "\n",
      "Epoch: [81/100], Step: [800/6250], Loss: 0.4860 \n",
      "\n",
      "Epoch: [81/100], Step: [900/6250], Loss: 0.7484 \n",
      "\n",
      "Epoch: [81/100], Step: [1000/6250], Loss: 0.2736 \n",
      "\n",
      "Epoch: [81/100], Step: [1100/6250], Loss: 1.1615 \n",
      "\n",
      "Epoch: [81/100], Step: [1200/6250], Loss: 0.1904 \n",
      "\n",
      "Epoch: [81/100], Step: [1300/6250], Loss: 0.4621 \n",
      "\n",
      "Epoch: [81/100], Step: [1400/6250], Loss: 0.8013 \n",
      "\n",
      "Epoch: [81/100], Step: [1500/6250], Loss: 0.3342 \n",
      "\n",
      "Epoch: [81/100], Step: [1600/6250], Loss: 0.9308 \n",
      "\n",
      "Epoch: [81/100], Step: [1700/6250], Loss: 0.2737 \n",
      "\n",
      "Epoch: [81/100], Step: [1800/6250], Loss: 0.4963 \n",
      "\n",
      "Epoch: [81/100], Step: [1900/6250], Loss: 0.2141 \n",
      "\n",
      "Epoch: [81/100], Step: [2000/6250], Loss: 0.7226 \n",
      "\n",
      "Epoch: [81/100], Step: [2100/6250], Loss: 0.5621 \n",
      "\n",
      "Epoch: [81/100], Step: [2200/6250], Loss: 0.2090 \n",
      "\n",
      "Epoch: [81/100], Step: [2300/6250], Loss: 0.4408 \n",
      "\n",
      "Epoch: [81/100], Step: [2400/6250], Loss: 0.1578 \n",
      "\n",
      "Epoch: [81/100], Step: [2500/6250], Loss: 0.4675 \n",
      "\n",
      "Epoch: [81/100], Step: [2600/6250], Loss: 0.1957 \n",
      "\n",
      "Epoch: [81/100], Step: [2700/6250], Loss: 0.2985 \n",
      "\n",
      "Epoch: [81/100], Step: [2800/6250], Loss: 0.6222 \n",
      "\n",
      "Epoch: [81/100], Step: [2900/6250], Loss: 0.4781 \n",
      "\n",
      "Epoch: [81/100], Step: [3000/6250], Loss: 0.4208 \n",
      "\n",
      "Epoch: [81/100], Step: [3100/6250], Loss: 0.1559 \n",
      "\n",
      "Epoch: [81/100], Step: [3200/6250], Loss: 1.3152 \n",
      "\n",
      "Epoch: [81/100], Step: [3300/6250], Loss: 0.3367 \n",
      "\n",
      "Epoch: [81/100], Step: [3400/6250], Loss: 0.2357 \n",
      "\n",
      "Epoch: [81/100], Step: [3500/6250], Loss: 0.6678 \n",
      "\n",
      "Epoch: [81/100], Step: [3600/6250], Loss: 0.4404 \n",
      "\n",
      "Epoch: [81/100], Step: [3700/6250], Loss: 0.2828 \n",
      "\n",
      "Epoch: [81/100], Step: [3800/6250], Loss: 1.1624 \n",
      "\n",
      "Epoch: [81/100], Step: [3900/6250], Loss: 0.3907 \n",
      "\n",
      "Epoch: [81/100], Step: [4000/6250], Loss: 0.7193 \n",
      "\n",
      "Epoch: [81/100], Step: [4100/6250], Loss: 1.1162 \n",
      "\n",
      "Epoch: [81/100], Step: [4200/6250], Loss: 1.0920 \n",
      "\n",
      "Epoch: [81/100], Step: [4300/6250], Loss: 0.7241 \n",
      "\n",
      "Epoch: [81/100], Step: [4400/6250], Loss: 0.4327 \n",
      "\n",
      "Epoch: [81/100], Step: [4500/6250], Loss: 0.8042 \n",
      "\n",
      "Epoch: [81/100], Step: [4600/6250], Loss: 0.1769 \n",
      "\n",
      "Epoch: [81/100], Step: [4700/6250], Loss: 0.6679 \n",
      "\n",
      "Epoch: [81/100], Step: [4800/6250], Loss: 0.0934 \n",
      "\n",
      "Epoch: [81/100], Step: [4900/6250], Loss: 0.3100 \n",
      "\n",
      "Epoch: [81/100], Step: [5000/6250], Loss: 0.4930 \n",
      "\n",
      "Epoch: [81/100], Step: [5100/6250], Loss: 0.3323 \n",
      "\n",
      "Epoch: [81/100], Step: [5200/6250], Loss: 0.3000 \n",
      "\n",
      "Epoch: [81/100], Step: [5300/6250], Loss: 0.2830 \n",
      "\n",
      "Epoch: [81/100], Step: [5400/6250], Loss: 0.5540 \n",
      "\n",
      "Epoch: [81/100], Step: [5500/6250], Loss: 1.2389 \n",
      "\n",
      "Epoch: [81/100], Step: [5600/6250], Loss: 0.3483 \n",
      "\n",
      "Epoch: [81/100], Step: [5700/6250], Loss: 0.3094 \n",
      "\n",
      "Epoch: [81/100], Step: [5800/6250], Loss: 0.7390 \n",
      "\n",
      "Epoch: [81/100], Step: [5900/6250], Loss: 0.9701 \n",
      "\n",
      "Epoch: [81/100], Step: [6000/6250], Loss: 0.1906 \n",
      "\n",
      "Epoch: [81/100], Step: [6100/6250], Loss: 0.5591 \n",
      "\n",
      "Epoch: [81/100], Step: [6200/6250], Loss: 0.6520 \n",
      "\n",
      "Epoch: [82/100], Step: [100/6250], Loss: 0.7383 \n",
      "\n",
      "Epoch: [82/100], Step: [200/6250], Loss: 0.2419 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [82/100], Step: [300/6250], Loss: 0.2516 \n",
      "\n",
      "Epoch: [82/100], Step: [400/6250], Loss: 0.3104 \n",
      "\n",
      "Epoch: [82/100], Step: [500/6250], Loss: 0.5930 \n",
      "\n",
      "Epoch: [82/100], Step: [600/6250], Loss: 0.4469 \n",
      "\n",
      "Epoch: [82/100], Step: [700/6250], Loss: 0.4506 \n",
      "\n",
      "Epoch: [82/100], Step: [800/6250], Loss: 0.1035 \n",
      "\n",
      "Epoch: [82/100], Step: [900/6250], Loss: 0.4398 \n",
      "\n",
      "Epoch: [82/100], Step: [1000/6250], Loss: 0.1135 \n",
      "\n",
      "Epoch: [82/100], Step: [1100/6250], Loss: 0.4435 \n",
      "\n",
      "Epoch: [82/100], Step: [1200/6250], Loss: 0.3484 \n",
      "\n",
      "Epoch: [82/100], Step: [1300/6250], Loss: 0.1954 \n",
      "\n",
      "Epoch: [82/100], Step: [1400/6250], Loss: 0.6143 \n",
      "\n",
      "Epoch: [82/100], Step: [1500/6250], Loss: 0.2204 \n",
      "\n",
      "Epoch: [82/100], Step: [1600/6250], Loss: 0.3342 \n",
      "\n",
      "Epoch: [82/100], Step: [1700/6250], Loss: 0.4206 \n",
      "\n",
      "Epoch: [82/100], Step: [1800/6250], Loss: 0.9555 \n",
      "\n",
      "Epoch: [82/100], Step: [1900/6250], Loss: 0.8287 \n",
      "\n",
      "Epoch: [82/100], Step: [2000/6250], Loss: 0.7701 \n",
      "\n",
      "Epoch: [82/100], Step: [2100/6250], Loss: 0.5279 \n",
      "\n",
      "Epoch: [82/100], Step: [2200/6250], Loss: 0.8697 \n",
      "\n",
      "Epoch: [82/100], Step: [2300/6250], Loss: 0.6793 \n",
      "\n",
      "Epoch: [82/100], Step: [2400/6250], Loss: 0.3189 \n",
      "\n",
      "Epoch: [82/100], Step: [2500/6250], Loss: 0.0646 \n",
      "\n",
      "Epoch: [82/100], Step: [2600/6250], Loss: 0.3468 \n",
      "\n",
      "Epoch: [82/100], Step: [2700/6250], Loss: 0.8737 \n",
      "\n",
      "Epoch: [82/100], Step: [2800/6250], Loss: 0.5570 \n",
      "\n",
      "Epoch: [82/100], Step: [2900/6250], Loss: 0.4895 \n",
      "\n",
      "Epoch: [82/100], Step: [3000/6250], Loss: 0.4798 \n",
      "\n",
      "Epoch: [82/100], Step: [3100/6250], Loss: 1.2577 \n",
      "\n",
      "Epoch: [82/100], Step: [3200/6250], Loss: 1.2307 \n",
      "\n",
      "Epoch: [82/100], Step: [3300/6250], Loss: 0.4608 \n",
      "\n",
      "Epoch: [82/100], Step: [3400/6250], Loss: 0.0691 \n",
      "\n",
      "Epoch: [82/100], Step: [3500/6250], Loss: 0.4040 \n",
      "\n",
      "Epoch: [82/100], Step: [3600/6250], Loss: 0.1940 \n",
      "\n",
      "Epoch: [82/100], Step: [3700/6250], Loss: 0.0947 \n",
      "\n",
      "Epoch: [82/100], Step: [3800/6250], Loss: 0.0847 \n",
      "\n",
      "Epoch: [82/100], Step: [3900/6250], Loss: 0.1339 \n",
      "\n",
      "Epoch: [82/100], Step: [4000/6250], Loss: 0.1319 \n",
      "\n",
      "Epoch: [82/100], Step: [4100/6250], Loss: 0.7372 \n",
      "\n",
      "Epoch: [82/100], Step: [4200/6250], Loss: 0.2322 \n",
      "\n",
      "Epoch: [82/100], Step: [4300/6250], Loss: 0.4615 \n",
      "\n",
      "Epoch: [82/100], Step: [4400/6250], Loss: 0.1722 \n",
      "\n",
      "Epoch: [82/100], Step: [4500/6250], Loss: 0.2235 \n",
      "\n",
      "Epoch: [82/100], Step: [4600/6250], Loss: 0.4744 \n",
      "\n",
      "Epoch: [82/100], Step: [4700/6250], Loss: 0.2679 \n",
      "\n",
      "Epoch: [82/100], Step: [4800/6250], Loss: 0.4436 \n",
      "\n",
      "Epoch: [82/100], Step: [4900/6250], Loss: 0.6802 \n",
      "\n",
      "Epoch: [82/100], Step: [5000/6250], Loss: 0.6454 \n",
      "\n",
      "Epoch: [82/100], Step: [5100/6250], Loss: 0.7752 \n",
      "\n",
      "Epoch: [82/100], Step: [5200/6250], Loss: 0.2291 \n",
      "\n",
      "Epoch: [82/100], Step: [5300/6250], Loss: 0.6351 \n",
      "\n",
      "Epoch: [82/100], Step: [5400/6250], Loss: 0.1449 \n",
      "\n",
      "Epoch: [82/100], Step: [5500/6250], Loss: 0.8133 \n",
      "\n",
      "Epoch: [82/100], Step: [5600/6250], Loss: 0.4004 \n",
      "\n",
      "Epoch: [82/100], Step: [5700/6250], Loss: 0.2732 \n",
      "\n",
      "Epoch: [82/100], Step: [5800/6250], Loss: 0.4287 \n",
      "\n",
      "Epoch: [82/100], Step: [5900/6250], Loss: 0.5385 \n",
      "\n",
      "Epoch: [82/100], Step: [6000/6250], Loss: 0.8283 \n",
      "\n",
      "Epoch: [82/100], Step: [6100/6250], Loss: 0.7515 \n",
      "\n",
      "Epoch: [82/100], Step: [6200/6250], Loss: 0.6022 \n",
      "\n",
      "Epoch: [83/100], Step: [100/6250], Loss: 0.6144 \n",
      "\n",
      "Epoch: [83/100], Step: [200/6250], Loss: 0.5291 \n",
      "\n",
      "Epoch: [83/100], Step: [300/6250], Loss: 0.5118 \n",
      "\n",
      "Epoch: [83/100], Step: [400/6250], Loss: 0.3131 \n",
      "\n",
      "Epoch: [83/100], Step: [500/6250], Loss: 0.2123 \n",
      "\n",
      "Epoch: [83/100], Step: [600/6250], Loss: 0.5986 \n",
      "\n",
      "Epoch: [83/100], Step: [700/6250], Loss: 0.1818 \n",
      "\n",
      "Epoch: [83/100], Step: [800/6250], Loss: 0.6259 \n",
      "\n",
      "Epoch: [83/100], Step: [900/6250], Loss: 0.0833 \n",
      "\n",
      "Epoch: [83/100], Step: [1000/6250], Loss: 0.3446 \n",
      "\n",
      "Epoch: [83/100], Step: [1100/6250], Loss: 0.3594 \n",
      "\n",
      "Epoch: [83/100], Step: [1200/6250], Loss: 0.4943 \n",
      "\n",
      "Epoch: [83/100], Step: [1300/6250], Loss: 0.4144 \n",
      "\n",
      "Epoch: [83/100], Step: [1400/6250], Loss: 0.7763 \n",
      "\n",
      "Epoch: [83/100], Step: [1500/6250], Loss: 0.2563 \n",
      "\n",
      "Epoch: [83/100], Step: [1600/6250], Loss: 0.4984 \n",
      "\n",
      "Epoch: [83/100], Step: [1700/6250], Loss: 0.7852 \n",
      "\n",
      "Epoch: [83/100], Step: [1800/6250], Loss: 0.4193 \n",
      "\n",
      "Epoch: [83/100], Step: [1900/6250], Loss: 0.3936 \n",
      "\n",
      "Epoch: [83/100], Step: [2000/6250], Loss: 0.4526 \n",
      "\n",
      "Epoch: [83/100], Step: [2100/6250], Loss: 0.3636 \n",
      "\n",
      "Epoch: [83/100], Step: [2200/6250], Loss: 0.7995 \n",
      "\n",
      "Epoch: [83/100], Step: [2300/6250], Loss: 0.5747 \n",
      "\n",
      "Epoch: [83/100], Step: [2400/6250], Loss: 0.9778 \n",
      "\n",
      "Epoch: [83/100], Step: [2500/6250], Loss: 0.3051 \n",
      "\n",
      "Epoch: [83/100], Step: [2600/6250], Loss: 0.2561 \n",
      "\n",
      "Epoch: [83/100], Step: [2700/6250], Loss: 0.4249 \n",
      "\n",
      "Epoch: [83/100], Step: [2800/6250], Loss: 0.1258 \n",
      "\n",
      "Epoch: [83/100], Step: [2900/6250], Loss: 0.1737 \n",
      "\n",
      "Epoch: [83/100], Step: [3000/6250], Loss: 0.7550 \n",
      "\n",
      "Epoch: [83/100], Step: [3100/6250], Loss: 0.5404 \n",
      "\n",
      "Epoch: [83/100], Step: [3200/6250], Loss: 0.6942 \n",
      "\n",
      "Epoch: [83/100], Step: [3300/6250], Loss: 0.3265 \n",
      "\n",
      "Epoch: [83/100], Step: [3400/6250], Loss: 0.4517 \n",
      "\n",
      "Epoch: [83/100], Step: [3500/6250], Loss: 0.3501 \n",
      "\n",
      "Epoch: [83/100], Step: [3600/6250], Loss: 0.3107 \n",
      "\n",
      "Epoch: [83/100], Step: [3700/6250], Loss: 0.2449 \n",
      "\n",
      "Epoch: [83/100], Step: [3800/6250], Loss: 0.3034 \n",
      "\n",
      "Epoch: [83/100], Step: [3900/6250], Loss: 0.5976 \n",
      "\n",
      "Epoch: [83/100], Step: [4000/6250], Loss: 0.5182 \n",
      "\n",
      "Epoch: [83/100], Step: [4100/6250], Loss: 0.3313 \n",
      "\n",
      "Epoch: [83/100], Step: [4200/6250], Loss: 0.1971 \n",
      "\n",
      "Epoch: [83/100], Step: [4300/6250], Loss: 0.4368 \n",
      "\n",
      "Epoch: [83/100], Step: [4400/6250], Loss: 1.2457 \n",
      "\n",
      "Epoch: [83/100], Step: [4500/6250], Loss: 0.4748 \n",
      "\n",
      "Epoch: [83/100], Step: [4600/6250], Loss: 0.3286 \n",
      "\n",
      "Epoch: [83/100], Step: [4700/6250], Loss: 0.6023 \n",
      "\n",
      "Epoch: [83/100], Step: [4800/6250], Loss: 0.6377 \n",
      "\n",
      "Epoch: [83/100], Step: [4900/6250], Loss: 0.6582 \n",
      "\n",
      "Epoch: [83/100], Step: [5000/6250], Loss: 1.2257 \n",
      "\n",
      "Epoch: [83/100], Step: [5100/6250], Loss: 0.9059 \n",
      "\n",
      "Epoch: [83/100], Step: [5200/6250], Loss: 1.0284 \n",
      "\n",
      "Epoch: [83/100], Step: [5300/6250], Loss: 0.3844 \n",
      "\n",
      "Epoch: [83/100], Step: [5400/6250], Loss: 0.3096 \n",
      "\n",
      "Epoch: [83/100], Step: [5500/6250], Loss: 0.3447 \n",
      "\n",
      "Epoch: [83/100], Step: [5600/6250], Loss: 0.2251 \n",
      "\n",
      "Epoch: [83/100], Step: [5700/6250], Loss: 0.4635 \n",
      "\n",
      "Epoch: [83/100], Step: [5800/6250], Loss: 0.0647 \n",
      "\n",
      "Epoch: [83/100], Step: [5900/6250], Loss: 0.3328 \n",
      "\n",
      "Epoch: [83/100], Step: [6000/6250], Loss: 0.4888 \n",
      "\n",
      "Epoch: [83/100], Step: [6100/6250], Loss: 0.1977 \n",
      "\n",
      "Epoch: [83/100], Step: [6200/6250], Loss: 0.1033 \n",
      "\n",
      "Epoch: [84/100], Step: [100/6250], Loss: 0.1996 \n",
      "\n",
      "Epoch: [84/100], Step: [200/6250], Loss: 0.0965 \n",
      "\n",
      "Epoch: [84/100], Step: [300/6250], Loss: 0.3049 \n",
      "\n",
      "Epoch: [84/100], Step: [400/6250], Loss: 0.7262 \n",
      "\n",
      "Epoch: [84/100], Step: [500/6250], Loss: 0.9926 \n",
      "\n",
      "Epoch: [84/100], Step: [600/6250], Loss: 0.1785 \n",
      "\n",
      "Epoch: [84/100], Step: [700/6250], Loss: 0.3907 \n",
      "\n",
      "Epoch: [84/100], Step: [800/6250], Loss: 0.4129 \n",
      "\n",
      "Epoch: [84/100], Step: [900/6250], Loss: 0.5928 \n",
      "\n",
      "Epoch: [84/100], Step: [1000/6250], Loss: 0.1927 \n",
      "\n",
      "Epoch: [84/100], Step: [1100/6250], Loss: 0.3243 \n",
      "\n",
      "Epoch: [84/100], Step: [1200/6250], Loss: 0.1965 \n",
      "\n",
      "Epoch: [84/100], Step: [1300/6250], Loss: 0.3064 \n",
      "\n",
      "Epoch: [84/100], Step: [1400/6250], Loss: 0.9599 \n",
      "\n",
      "Epoch: [84/100], Step: [1500/6250], Loss: 0.3911 \n",
      "\n",
      "Epoch: [84/100], Step: [1600/6250], Loss: 0.2139 \n",
      "\n",
      "Epoch: [84/100], Step: [1700/6250], Loss: 0.8144 \n",
      "\n",
      "Epoch: [84/100], Step: [1800/6250], Loss: 0.2205 \n",
      "\n",
      "Epoch: [84/100], Step: [1900/6250], Loss: 0.6202 \n",
      "\n",
      "Epoch: [84/100], Step: [2000/6250], Loss: 0.1004 \n",
      "\n",
      "Epoch: [84/100], Step: [2100/6250], Loss: 0.8330 \n",
      "\n",
      "Epoch: [84/100], Step: [2200/6250], Loss: 0.2385 \n",
      "\n",
      "Epoch: [84/100], Step: [2300/6250], Loss: 0.4557 \n",
      "\n",
      "Epoch: [84/100], Step: [2400/6250], Loss: 0.1970 \n",
      "\n",
      "Epoch: [84/100], Step: [2500/6250], Loss: 0.8554 \n",
      "\n",
      "Epoch: [84/100], Step: [2600/6250], Loss: 0.2370 \n",
      "\n",
      "Epoch: [84/100], Step: [2700/6250], Loss: 0.5696 \n",
      "\n",
      "Epoch: [84/100], Step: [2800/6250], Loss: 0.2930 \n",
      "\n",
      "Epoch: [84/100], Step: [2900/6250], Loss: 0.1853 \n",
      "\n",
      "Epoch: [84/100], Step: [3000/6250], Loss: 0.6718 \n",
      "\n",
      "Epoch: [84/100], Step: [3100/6250], Loss: 0.3482 \n",
      "\n",
      "Epoch: [84/100], Step: [3200/6250], Loss: 0.3446 \n",
      "\n",
      "Epoch: [84/100], Step: [3300/6250], Loss: 0.5236 \n",
      "\n",
      "Epoch: [84/100], Step: [3400/6250], Loss: 0.2309 \n",
      "\n",
      "Epoch: [84/100], Step: [3500/6250], Loss: 0.3927 \n",
      "\n",
      "Epoch: [84/100], Step: [3600/6250], Loss: 0.6915 \n",
      "\n",
      "Epoch: [84/100], Step: [3700/6250], Loss: 0.2531 \n",
      "\n",
      "Epoch: [84/100], Step: [3800/6250], Loss: 0.3125 \n",
      "\n",
      "Epoch: [84/100], Step: [3900/6250], Loss: 0.3431 \n",
      "\n",
      "Epoch: [84/100], Step: [4000/6250], Loss: 0.7724 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [84/100], Step: [4100/6250], Loss: 0.9372 \n",
      "\n",
      "Epoch: [84/100], Step: [4200/6250], Loss: 0.5778 \n",
      "\n",
      "Epoch: [84/100], Step: [4300/6250], Loss: 0.4267 \n",
      "\n",
      "Epoch: [84/100], Step: [4400/6250], Loss: 0.1670 \n",
      "\n",
      "Epoch: [84/100], Step: [4500/6250], Loss: 0.5853 \n",
      "\n",
      "Epoch: [84/100], Step: [4600/6250], Loss: 0.0689 \n",
      "\n",
      "Epoch: [84/100], Step: [4700/6250], Loss: 0.9806 \n",
      "\n",
      "Epoch: [84/100], Step: [4800/6250], Loss: 0.3644 \n",
      "\n",
      "Epoch: [84/100], Step: [4900/6250], Loss: 0.2098 \n",
      "\n",
      "Epoch: [84/100], Step: [5000/6250], Loss: 0.1525 \n",
      "\n",
      "Epoch: [84/100], Step: [5100/6250], Loss: 0.3178 \n",
      "\n",
      "Epoch: [84/100], Step: [5200/6250], Loss: 0.5641 \n",
      "\n",
      "Epoch: [84/100], Step: [5300/6250], Loss: 0.1103 \n",
      "\n",
      "Epoch: [84/100], Step: [5400/6250], Loss: 0.2583 \n",
      "\n",
      "Epoch: [84/100], Step: [5500/6250], Loss: 0.8013 \n",
      "\n",
      "Epoch: [84/100], Step: [5600/6250], Loss: 0.1722 \n",
      "\n",
      "Epoch: [84/100], Step: [5700/6250], Loss: 0.7073 \n",
      "\n",
      "Epoch: [84/100], Step: [5800/6250], Loss: 0.9769 \n",
      "\n",
      "Epoch: [84/100], Step: [5900/6250], Loss: 0.3092 \n",
      "\n",
      "Epoch: [84/100], Step: [6000/6250], Loss: 0.2922 \n",
      "\n",
      "Epoch: [84/100], Step: [6100/6250], Loss: 0.3256 \n",
      "\n",
      "Epoch: [84/100], Step: [6200/6250], Loss: 0.7345 \n",
      "\n",
      "Epoch: [85/100], Step: [100/6250], Loss: 0.4779 \n",
      "\n",
      "Epoch: [85/100], Step: [200/6250], Loss: 0.2806 \n",
      "\n",
      "Epoch: [85/100], Step: [300/6250], Loss: 0.4606 \n",
      "\n",
      "Epoch: [85/100], Step: [400/6250], Loss: 0.6564 \n",
      "\n",
      "Epoch: [85/100], Step: [500/6250], Loss: 0.1414 \n",
      "\n",
      "Epoch: [85/100], Step: [600/6250], Loss: 0.2365 \n",
      "\n",
      "Epoch: [85/100], Step: [700/6250], Loss: 0.7083 \n",
      "\n",
      "Epoch: [85/100], Step: [800/6250], Loss: 0.4661 \n",
      "\n",
      "Epoch: [85/100], Step: [900/6250], Loss: 0.2637 \n",
      "\n",
      "Epoch: [85/100], Step: [1000/6250], Loss: 0.5808 \n",
      "\n",
      "Epoch: [85/100], Step: [1100/6250], Loss: 0.2681 \n",
      "\n",
      "Epoch: [85/100], Step: [1200/6250], Loss: 0.6452 \n",
      "\n",
      "Epoch: [85/100], Step: [1300/6250], Loss: 0.6174 \n",
      "\n",
      "Epoch: [85/100], Step: [1400/6250], Loss: 0.4225 \n",
      "\n",
      "Epoch: [85/100], Step: [1500/6250], Loss: 0.1260 \n",
      "\n",
      "Epoch: [85/100], Step: [1600/6250], Loss: 0.5472 \n",
      "\n",
      "Epoch: [85/100], Step: [1700/6250], Loss: 0.3809 \n",
      "\n",
      "Epoch: [85/100], Step: [1800/6250], Loss: 0.2574 \n",
      "\n",
      "Epoch: [85/100], Step: [1900/6250], Loss: 0.4440 \n",
      "\n",
      "Epoch: [85/100], Step: [2000/6250], Loss: 0.3228 \n",
      "\n",
      "Epoch: [85/100], Step: [2100/6250], Loss: 1.0448 \n",
      "\n",
      "Epoch: [85/100], Step: [2200/6250], Loss: 0.0163 \n",
      "\n",
      "Epoch: [85/100], Step: [2300/6250], Loss: 0.4177 \n",
      "\n",
      "Epoch: [85/100], Step: [2400/6250], Loss: 0.2826 \n",
      "\n",
      "Epoch: [85/100], Step: [2500/6250], Loss: 0.2754 \n",
      "\n",
      "Epoch: [85/100], Step: [2600/6250], Loss: 0.3976 \n",
      "\n",
      "Epoch: [85/100], Step: [2700/6250], Loss: 0.3444 \n",
      "\n",
      "Epoch: [85/100], Step: [2800/6250], Loss: 0.4260 \n",
      "\n",
      "Epoch: [85/100], Step: [2900/6250], Loss: 1.5127 \n",
      "\n",
      "Epoch: [85/100], Step: [3000/6250], Loss: 0.2347 \n",
      "\n",
      "Epoch: [85/100], Step: [3100/6250], Loss: 0.0734 \n",
      "\n",
      "Epoch: [85/100], Step: [3200/6250], Loss: 0.0667 \n",
      "\n",
      "Epoch: [85/100], Step: [3300/6250], Loss: 1.0912 \n",
      "\n",
      "Epoch: [85/100], Step: [3400/6250], Loss: 0.9538 \n",
      "\n",
      "Epoch: [85/100], Step: [3500/6250], Loss: 0.3040 \n",
      "\n",
      "Epoch: [85/100], Step: [3600/6250], Loss: 0.2892 \n",
      "\n",
      "Epoch: [85/100], Step: [3700/6250], Loss: 0.4041 \n",
      "\n",
      "Epoch: [85/100], Step: [3800/6250], Loss: 0.0874 \n",
      "\n",
      "Epoch: [85/100], Step: [3900/6250], Loss: 0.8511 \n",
      "\n",
      "Epoch: [85/100], Step: [4000/6250], Loss: 0.5675 \n",
      "\n",
      "Epoch: [85/100], Step: [4100/6250], Loss: 0.5326 \n",
      "\n",
      "Epoch: [85/100], Step: [4200/6250], Loss: 0.8473 \n",
      "\n",
      "Epoch: [85/100], Step: [4300/6250], Loss: 0.2541 \n",
      "\n",
      "Epoch: [85/100], Step: [4400/6250], Loss: 0.6812 \n",
      "\n",
      "Epoch: [85/100], Step: [4500/6250], Loss: 0.6401 \n",
      "\n",
      "Epoch: [85/100], Step: [4600/6250], Loss: 0.2909 \n",
      "\n",
      "Epoch: [85/100], Step: [4700/6250], Loss: 0.5950 \n",
      "\n",
      "Epoch: [85/100], Step: [4800/6250], Loss: 0.3158 \n",
      "\n",
      "Epoch: [85/100], Step: [4900/6250], Loss: 0.5252 \n",
      "\n",
      "Epoch: [85/100], Step: [5000/6250], Loss: 0.3762 \n",
      "\n",
      "Epoch: [85/100], Step: [5100/6250], Loss: 0.6557 \n",
      "\n",
      "Epoch: [85/100], Step: [5200/6250], Loss: 0.2120 \n",
      "\n",
      "Epoch: [85/100], Step: [5300/6250], Loss: 0.1138 \n",
      "\n",
      "Epoch: [85/100], Step: [5400/6250], Loss: 0.1002 \n",
      "\n",
      "Epoch: [85/100], Step: [5500/6250], Loss: 0.8195 \n",
      "\n",
      "Epoch: [85/100], Step: [5600/6250], Loss: 0.5296 \n",
      "\n",
      "Epoch: [85/100], Step: [5700/6250], Loss: 0.3178 \n",
      "\n",
      "Epoch: [85/100], Step: [5800/6250], Loss: 0.7066 \n",
      "\n",
      "Epoch: [85/100], Step: [5900/6250], Loss: 0.3843 \n",
      "\n",
      "Epoch: [85/100], Step: [6000/6250], Loss: 0.5230 \n",
      "\n",
      "Epoch: [85/100], Step: [6100/6250], Loss: 1.4611 \n",
      "\n",
      "Epoch: [85/100], Step: [6200/6250], Loss: 0.0413 \n",
      "\n",
      "Epoch: [86/100], Step: [100/6250], Loss: 0.1749 \n",
      "\n",
      "Epoch: [86/100], Step: [200/6250], Loss: 0.9540 \n",
      "\n",
      "Epoch: [86/100], Step: [300/6250], Loss: 0.2427 \n",
      "\n",
      "Epoch: [86/100], Step: [400/6250], Loss: 0.2462 \n",
      "\n",
      "Epoch: [86/100], Step: [500/6250], Loss: 0.7246 \n",
      "\n",
      "Epoch: [86/100], Step: [600/6250], Loss: 0.4300 \n",
      "\n",
      "Epoch: [86/100], Step: [700/6250], Loss: 0.5218 \n",
      "\n",
      "Epoch: [86/100], Step: [800/6250], Loss: 0.9188 \n",
      "\n",
      "Epoch: [86/100], Step: [900/6250], Loss: 1.4520 \n",
      "\n",
      "Epoch: [86/100], Step: [1000/6250], Loss: 0.6860 \n",
      "\n",
      "Epoch: [86/100], Step: [1100/6250], Loss: 0.1187 \n",
      "\n",
      "Epoch: [86/100], Step: [1200/6250], Loss: 0.3671 \n",
      "\n",
      "Epoch: [86/100], Step: [1300/6250], Loss: 0.2465 \n",
      "\n",
      "Epoch: [86/100], Step: [1400/6250], Loss: 0.2858 \n",
      "\n",
      "Epoch: [86/100], Step: [1500/6250], Loss: 0.2900 \n",
      "\n",
      "Epoch: [86/100], Step: [1600/6250], Loss: 0.5514 \n",
      "\n",
      "Epoch: [86/100], Step: [1700/6250], Loss: 0.4336 \n",
      "\n",
      "Epoch: [86/100], Step: [1800/6250], Loss: 1.1813 \n",
      "\n",
      "Epoch: [86/100], Step: [1900/6250], Loss: 0.2198 \n",
      "\n",
      "Epoch: [86/100], Step: [2000/6250], Loss: 0.9424 \n",
      "\n",
      "Epoch: [86/100], Step: [2100/6250], Loss: 0.9783 \n",
      "\n",
      "Epoch: [86/100], Step: [2200/6250], Loss: 0.5570 \n",
      "\n",
      "Epoch: [86/100], Step: [2300/6250], Loss: 0.1603 \n",
      "\n",
      "Epoch: [86/100], Step: [2400/6250], Loss: 0.1932 \n",
      "\n",
      "Epoch: [86/100], Step: [2500/6250], Loss: 1.9405 \n",
      "\n",
      "Epoch: [86/100], Step: [2600/6250], Loss: 0.4331 \n",
      "\n",
      "Epoch: [86/100], Step: [2700/6250], Loss: 0.9962 \n",
      "\n",
      "Epoch: [86/100], Step: [2800/6250], Loss: 0.4156 \n",
      "\n",
      "Epoch: [86/100], Step: [2900/6250], Loss: 0.1653 \n",
      "\n",
      "Epoch: [86/100], Step: [3000/6250], Loss: 0.1532 \n",
      "\n",
      "Epoch: [86/100], Step: [3100/6250], Loss: 0.4273 \n",
      "\n",
      "Epoch: [86/100], Step: [3200/6250], Loss: 0.2774 \n",
      "\n",
      "Epoch: [86/100], Step: [3300/6250], Loss: 0.4159 \n",
      "\n",
      "Epoch: [86/100], Step: [3400/6250], Loss: 0.9139 \n",
      "\n",
      "Epoch: [86/100], Step: [3500/6250], Loss: 0.1133 \n",
      "\n",
      "Epoch: [86/100], Step: [3600/6250], Loss: 0.2974 \n",
      "\n",
      "Epoch: [86/100], Step: [3700/6250], Loss: 0.7836 \n",
      "\n",
      "Epoch: [86/100], Step: [3800/6250], Loss: 0.2110 \n",
      "\n",
      "Epoch: [86/100], Step: [3900/6250], Loss: 0.2695 \n",
      "\n",
      "Epoch: [86/100], Step: [4000/6250], Loss: 0.2878 \n",
      "\n",
      "Epoch: [86/100], Step: [4100/6250], Loss: 0.4282 \n",
      "\n",
      "Epoch: [86/100], Step: [4200/6250], Loss: 0.2619 \n",
      "\n",
      "Epoch: [86/100], Step: [4300/6250], Loss: 0.2529 \n",
      "\n",
      "Epoch: [86/100], Step: [4400/6250], Loss: 0.2748 \n",
      "\n",
      "Epoch: [86/100], Step: [4500/6250], Loss: 0.2965 \n",
      "\n",
      "Epoch: [86/100], Step: [4600/6250], Loss: 0.1834 \n",
      "\n",
      "Epoch: [86/100], Step: [4700/6250], Loss: 0.1470 \n",
      "\n",
      "Epoch: [86/100], Step: [4800/6250], Loss: 0.6059 \n",
      "\n",
      "Epoch: [86/100], Step: [4900/6250], Loss: 0.7115 \n",
      "\n",
      "Epoch: [86/100], Step: [5000/6250], Loss: 0.5102 \n",
      "\n",
      "Epoch: [86/100], Step: [5100/6250], Loss: 0.1054 \n",
      "\n",
      "Epoch: [86/100], Step: [5200/6250], Loss: 0.4639 \n",
      "\n",
      "Epoch: [86/100], Step: [5300/6250], Loss: 0.4339 \n",
      "\n",
      "Epoch: [86/100], Step: [5400/6250], Loss: 0.9841 \n",
      "\n",
      "Epoch: [86/100], Step: [5500/6250], Loss: 0.5781 \n",
      "\n",
      "Epoch: [86/100], Step: [5600/6250], Loss: 0.4139 \n",
      "\n",
      "Epoch: [86/100], Step: [5700/6250], Loss: 0.4913 \n",
      "\n",
      "Epoch: [86/100], Step: [5800/6250], Loss: 0.4244 \n",
      "\n",
      "Epoch: [86/100], Step: [5900/6250], Loss: 0.8302 \n",
      "\n",
      "Epoch: [86/100], Step: [6000/6250], Loss: 0.7667 \n",
      "\n",
      "Epoch: [86/100], Step: [6100/6250], Loss: 0.2434 \n",
      "\n",
      "Epoch: [86/100], Step: [6200/6250], Loss: 0.2865 \n",
      "\n",
      "Epoch: [87/100], Step: [100/6250], Loss: 0.1778 \n",
      "\n",
      "Epoch: [87/100], Step: [200/6250], Loss: 0.1152 \n",
      "\n",
      "Epoch: [87/100], Step: [300/6250], Loss: 0.4641 \n",
      "\n",
      "Epoch: [87/100], Step: [400/6250], Loss: 0.5345 \n",
      "\n",
      "Epoch: [87/100], Step: [500/6250], Loss: 0.4121 \n",
      "\n",
      "Epoch: [87/100], Step: [600/6250], Loss: 0.2426 \n",
      "\n",
      "Epoch: [87/100], Step: [700/6250], Loss: 0.3067 \n",
      "\n",
      "Epoch: [87/100], Step: [800/6250], Loss: 0.2783 \n",
      "\n",
      "Epoch: [87/100], Step: [900/6250], Loss: 0.1165 \n",
      "\n",
      "Epoch: [87/100], Step: [1000/6250], Loss: 0.1814 \n",
      "\n",
      "Epoch: [87/100], Step: [1100/6250], Loss: 0.1608 \n",
      "\n",
      "Epoch: [87/100], Step: [1200/6250], Loss: 0.4301 \n",
      "\n",
      "Epoch: [87/100], Step: [1300/6250], Loss: 0.4320 \n",
      "\n",
      "Epoch: [87/100], Step: [1400/6250], Loss: 0.1712 \n",
      "\n",
      "Epoch: [87/100], Step: [1500/6250], Loss: 1.1004 \n",
      "\n",
      "Epoch: [87/100], Step: [1600/6250], Loss: 0.3157 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [87/100], Step: [1700/6250], Loss: 0.1387 \n",
      "\n",
      "Epoch: [87/100], Step: [1800/6250], Loss: 0.8696 \n",
      "\n",
      "Epoch: [87/100], Step: [1900/6250], Loss: 0.4660 \n",
      "\n",
      "Epoch: [87/100], Step: [2000/6250], Loss: 1.6734 \n",
      "\n",
      "Epoch: [87/100], Step: [2100/6250], Loss: 0.5548 \n",
      "\n",
      "Epoch: [87/100], Step: [2200/6250], Loss: 0.5034 \n",
      "\n",
      "Epoch: [87/100], Step: [2300/6250], Loss: 0.3808 \n",
      "\n",
      "Epoch: [87/100], Step: [2400/6250], Loss: 0.0374 \n",
      "\n",
      "Epoch: [87/100], Step: [2500/6250], Loss: 0.2980 \n",
      "\n",
      "Epoch: [87/100], Step: [2600/6250], Loss: 0.7776 \n",
      "\n",
      "Epoch: [87/100], Step: [2700/6250], Loss: 0.5419 \n",
      "\n",
      "Epoch: [87/100], Step: [2800/6250], Loss: 0.5391 \n",
      "\n",
      "Epoch: [87/100], Step: [2900/6250], Loss: 0.1667 \n",
      "\n",
      "Epoch: [87/100], Step: [3000/6250], Loss: 0.6372 \n",
      "\n",
      "Epoch: [87/100], Step: [3100/6250], Loss: 0.9238 \n",
      "\n",
      "Epoch: [87/100], Step: [3200/6250], Loss: 0.5016 \n",
      "\n",
      "Epoch: [87/100], Step: [3300/6250], Loss: 0.1480 \n",
      "\n",
      "Epoch: [87/100], Step: [3400/6250], Loss: 1.0976 \n",
      "\n",
      "Epoch: [87/100], Step: [3500/6250], Loss: 0.6570 \n",
      "\n",
      "Epoch: [87/100], Step: [3600/6250], Loss: 0.3903 \n",
      "\n",
      "Epoch: [87/100], Step: [3700/6250], Loss: 0.8069 \n",
      "\n",
      "Epoch: [87/100], Step: [3800/6250], Loss: 0.5045 \n",
      "\n",
      "Epoch: [87/100], Step: [3900/6250], Loss: 0.4174 \n",
      "\n",
      "Epoch: [87/100], Step: [4000/6250], Loss: 0.3123 \n",
      "\n",
      "Epoch: [87/100], Step: [4100/6250], Loss: 0.1347 \n",
      "\n",
      "Epoch: [87/100], Step: [4200/6250], Loss: 0.4929 \n",
      "\n",
      "Epoch: [87/100], Step: [4300/6250], Loss: 0.2189 \n",
      "\n",
      "Epoch: [87/100], Step: [4400/6250], Loss: 0.4728 \n",
      "\n",
      "Epoch: [87/100], Step: [4500/6250], Loss: 0.5121 \n",
      "\n",
      "Epoch: [87/100], Step: [4600/6250], Loss: 0.1648 \n",
      "\n",
      "Epoch: [87/100], Step: [4700/6250], Loss: 0.4887 \n",
      "\n",
      "Epoch: [87/100], Step: [4800/6250], Loss: 0.2291 \n",
      "\n",
      "Epoch: [87/100], Step: [4900/6250], Loss: 0.2871 \n",
      "\n",
      "Epoch: [87/100], Step: [5000/6250], Loss: 0.0236 \n",
      "\n",
      "Epoch: [87/100], Step: [5100/6250], Loss: 0.0369 \n",
      "\n",
      "Epoch: [87/100], Step: [5200/6250], Loss: 0.2618 \n",
      "\n",
      "Epoch: [87/100], Step: [5300/6250], Loss: 0.5124 \n",
      "\n",
      "Epoch: [87/100], Step: [5400/6250], Loss: 0.2452 \n",
      "\n",
      "Epoch: [87/100], Step: [5500/6250], Loss: 0.2362 \n",
      "\n",
      "Epoch: [87/100], Step: [5600/6250], Loss: 0.0930 \n",
      "\n",
      "Epoch: [87/100], Step: [5700/6250], Loss: 0.3848 \n",
      "\n",
      "Epoch: [87/100], Step: [5800/6250], Loss: 0.6180 \n",
      "\n",
      "Epoch: [87/100], Step: [5900/6250], Loss: 0.1384 \n",
      "\n",
      "Epoch: [87/100], Step: [6000/6250], Loss: 0.3145 \n",
      "\n",
      "Epoch: [87/100], Step: [6100/6250], Loss: 0.7418 \n",
      "\n",
      "Epoch: [87/100], Step: [6200/6250], Loss: 0.2010 \n",
      "\n",
      "Epoch: [88/100], Step: [100/6250], Loss: 0.3482 \n",
      "\n",
      "Epoch: [88/100], Step: [200/6250], Loss: 0.5759 \n",
      "\n",
      "Epoch: [88/100], Step: [300/6250], Loss: 0.1661 \n",
      "\n",
      "Epoch: [88/100], Step: [400/6250], Loss: 0.6788 \n",
      "\n",
      "Epoch: [88/100], Step: [500/6250], Loss: 0.2219 \n",
      "\n",
      "Epoch: [88/100], Step: [600/6250], Loss: 0.1161 \n",
      "\n",
      "Epoch: [88/100], Step: [700/6250], Loss: 0.2004 \n",
      "\n",
      "Epoch: [88/100], Step: [800/6250], Loss: 0.1496 \n",
      "\n",
      "Epoch: [88/100], Step: [900/6250], Loss: 0.4156 \n",
      "\n",
      "Epoch: [88/100], Step: [1000/6250], Loss: 0.4740 \n",
      "\n",
      "Epoch: [88/100], Step: [1100/6250], Loss: 0.1966 \n",
      "\n",
      "Epoch: [88/100], Step: [1200/6250], Loss: 0.2613 \n",
      "\n",
      "Epoch: [88/100], Step: [1300/6250], Loss: 0.3994 \n",
      "\n",
      "Epoch: [88/100], Step: [1400/6250], Loss: 0.1455 \n",
      "\n",
      "Epoch: [88/100], Step: [1500/6250], Loss: 0.3091 \n",
      "\n",
      "Epoch: [88/100], Step: [1600/6250], Loss: 0.1105 \n",
      "\n",
      "Epoch: [88/100], Step: [1700/6250], Loss: 0.6528 \n",
      "\n",
      "Epoch: [88/100], Step: [1800/6250], Loss: 1.1491 \n",
      "\n",
      "Epoch: [88/100], Step: [1900/6250], Loss: 0.6117 \n",
      "\n",
      "Epoch: [88/100], Step: [2000/6250], Loss: 0.6630 \n",
      "\n",
      "Epoch: [88/100], Step: [2100/6250], Loss: 0.1119 \n",
      "\n",
      "Epoch: [88/100], Step: [2200/6250], Loss: 0.6488 \n",
      "\n",
      "Epoch: [88/100], Step: [2300/6250], Loss: 0.9148 \n",
      "\n",
      "Epoch: [88/100], Step: [2400/6250], Loss: 0.5825 \n",
      "\n",
      "Epoch: [88/100], Step: [2500/6250], Loss: 0.4427 \n",
      "\n",
      "Epoch: [88/100], Step: [2600/6250], Loss: 0.2870 \n",
      "\n",
      "Epoch: [88/100], Step: [2700/6250], Loss: 0.4824 \n",
      "\n",
      "Epoch: [88/100], Step: [2800/6250], Loss: 0.0350 \n",
      "\n",
      "Epoch: [88/100], Step: [2900/6250], Loss: 0.5122 \n",
      "\n",
      "Epoch: [88/100], Step: [3000/6250], Loss: 0.2462 \n",
      "\n",
      "Epoch: [88/100], Step: [3100/6250], Loss: 0.0734 \n",
      "\n",
      "Epoch: [88/100], Step: [3200/6250], Loss: 0.4945 \n",
      "\n",
      "Epoch: [88/100], Step: [3300/6250], Loss: 0.4522 \n",
      "\n",
      "Epoch: [88/100], Step: [3400/6250], Loss: 0.4703 \n",
      "\n",
      "Epoch: [88/100], Step: [3500/6250], Loss: 1.1420 \n",
      "\n",
      "Epoch: [88/100], Step: [3600/6250], Loss: 1.0452 \n",
      "\n",
      "Epoch: [88/100], Step: [3700/6250], Loss: 0.4861 \n",
      "\n",
      "Epoch: [88/100], Step: [3800/6250], Loss: 0.6060 \n",
      "\n",
      "Epoch: [88/100], Step: [3900/6250], Loss: 0.1594 \n",
      "\n",
      "Epoch: [88/100], Step: [4000/6250], Loss: 0.9693 \n",
      "\n",
      "Epoch: [88/100], Step: [4100/6250], Loss: 0.5542 \n",
      "\n",
      "Epoch: [88/100], Step: [4200/6250], Loss: 0.9598 \n",
      "\n",
      "Epoch: [88/100], Step: [4300/6250], Loss: 0.5164 \n",
      "\n",
      "Epoch: [88/100], Step: [4400/6250], Loss: 0.9086 \n",
      "\n",
      "Epoch: [88/100], Step: [4500/6250], Loss: 0.1661 \n",
      "\n",
      "Epoch: [88/100], Step: [4600/6250], Loss: 0.6077 \n",
      "\n",
      "Epoch: [88/100], Step: [4700/6250], Loss: 0.3707 \n",
      "\n",
      "Epoch: [88/100], Step: [4800/6250], Loss: 0.2117 \n",
      "\n",
      "Epoch: [88/100], Step: [4900/6250], Loss: 0.6182 \n",
      "\n",
      "Epoch: [88/100], Step: [5000/6250], Loss: 0.6289 \n",
      "\n",
      "Epoch: [88/100], Step: [5100/6250], Loss: 0.0488 \n",
      "\n",
      "Epoch: [88/100], Step: [5200/6250], Loss: 0.2990 \n",
      "\n",
      "Epoch: [88/100], Step: [5300/6250], Loss: 0.5760 \n",
      "\n",
      "Epoch: [88/100], Step: [5400/6250], Loss: 0.1115 \n",
      "\n",
      "Epoch: [88/100], Step: [5500/6250], Loss: 0.6411 \n",
      "\n",
      "Epoch: [88/100], Step: [5600/6250], Loss: 0.5177 \n",
      "\n",
      "Epoch: [88/100], Step: [5700/6250], Loss: 1.3583 \n",
      "\n",
      "Epoch: [88/100], Step: [5800/6250], Loss: 0.2058 \n",
      "\n",
      "Epoch: [88/100], Step: [5900/6250], Loss: 0.4149 \n",
      "\n",
      "Epoch: [88/100], Step: [6000/6250], Loss: 0.4359 \n",
      "\n",
      "Epoch: [88/100], Step: [6100/6250], Loss: 0.7895 \n",
      "\n",
      "Epoch: [88/100], Step: [6200/6250], Loss: 0.4472 \n",
      "\n",
      "Epoch: [89/100], Step: [100/6250], Loss: 0.5226 \n",
      "\n",
      "Epoch: [89/100], Step: [200/6250], Loss: 0.1843 \n",
      "\n",
      "Epoch: [89/100], Step: [300/6250], Loss: 0.2813 \n",
      "\n",
      "Epoch: [89/100], Step: [400/6250], Loss: 0.7353 \n",
      "\n",
      "Epoch: [89/100], Step: [500/6250], Loss: 0.1949 \n",
      "\n",
      "Epoch: [89/100], Step: [600/6250], Loss: 0.4716 \n",
      "\n",
      "Epoch: [89/100], Step: [700/6250], Loss: 0.6341 \n",
      "\n",
      "Epoch: [89/100], Step: [800/6250], Loss: 0.0632 \n",
      "\n",
      "Epoch: [89/100], Step: [900/6250], Loss: 0.2121 \n",
      "\n",
      "Epoch: [89/100], Step: [1000/6250], Loss: 0.3366 \n",
      "\n",
      "Epoch: [89/100], Step: [1100/6250], Loss: 0.3774 \n",
      "\n",
      "Epoch: [89/100], Step: [1200/6250], Loss: 0.4548 \n",
      "\n",
      "Epoch: [89/100], Step: [1300/6250], Loss: 0.3617 \n",
      "\n",
      "Epoch: [89/100], Step: [1400/6250], Loss: 0.1203 \n",
      "\n",
      "Epoch: [89/100], Step: [1500/6250], Loss: 0.7392 \n",
      "\n",
      "Epoch: [89/100], Step: [1600/6250], Loss: 1.0180 \n",
      "\n",
      "Epoch: [89/100], Step: [1700/6250], Loss: 0.3475 \n",
      "\n",
      "Epoch: [89/100], Step: [1800/6250], Loss: 0.2800 \n",
      "\n",
      "Epoch: [89/100], Step: [1900/6250], Loss: 0.7556 \n",
      "\n",
      "Epoch: [89/100], Step: [2000/6250], Loss: 0.2798 \n",
      "\n",
      "Epoch: [89/100], Step: [2100/6250], Loss: 0.2640 \n",
      "\n",
      "Epoch: [89/100], Step: [2200/6250], Loss: 1.0507 \n",
      "\n",
      "Epoch: [89/100], Step: [2300/6250], Loss: 0.4214 \n",
      "\n",
      "Epoch: [89/100], Step: [2400/6250], Loss: 0.2477 \n",
      "\n",
      "Epoch: [89/100], Step: [2500/6250], Loss: 0.1282 \n",
      "\n",
      "Epoch: [89/100], Step: [2600/6250], Loss: 0.2769 \n",
      "\n",
      "Epoch: [89/100], Step: [2700/6250], Loss: 0.5251 \n",
      "\n",
      "Epoch: [89/100], Step: [2800/6250], Loss: 0.4012 \n",
      "\n",
      "Epoch: [89/100], Step: [2900/6250], Loss: 0.1713 \n",
      "\n",
      "Epoch: [89/100], Step: [3000/6250], Loss: 0.2359 \n",
      "\n",
      "Epoch: [89/100], Step: [3100/6250], Loss: 0.4061 \n",
      "\n",
      "Epoch: [89/100], Step: [3200/6250], Loss: 0.1330 \n",
      "\n",
      "Epoch: [89/100], Step: [3300/6250], Loss: 0.4458 \n",
      "\n",
      "Epoch: [89/100], Step: [3400/6250], Loss: 0.6349 \n",
      "\n",
      "Epoch: [89/100], Step: [3500/6250], Loss: 0.6002 \n",
      "\n",
      "Epoch: [89/100], Step: [3600/6250], Loss: 0.1097 \n",
      "\n",
      "Epoch: [89/100], Step: [3700/6250], Loss: 0.3870 \n",
      "\n",
      "Epoch: [89/100], Step: [3800/6250], Loss: 0.2061 \n",
      "\n",
      "Epoch: [89/100], Step: [3900/6250], Loss: 0.3045 \n",
      "\n",
      "Epoch: [89/100], Step: [4000/6250], Loss: 0.8137 \n",
      "\n",
      "Epoch: [89/100], Step: [4100/6250], Loss: 0.1585 \n",
      "\n",
      "Epoch: [89/100], Step: [4200/6250], Loss: 0.2338 \n",
      "\n",
      "Epoch: [89/100], Step: [4300/6250], Loss: 0.8643 \n",
      "\n",
      "Epoch: [89/100], Step: [4400/6250], Loss: 0.7285 \n",
      "\n",
      "Epoch: [89/100], Step: [4500/6250], Loss: 0.2816 \n",
      "\n",
      "Epoch: [89/100], Step: [4600/6250], Loss: 0.2887 \n",
      "\n",
      "Epoch: [89/100], Step: [4700/6250], Loss: 0.7254 \n",
      "\n",
      "Epoch: [89/100], Step: [4800/6250], Loss: 0.4977 \n",
      "\n",
      "Epoch: [89/100], Step: [4900/6250], Loss: 0.2268 \n",
      "\n",
      "Epoch: [89/100], Step: [5000/6250], Loss: 1.0082 \n",
      "\n",
      "Epoch: [89/100], Step: [5100/6250], Loss: 0.4324 \n",
      "\n",
      "Epoch: [89/100], Step: [5200/6250], Loss: 0.3947 \n",
      "\n",
      "Epoch: [89/100], Step: [5300/6250], Loss: 0.3414 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [89/100], Step: [5400/6250], Loss: 0.1678 \n",
      "\n",
      "Epoch: [89/100], Step: [5500/6250], Loss: 0.3484 \n",
      "\n",
      "Epoch: [89/100], Step: [5600/6250], Loss: 0.4068 \n",
      "\n",
      "Epoch: [89/100], Step: [5700/6250], Loss: 0.2880 \n",
      "\n",
      "Epoch: [89/100], Step: [5800/6250], Loss: 0.1616 \n",
      "\n",
      "Epoch: [89/100], Step: [5900/6250], Loss: 0.2774 \n",
      "\n",
      "Epoch: [89/100], Step: [6000/6250], Loss: 0.9866 \n",
      "\n",
      "Epoch: [89/100], Step: [6100/6250], Loss: 0.2313 \n",
      "\n",
      "Epoch: [89/100], Step: [6200/6250], Loss: 0.3026 \n",
      "\n",
      "Epoch: [90/100], Step: [100/6250], Loss: 0.3542 \n",
      "\n",
      "Epoch: [90/100], Step: [200/6250], Loss: 0.1262 \n",
      "\n",
      "Epoch: [90/100], Step: [300/6250], Loss: 0.7523 \n",
      "\n",
      "Epoch: [90/100], Step: [400/6250], Loss: 0.8964 \n",
      "\n",
      "Epoch: [90/100], Step: [500/6250], Loss: 0.5300 \n",
      "\n",
      "Epoch: [90/100], Step: [600/6250], Loss: 0.1911 \n",
      "\n",
      "Epoch: [90/100], Step: [700/6250], Loss: 0.1871 \n",
      "\n",
      "Epoch: [90/100], Step: [800/6250], Loss: 0.8258 \n",
      "\n",
      "Epoch: [90/100], Step: [900/6250], Loss: 1.0454 \n",
      "\n",
      "Epoch: [90/100], Step: [1000/6250], Loss: 0.6218 \n",
      "\n",
      "Epoch: [90/100], Step: [1100/6250], Loss: 0.1679 \n",
      "\n",
      "Epoch: [90/100], Step: [1200/6250], Loss: 0.3777 \n",
      "\n",
      "Epoch: [90/100], Step: [1300/6250], Loss: 0.4313 \n",
      "\n",
      "Epoch: [90/100], Step: [1400/6250], Loss: 0.3117 \n",
      "\n",
      "Epoch: [90/100], Step: [1500/6250], Loss: 0.3184 \n",
      "\n",
      "Epoch: [90/100], Step: [1600/6250], Loss: 0.1532 \n",
      "\n",
      "Epoch: [90/100], Step: [1700/6250], Loss: 0.1584 \n",
      "\n",
      "Epoch: [90/100], Step: [1800/6250], Loss: 0.4871 \n",
      "\n",
      "Epoch: [90/100], Step: [1900/6250], Loss: 0.2400 \n",
      "\n",
      "Epoch: [90/100], Step: [2000/6250], Loss: 0.1987 \n",
      "\n",
      "Epoch: [90/100], Step: [2100/6250], Loss: 0.6688 \n",
      "\n",
      "Epoch: [90/100], Step: [2200/6250], Loss: 0.9058 \n",
      "\n",
      "Epoch: [90/100], Step: [2300/6250], Loss: 0.5838 \n",
      "\n",
      "Epoch: [90/100], Step: [2400/6250], Loss: 0.4542 \n",
      "\n",
      "Epoch: [90/100], Step: [2500/6250], Loss: 0.4480 \n",
      "\n",
      "Epoch: [90/100], Step: [2600/6250], Loss: 0.4664 \n",
      "\n",
      "Epoch: [90/100], Step: [2700/6250], Loss: 0.5270 \n",
      "\n",
      "Epoch: [90/100], Step: [2800/6250], Loss: 0.6720 \n",
      "\n",
      "Epoch: [90/100], Step: [2900/6250], Loss: 0.1619 \n",
      "\n",
      "Epoch: [90/100], Step: [3000/6250], Loss: 0.9553 \n",
      "\n",
      "Epoch: [90/100], Step: [3100/6250], Loss: 0.1817 \n",
      "\n",
      "Epoch: [90/100], Step: [3200/6250], Loss: 0.6584 \n",
      "\n",
      "Epoch: [90/100], Step: [3300/6250], Loss: 0.2871 \n",
      "\n",
      "Epoch: [90/100], Step: [3400/6250], Loss: 0.2159 \n",
      "\n",
      "Epoch: [90/100], Step: [3500/6250], Loss: 0.2827 \n",
      "\n",
      "Epoch: [90/100], Step: [3600/6250], Loss: 0.2191 \n",
      "\n",
      "Epoch: [90/100], Step: [3700/6250], Loss: 0.9852 \n",
      "\n",
      "Epoch: [90/100], Step: [3800/6250], Loss: 0.7477 \n",
      "\n",
      "Epoch: [90/100], Step: [3900/6250], Loss: 0.2545 \n",
      "\n",
      "Epoch: [90/100], Step: [4000/6250], Loss: 0.2633 \n",
      "\n",
      "Epoch: [90/100], Step: [4100/6250], Loss: 0.7249 \n",
      "\n",
      "Epoch: [90/100], Step: [4200/6250], Loss: 0.3358 \n",
      "\n",
      "Epoch: [90/100], Step: [4300/6250], Loss: 0.2396 \n",
      "\n",
      "Epoch: [90/100], Step: [4400/6250], Loss: 0.3325 \n",
      "\n",
      "Epoch: [90/100], Step: [4500/6250], Loss: 0.2229 \n",
      "\n",
      "Epoch: [90/100], Step: [4600/6250], Loss: 0.4350 \n",
      "\n",
      "Epoch: [90/100], Step: [4700/6250], Loss: 0.1398 \n",
      "\n",
      "Epoch: [90/100], Step: [4800/6250], Loss: 0.4562 \n",
      "\n",
      "Epoch: [90/100], Step: [4900/6250], Loss: 1.0873 \n",
      "\n",
      "Epoch: [90/100], Step: [5000/6250], Loss: 0.6016 \n",
      "\n",
      "Epoch: [90/100], Step: [5100/6250], Loss: 0.1885 \n",
      "\n",
      "Epoch: [90/100], Step: [5200/6250], Loss: 0.2677 \n",
      "\n",
      "Epoch: [90/100], Step: [5300/6250], Loss: 0.3854 \n",
      "\n",
      "Epoch: [90/100], Step: [5400/6250], Loss: 0.4738 \n",
      "\n",
      "Epoch: [90/100], Step: [5500/6250], Loss: 0.1391 \n",
      "\n",
      "Epoch: [90/100], Step: [5600/6250], Loss: 0.2392 \n",
      "\n",
      "Epoch: [90/100], Step: [5700/6250], Loss: 0.5964 \n",
      "\n",
      "Epoch: [90/100], Step: [5800/6250], Loss: 0.4898 \n",
      "\n",
      "Epoch: [90/100], Step: [5900/6250], Loss: 0.8231 \n",
      "\n",
      "Epoch: [90/100], Step: [6000/6250], Loss: 0.4875 \n",
      "\n",
      "Epoch: [90/100], Step: [6100/6250], Loss: 0.2041 \n",
      "\n",
      "Epoch: [90/100], Step: [6200/6250], Loss: 0.3217 \n",
      "\n",
      "Epoch: [91/100], Step: [100/6250], Loss: 0.3706 \n",
      "\n",
      "Epoch: [91/100], Step: [200/6250], Loss: 0.3517 \n",
      "\n",
      "Epoch: [91/100], Step: [300/6250], Loss: 0.1187 \n",
      "\n",
      "Epoch: [91/100], Step: [400/6250], Loss: 0.9812 \n",
      "\n",
      "Epoch: [91/100], Step: [500/6250], Loss: 0.2924 \n",
      "\n",
      "Epoch: [91/100], Step: [600/6250], Loss: 0.2180 \n",
      "\n",
      "Epoch: [91/100], Step: [700/6250], Loss: 1.4414 \n",
      "\n",
      "Epoch: [91/100], Step: [800/6250], Loss: 0.2688 \n",
      "\n",
      "Epoch: [91/100], Step: [900/6250], Loss: 0.3019 \n",
      "\n",
      "Epoch: [91/100], Step: [1000/6250], Loss: 0.1224 \n",
      "\n",
      "Epoch: [91/100], Step: [1100/6250], Loss: 0.5125 \n",
      "\n",
      "Epoch: [91/100], Step: [1200/6250], Loss: 0.4946 \n",
      "\n",
      "Epoch: [91/100], Step: [1300/6250], Loss: 0.3378 \n",
      "\n",
      "Epoch: [91/100], Step: [1400/6250], Loss: 0.3191 \n",
      "\n",
      "Epoch: [91/100], Step: [1500/6250], Loss: 0.3052 \n",
      "\n",
      "Epoch: [91/100], Step: [1600/6250], Loss: 0.4103 \n",
      "\n",
      "Epoch: [91/100], Step: [1700/6250], Loss: 0.6439 \n",
      "\n",
      "Epoch: [91/100], Step: [1800/6250], Loss: 0.3919 \n",
      "\n",
      "Epoch: [91/100], Step: [1900/6250], Loss: 0.1096 \n",
      "\n",
      "Epoch: [91/100], Step: [2000/6250], Loss: 0.3590 \n",
      "\n",
      "Epoch: [91/100], Step: [2100/6250], Loss: 0.2261 \n",
      "\n",
      "Epoch: [91/100], Step: [2200/6250], Loss: 0.3739 \n",
      "\n",
      "Epoch: [91/100], Step: [2300/6250], Loss: 0.3267 \n",
      "\n",
      "Epoch: [91/100], Step: [2400/6250], Loss: 1.5087 \n",
      "\n",
      "Epoch: [91/100], Step: [2500/6250], Loss: 0.7714 \n",
      "\n",
      "Epoch: [91/100], Step: [2600/6250], Loss: 0.1722 \n",
      "\n",
      "Epoch: [91/100], Step: [2700/6250], Loss: 0.1928 \n",
      "\n",
      "Epoch: [91/100], Step: [2800/6250], Loss: 0.4021 \n",
      "\n",
      "Epoch: [91/100], Step: [2900/6250], Loss: 0.2251 \n",
      "\n",
      "Epoch: [91/100], Step: [3000/6250], Loss: 0.3281 \n",
      "\n",
      "Epoch: [91/100], Step: [3100/6250], Loss: 0.2340 \n",
      "\n",
      "Epoch: [91/100], Step: [3200/6250], Loss: 0.3900 \n",
      "\n",
      "Epoch: [91/100], Step: [3300/6250], Loss: 1.0086 \n",
      "\n",
      "Epoch: [91/100], Step: [3400/6250], Loss: 0.4526 \n",
      "\n",
      "Epoch: [91/100], Step: [3500/6250], Loss: 0.6585 \n",
      "\n",
      "Epoch: [91/100], Step: [3600/6250], Loss: 0.1285 \n",
      "\n",
      "Epoch: [91/100], Step: [3700/6250], Loss: 0.3426 \n",
      "\n",
      "Epoch: [91/100], Step: [3800/6250], Loss: 0.3774 \n",
      "\n",
      "Epoch: [91/100], Step: [3900/6250], Loss: 0.5081 \n",
      "\n",
      "Epoch: [91/100], Step: [4000/6250], Loss: 0.5074 \n",
      "\n",
      "Epoch: [91/100], Step: [4100/6250], Loss: 0.9410 \n",
      "\n",
      "Epoch: [91/100], Step: [4200/6250], Loss: 0.4455 \n",
      "\n",
      "Epoch: [91/100], Step: [4300/6250], Loss: 0.8969 \n",
      "\n",
      "Epoch: [91/100], Step: [4400/6250], Loss: 0.0229 \n",
      "\n",
      "Epoch: [91/100], Step: [4500/6250], Loss: 0.9645 \n",
      "\n",
      "Epoch: [91/100], Step: [4600/6250], Loss: 0.1862 \n",
      "\n",
      "Epoch: [91/100], Step: [4700/6250], Loss: 0.8126 \n",
      "\n",
      "Epoch: [91/100], Step: [4800/6250], Loss: 0.3093 \n",
      "\n",
      "Epoch: [91/100], Step: [4900/6250], Loss: 0.1842 \n",
      "\n",
      "Epoch: [91/100], Step: [5000/6250], Loss: 0.7520 \n",
      "\n",
      "Epoch: [91/100], Step: [5100/6250], Loss: 0.3400 \n",
      "\n",
      "Epoch: [91/100], Step: [5200/6250], Loss: 0.2420 \n",
      "\n",
      "Epoch: [91/100], Step: [5300/6250], Loss: 0.4804 \n",
      "\n",
      "Epoch: [91/100], Step: [5400/6250], Loss: 0.4518 \n",
      "\n",
      "Epoch: [91/100], Step: [5500/6250], Loss: 0.6740 \n",
      "\n",
      "Epoch: [91/100], Step: [5600/6250], Loss: 0.5647 \n",
      "\n",
      "Epoch: [91/100], Step: [5700/6250], Loss: 0.3788 \n",
      "\n",
      "Epoch: [91/100], Step: [5800/6250], Loss: 0.3756 \n",
      "\n",
      "Epoch: [91/100], Step: [5900/6250], Loss: 0.5726 \n",
      "\n",
      "Epoch: [91/100], Step: [6000/6250], Loss: 0.2375 \n",
      "\n",
      "Epoch: [91/100], Step: [6100/6250], Loss: 0.3550 \n",
      "\n",
      "Epoch: [91/100], Step: [6200/6250], Loss: 0.1298 \n",
      "\n",
      "Epoch: [92/100], Step: [100/6250], Loss: 0.7531 \n",
      "\n",
      "Epoch: [92/100], Step: [200/6250], Loss: 0.4200 \n",
      "\n",
      "Epoch: [92/100], Step: [300/6250], Loss: 0.6596 \n",
      "\n",
      "Epoch: [92/100], Step: [400/6250], Loss: 0.3779 \n",
      "\n",
      "Epoch: [92/100], Step: [500/6250], Loss: 0.3341 \n",
      "\n",
      "Epoch: [92/100], Step: [600/6250], Loss: 0.6539 \n",
      "\n",
      "Epoch: [92/100], Step: [700/6250], Loss: 0.2103 \n",
      "\n",
      "Epoch: [92/100], Step: [800/6250], Loss: 0.0664 \n",
      "\n",
      "Epoch: [92/100], Step: [900/6250], Loss: 0.2530 \n",
      "\n",
      "Epoch: [92/100], Step: [1000/6250], Loss: 0.4858 \n",
      "\n",
      "Epoch: [92/100], Step: [1100/6250], Loss: 0.5130 \n",
      "\n",
      "Epoch: [92/100], Step: [1200/6250], Loss: 0.9972 \n",
      "\n",
      "Epoch: [92/100], Step: [1300/6250], Loss: 0.2782 \n",
      "\n",
      "Epoch: [92/100], Step: [1400/6250], Loss: 0.7703 \n",
      "\n",
      "Epoch: [92/100], Step: [1500/6250], Loss: 0.3271 \n",
      "\n",
      "Epoch: [92/100], Step: [1600/6250], Loss: 0.7108 \n",
      "\n",
      "Epoch: [92/100], Step: [1700/6250], Loss: 0.7914 \n",
      "\n",
      "Epoch: [92/100], Step: [1800/6250], Loss: 1.1083 \n",
      "\n",
      "Epoch: [92/100], Step: [1900/6250], Loss: 0.3054 \n",
      "\n",
      "Epoch: [92/100], Step: [2000/6250], Loss: 0.5068 \n",
      "\n",
      "Epoch: [92/100], Step: [2100/6250], Loss: 0.1548 \n",
      "\n",
      "Epoch: [92/100], Step: [2200/6250], Loss: 0.3520 \n",
      "\n",
      "Epoch: [92/100], Step: [2300/6250], Loss: 0.3776 \n",
      "\n",
      "Epoch: [92/100], Step: [2400/6250], Loss: 0.5811 \n",
      "\n",
      "Epoch: [92/100], Step: [2500/6250], Loss: 0.0291 \n",
      "\n",
      "Epoch: [92/100], Step: [2600/6250], Loss: 0.5084 \n",
      "\n",
      "Epoch: [92/100], Step: [2700/6250], Loss: 0.4759 \n",
      "\n",
      "Epoch: [92/100], Step: [2800/6250], Loss: 0.5228 \n",
      "\n",
      "Epoch: [92/100], Step: [2900/6250], Loss: 0.3476 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [92/100], Step: [3000/6250], Loss: 0.2733 \n",
      "\n",
      "Epoch: [92/100], Step: [3100/6250], Loss: 0.2269 \n",
      "\n",
      "Epoch: [92/100], Step: [3200/6250], Loss: 0.2527 \n",
      "\n",
      "Epoch: [92/100], Step: [3300/6250], Loss: 0.2277 \n",
      "\n",
      "Epoch: [92/100], Step: [3400/6250], Loss: 0.3330 \n",
      "\n",
      "Epoch: [92/100], Step: [3500/6250], Loss: 0.2965 \n",
      "\n",
      "Epoch: [92/100], Step: [3600/6250], Loss: 0.4550 \n",
      "\n",
      "Epoch: [92/100], Step: [3700/6250], Loss: 0.3071 \n",
      "\n",
      "Epoch: [92/100], Step: [3800/6250], Loss: 0.3284 \n",
      "\n",
      "Epoch: [92/100], Step: [3900/6250], Loss: 0.3913 \n",
      "\n",
      "Epoch: [92/100], Step: [4000/6250], Loss: 0.6935 \n",
      "\n",
      "Epoch: [92/100], Step: [4100/6250], Loss: 0.1508 \n",
      "\n",
      "Epoch: [92/100], Step: [4200/6250], Loss: 0.7571 \n",
      "\n",
      "Epoch: [92/100], Step: [4300/6250], Loss: 0.2851 \n",
      "\n",
      "Epoch: [92/100], Step: [4400/6250], Loss: 0.3025 \n",
      "\n",
      "Epoch: [92/100], Step: [4500/6250], Loss: 0.1828 \n",
      "\n",
      "Epoch: [92/100], Step: [4600/6250], Loss: 0.4847 \n",
      "\n",
      "Epoch: [92/100], Step: [4700/6250], Loss: 0.7234 \n",
      "\n",
      "Epoch: [92/100], Step: [4800/6250], Loss: 0.3450 \n",
      "\n",
      "Epoch: [92/100], Step: [4900/6250], Loss: 0.4616 \n",
      "\n",
      "Epoch: [92/100], Step: [5000/6250], Loss: 0.5376 \n",
      "\n",
      "Epoch: [92/100], Step: [5100/6250], Loss: 0.5974 \n",
      "\n",
      "Epoch: [92/100], Step: [5200/6250], Loss: 0.3759 \n",
      "\n",
      "Epoch: [92/100], Step: [5300/6250], Loss: 0.3952 \n",
      "\n",
      "Epoch: [92/100], Step: [5400/6250], Loss: 0.6473 \n",
      "\n",
      "Epoch: [92/100], Step: [5500/6250], Loss: 0.2100 \n",
      "\n",
      "Epoch: [92/100], Step: [5600/6250], Loss: 0.7004 \n",
      "\n",
      "Epoch: [92/100], Step: [5700/6250], Loss: 0.0818 \n",
      "\n",
      "Epoch: [92/100], Step: [5800/6250], Loss: 0.5102 \n",
      "\n",
      "Epoch: [92/100], Step: [5900/6250], Loss: 0.6707 \n",
      "\n",
      "Epoch: [92/100], Step: [6000/6250], Loss: 0.6546 \n",
      "\n",
      "Epoch: [92/100], Step: [6100/6250], Loss: 0.5024 \n",
      "\n",
      "Epoch: [92/100], Step: [6200/6250], Loss: 0.1252 \n",
      "\n",
      "Epoch: [93/100], Step: [100/6250], Loss: 0.2033 \n",
      "\n",
      "Epoch: [93/100], Step: [200/6250], Loss: 0.6401 \n",
      "\n",
      "Epoch: [93/100], Step: [300/6250], Loss: 0.3955 \n",
      "\n",
      "Epoch: [93/100], Step: [400/6250], Loss: 0.2103 \n",
      "\n",
      "Epoch: [93/100], Step: [500/6250], Loss: 0.1322 \n",
      "\n",
      "Epoch: [93/100], Step: [600/6250], Loss: 0.0310 \n",
      "\n",
      "Epoch: [93/100], Step: [700/6250], Loss: 0.0471 \n",
      "\n",
      "Epoch: [93/100], Step: [800/6250], Loss: 0.1880 \n",
      "\n",
      "Epoch: [93/100], Step: [900/6250], Loss: 0.4029 \n",
      "\n",
      "Epoch: [93/100], Step: [1000/6250], Loss: 0.6040 \n",
      "\n",
      "Epoch: [93/100], Step: [1100/6250], Loss: 0.4907 \n",
      "\n",
      "Epoch: [93/100], Step: [1200/6250], Loss: 0.4873 \n",
      "\n",
      "Epoch: [93/100], Step: [1300/6250], Loss: 0.6253 \n",
      "\n",
      "Epoch: [93/100], Step: [1400/6250], Loss: 0.2731 \n",
      "\n",
      "Epoch: [93/100], Step: [1500/6250], Loss: 0.4849 \n",
      "\n",
      "Epoch: [93/100], Step: [1600/6250], Loss: 1.0266 \n",
      "\n",
      "Epoch: [93/100], Step: [1700/6250], Loss: 0.2982 \n",
      "\n",
      "Epoch: [93/100], Step: [1800/6250], Loss: 0.8182 \n",
      "\n",
      "Epoch: [93/100], Step: [1900/6250], Loss: 0.2974 \n",
      "\n",
      "Epoch: [93/100], Step: [2000/6250], Loss: 0.4187 \n",
      "\n",
      "Epoch: [93/100], Step: [2100/6250], Loss: 0.6620 \n",
      "\n",
      "Epoch: [93/100], Step: [2200/6250], Loss: 0.9364 \n",
      "\n",
      "Epoch: [93/100], Step: [2300/6250], Loss: 0.2472 \n",
      "\n",
      "Epoch: [93/100], Step: [2400/6250], Loss: 0.8471 \n",
      "\n",
      "Epoch: [93/100], Step: [2500/6250], Loss: 0.8181 \n",
      "\n",
      "Epoch: [93/100], Step: [2600/6250], Loss: 0.3694 \n",
      "\n",
      "Epoch: [93/100], Step: [2700/6250], Loss: 0.6579 \n",
      "\n",
      "Epoch: [93/100], Step: [2800/6250], Loss: 0.1871 \n",
      "\n",
      "Epoch: [93/100], Step: [2900/6250], Loss: 0.1032 \n",
      "\n",
      "Epoch: [93/100], Step: [3000/6250], Loss: 0.8914 \n",
      "\n",
      "Epoch: [93/100], Step: [3100/6250], Loss: 1.1291 \n",
      "\n",
      "Epoch: [93/100], Step: [3200/6250], Loss: 0.1980 \n",
      "\n",
      "Epoch: [93/100], Step: [3300/6250], Loss: 0.9585 \n",
      "\n",
      "Epoch: [93/100], Step: [3400/6250], Loss: 0.2167 \n",
      "\n",
      "Epoch: [93/100], Step: [3500/6250], Loss: 0.4539 \n",
      "\n",
      "Epoch: [93/100], Step: [3600/6250], Loss: 0.1871 \n",
      "\n",
      "Epoch: [93/100], Step: [3700/6250], Loss: 0.2774 \n",
      "\n",
      "Epoch: [93/100], Step: [3800/6250], Loss: 0.1870 \n",
      "\n",
      "Epoch: [93/100], Step: [3900/6250], Loss: 0.5658 \n",
      "\n",
      "Epoch: [93/100], Step: [4000/6250], Loss: 0.4477 \n",
      "\n",
      "Epoch: [93/100], Step: [4100/6250], Loss: 0.2302 \n",
      "\n",
      "Epoch: [93/100], Step: [4200/6250], Loss: 1.3029 \n",
      "\n",
      "Epoch: [93/100], Step: [4300/6250], Loss: 0.2179 \n",
      "\n",
      "Epoch: [93/100], Step: [4400/6250], Loss: 0.4833 \n",
      "\n",
      "Epoch: [93/100], Step: [4500/6250], Loss: 0.3460 \n",
      "\n",
      "Epoch: [93/100], Step: [4600/6250], Loss: 0.4559 \n",
      "\n",
      "Epoch: [93/100], Step: [4700/6250], Loss: 0.2024 \n",
      "\n",
      "Epoch: [93/100], Step: [4800/6250], Loss: 0.6150 \n",
      "\n",
      "Epoch: [93/100], Step: [4900/6250], Loss: 0.3716 \n",
      "\n",
      "Epoch: [93/100], Step: [5000/6250], Loss: 0.2963 \n",
      "\n",
      "Epoch: [93/100], Step: [5100/6250], Loss: 0.5906 \n",
      "\n",
      "Epoch: [93/100], Step: [5200/6250], Loss: 0.2372 \n",
      "\n",
      "Epoch: [93/100], Step: [5300/6250], Loss: 1.1410 \n",
      "\n",
      "Epoch: [93/100], Step: [5400/6250], Loss: 0.0416 \n",
      "\n",
      "Epoch: [93/100], Step: [5500/6250], Loss: 0.3055 \n",
      "\n",
      "Epoch: [93/100], Step: [5600/6250], Loss: 0.5513 \n",
      "\n",
      "Epoch: [93/100], Step: [5700/6250], Loss: 0.6440 \n",
      "\n",
      "Epoch: [93/100], Step: [5800/6250], Loss: 0.1291 \n",
      "\n",
      "Epoch: [93/100], Step: [5900/6250], Loss: 0.2608 \n",
      "\n",
      "Epoch: [93/100], Step: [6000/6250], Loss: 0.0876 \n",
      "\n",
      "Epoch: [93/100], Step: [6100/6250], Loss: 0.5338 \n",
      "\n",
      "Epoch: [93/100], Step: [6200/6250], Loss: 0.9068 \n",
      "\n",
      "Epoch: [94/100], Step: [100/6250], Loss: 0.1704 \n",
      "\n",
      "Epoch: [94/100], Step: [200/6250], Loss: 0.4653 \n",
      "\n",
      "Epoch: [94/100], Step: [300/6250], Loss: 0.2731 \n",
      "\n",
      "Epoch: [94/100], Step: [400/6250], Loss: 0.3640 \n",
      "\n",
      "Epoch: [94/100], Step: [500/6250], Loss: 0.3637 \n",
      "\n",
      "Epoch: [94/100], Step: [600/6250], Loss: 0.7813 \n",
      "\n",
      "Epoch: [94/100], Step: [700/6250], Loss: 0.2282 \n",
      "\n",
      "Epoch: [94/100], Step: [800/6250], Loss: 1.0012 \n",
      "\n",
      "Epoch: [94/100], Step: [900/6250], Loss: 0.0735 \n",
      "\n",
      "Epoch: [94/100], Step: [1000/6250], Loss: 0.3742 \n",
      "\n",
      "Epoch: [94/100], Step: [1100/6250], Loss: 0.3953 \n",
      "\n",
      "Epoch: [94/100], Step: [1200/6250], Loss: 0.3568 \n",
      "\n",
      "Epoch: [94/100], Step: [1300/6250], Loss: 0.1494 \n",
      "\n",
      "Epoch: [94/100], Step: [1400/6250], Loss: 0.2332 \n",
      "\n",
      "Epoch: [94/100], Step: [1500/6250], Loss: 0.3893 \n",
      "\n",
      "Epoch: [94/100], Step: [1600/6250], Loss: 0.6465 \n",
      "\n",
      "Epoch: [94/100], Step: [1700/6250], Loss: 0.4988 \n",
      "\n",
      "Epoch: [94/100], Step: [1800/6250], Loss: 0.5514 \n",
      "\n",
      "Epoch: [94/100], Step: [1900/6250], Loss: 0.1473 \n",
      "\n",
      "Epoch: [94/100], Step: [2000/6250], Loss: 0.2917 \n",
      "\n",
      "Epoch: [94/100], Step: [2100/6250], Loss: 0.5069 \n",
      "\n",
      "Epoch: [94/100], Step: [2200/6250], Loss: 0.7750 \n",
      "\n",
      "Epoch: [94/100], Step: [2300/6250], Loss: 0.1254 \n",
      "\n",
      "Epoch: [94/100], Step: [2400/6250], Loss: 0.7174 \n",
      "\n",
      "Epoch: [94/100], Step: [2500/6250], Loss: 0.1278 \n",
      "\n",
      "Epoch: [94/100], Step: [2600/6250], Loss: 0.1681 \n",
      "\n",
      "Epoch: [94/100], Step: [2700/6250], Loss: 0.2071 \n",
      "\n",
      "Epoch: [94/100], Step: [2800/6250], Loss: 0.5064 \n",
      "\n",
      "Epoch: [94/100], Step: [2900/6250], Loss: 0.1570 \n",
      "\n",
      "Epoch: [94/100], Step: [3000/6250], Loss: 0.3765 \n",
      "\n",
      "Epoch: [94/100], Step: [3100/6250], Loss: 0.3655 \n",
      "\n",
      "Epoch: [94/100], Step: [3200/6250], Loss: 0.2335 \n",
      "\n",
      "Epoch: [94/100], Step: [3300/6250], Loss: 0.2804 \n",
      "\n",
      "Epoch: [94/100], Step: [3400/6250], Loss: 0.5437 \n",
      "\n",
      "Epoch: [94/100], Step: [3500/6250], Loss: 0.8246 \n",
      "\n",
      "Epoch: [94/100], Step: [3600/6250], Loss: 0.5165 \n",
      "\n",
      "Epoch: [94/100], Step: [3700/6250], Loss: 0.4552 \n",
      "\n",
      "Epoch: [94/100], Step: [3800/6250], Loss: 0.3537 \n",
      "\n",
      "Epoch: [94/100], Step: [3900/6250], Loss: 0.1279 \n",
      "\n",
      "Epoch: [94/100], Step: [4000/6250], Loss: 0.7227 \n",
      "\n",
      "Epoch: [94/100], Step: [4100/6250], Loss: 0.7716 \n",
      "\n",
      "Epoch: [94/100], Step: [4200/6250], Loss: 0.9169 \n",
      "\n",
      "Epoch: [94/100], Step: [4300/6250], Loss: 0.4799 \n",
      "\n",
      "Epoch: [94/100], Step: [4400/6250], Loss: 0.1016 \n",
      "\n",
      "Epoch: [94/100], Step: [4500/6250], Loss: 0.4568 \n",
      "\n",
      "Epoch: [94/100], Step: [4600/6250], Loss: 0.5134 \n",
      "\n",
      "Epoch: [94/100], Step: [4700/6250], Loss: 0.1454 \n",
      "\n",
      "Epoch: [94/100], Step: [4800/6250], Loss: 0.3208 \n",
      "\n",
      "Epoch: [94/100], Step: [4900/6250], Loss: 0.4255 \n",
      "\n",
      "Epoch: [94/100], Step: [5000/6250], Loss: 0.7666 \n",
      "\n",
      "Epoch: [94/100], Step: [5100/6250], Loss: 1.0160 \n",
      "\n",
      "Epoch: [94/100], Step: [5200/6250], Loss: 0.4924 \n",
      "\n",
      "Epoch: [94/100], Step: [5300/6250], Loss: 0.0949 \n",
      "\n",
      "Epoch: [94/100], Step: [5400/6250], Loss: 0.5054 \n",
      "\n",
      "Epoch: [94/100], Step: [5500/6250], Loss: 0.4785 \n",
      "\n",
      "Epoch: [94/100], Step: [5600/6250], Loss: 0.2405 \n",
      "\n",
      "Epoch: [94/100], Step: [5700/6250], Loss: 0.3366 \n",
      "\n",
      "Epoch: [94/100], Step: [5800/6250], Loss: 0.9936 \n",
      "\n",
      "Epoch: [94/100], Step: [5900/6250], Loss: 0.4070 \n",
      "\n",
      "Epoch: [94/100], Step: [6000/6250], Loss: 0.5126 \n",
      "\n",
      "Epoch: [94/100], Step: [6100/6250], Loss: 0.0630 \n",
      "\n",
      "Epoch: [94/100], Step: [6200/6250], Loss: 0.8333 \n",
      "\n",
      "Epoch: [95/100], Step: [100/6250], Loss: 0.3728 \n",
      "\n",
      "Epoch: [95/100], Step: [200/6250], Loss: 0.3867 \n",
      "\n",
      "Epoch: [95/100], Step: [300/6250], Loss: 0.2769 \n",
      "\n",
      "Epoch: [95/100], Step: [400/6250], Loss: 0.8090 \n",
      "\n",
      "Epoch: [95/100], Step: [500/6250], Loss: 0.5725 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [95/100], Step: [600/6250], Loss: 0.0604 \n",
      "\n",
      "Epoch: [95/100], Step: [700/6250], Loss: 0.3079 \n",
      "\n",
      "Epoch: [95/100], Step: [800/6250], Loss: 0.2773 \n",
      "\n",
      "Epoch: [95/100], Step: [900/6250], Loss: 0.5711 \n",
      "\n",
      "Epoch: [95/100], Step: [1000/6250], Loss: 0.0800 \n",
      "\n",
      "Epoch: [95/100], Step: [1100/6250], Loss: 0.7771 \n",
      "\n",
      "Epoch: [95/100], Step: [1200/6250], Loss: 0.3358 \n",
      "\n",
      "Epoch: [95/100], Step: [1300/6250], Loss: 0.3621 \n",
      "\n",
      "Epoch: [95/100], Step: [1400/6250], Loss: 0.2927 \n",
      "\n",
      "Epoch: [95/100], Step: [1500/6250], Loss: 0.1081 \n",
      "\n",
      "Epoch: [95/100], Step: [1600/6250], Loss: 0.1195 \n",
      "\n",
      "Epoch: [95/100], Step: [1700/6250], Loss: 0.1712 \n",
      "\n",
      "Epoch: [95/100], Step: [1800/6250], Loss: 0.6056 \n",
      "\n",
      "Epoch: [95/100], Step: [1900/6250], Loss: 0.8159 \n",
      "\n",
      "Epoch: [95/100], Step: [2000/6250], Loss: 0.3920 \n",
      "\n",
      "Epoch: [95/100], Step: [2100/6250], Loss: 0.2004 \n",
      "\n",
      "Epoch: [95/100], Step: [2200/6250], Loss: 0.2293 \n",
      "\n",
      "Epoch: [95/100], Step: [2300/6250], Loss: 0.0623 \n",
      "\n",
      "Epoch: [95/100], Step: [2400/6250], Loss: 0.0488 \n",
      "\n",
      "Epoch: [95/100], Step: [2500/6250], Loss: 0.0253 \n",
      "\n",
      "Epoch: [95/100], Step: [2600/6250], Loss: 0.1892 \n",
      "\n",
      "Epoch: [95/100], Step: [2700/6250], Loss: 0.5220 \n",
      "\n",
      "Epoch: [95/100], Step: [2800/6250], Loss: 0.3237 \n",
      "\n",
      "Epoch: [95/100], Step: [2900/6250], Loss: 0.1096 \n",
      "\n",
      "Epoch: [95/100], Step: [3000/6250], Loss: 0.0432 \n",
      "\n",
      "Epoch: [95/100], Step: [3100/6250], Loss: 1.0682 \n",
      "\n",
      "Epoch: [95/100], Step: [3200/6250], Loss: 0.2417 \n",
      "\n",
      "Epoch: [95/100], Step: [3300/6250], Loss: 0.8454 \n",
      "\n",
      "Epoch: [95/100], Step: [3400/6250], Loss: 0.0203 \n",
      "\n",
      "Epoch: [95/100], Step: [3500/6250], Loss: 0.3572 \n",
      "\n",
      "Epoch: [95/100], Step: [3600/6250], Loss: 0.2449 \n",
      "\n",
      "Epoch: [95/100], Step: [3700/6250], Loss: 0.1439 \n",
      "\n",
      "Epoch: [95/100], Step: [3800/6250], Loss: 0.8909 \n",
      "\n",
      "Epoch: [95/100], Step: [3900/6250], Loss: 0.0524 \n",
      "\n",
      "Epoch: [95/100], Step: [4000/6250], Loss: 0.5706 \n",
      "\n",
      "Epoch: [95/100], Step: [4100/6250], Loss: 0.8219 \n",
      "\n",
      "Epoch: [95/100], Step: [4200/6250], Loss: 0.7528 \n",
      "\n",
      "Epoch: [95/100], Step: [4300/6250], Loss: 0.2306 \n",
      "\n",
      "Epoch: [95/100], Step: [4400/6250], Loss: 0.1295 \n",
      "\n",
      "Epoch: [95/100], Step: [4500/6250], Loss: 0.0857 \n",
      "\n",
      "Epoch: [95/100], Step: [4600/6250], Loss: 0.2332 \n",
      "\n",
      "Epoch: [95/100], Step: [4700/6250], Loss: 0.2350 \n",
      "\n",
      "Epoch: [95/100], Step: [4800/6250], Loss: 0.4087 \n",
      "\n",
      "Epoch: [95/100], Step: [4900/6250], Loss: 0.5005 \n",
      "\n",
      "Epoch: [95/100], Step: [5000/6250], Loss: 0.4285 \n",
      "\n",
      "Epoch: [95/100], Step: [5100/6250], Loss: 0.2392 \n",
      "\n",
      "Epoch: [95/100], Step: [5200/6250], Loss: 0.1912 \n",
      "\n",
      "Epoch: [95/100], Step: [5300/6250], Loss: 1.1788 \n",
      "\n",
      "Epoch: [95/100], Step: [5400/6250], Loss: 0.2709 \n",
      "\n",
      "Epoch: [95/100], Step: [5500/6250], Loss: 0.3741 \n",
      "\n",
      "Epoch: [95/100], Step: [5600/6250], Loss: 0.4913 \n",
      "\n",
      "Epoch: [95/100], Step: [5700/6250], Loss: 0.2860 \n",
      "\n",
      "Epoch: [95/100], Step: [5800/6250], Loss: 0.0915 \n",
      "\n",
      "Epoch: [95/100], Step: [5900/6250], Loss: 0.0191 \n",
      "\n",
      "Epoch: [95/100], Step: [6000/6250], Loss: 0.9048 \n",
      "\n",
      "Epoch: [95/100], Step: [6100/6250], Loss: 0.6311 \n",
      "\n",
      "Epoch: [95/100], Step: [6200/6250], Loss: 0.7078 \n",
      "\n",
      "Epoch: [96/100], Step: [100/6250], Loss: 0.2465 \n",
      "\n",
      "Epoch: [96/100], Step: [200/6250], Loss: 0.4748 \n",
      "\n",
      "Epoch: [96/100], Step: [300/6250], Loss: 0.6534 \n",
      "\n",
      "Epoch: [96/100], Step: [400/6250], Loss: 0.1837 \n",
      "\n",
      "Epoch: [96/100], Step: [500/6250], Loss: 0.2797 \n",
      "\n",
      "Epoch: [96/100], Step: [600/6250], Loss: 0.1811 \n",
      "\n",
      "Epoch: [96/100], Step: [700/6250], Loss: 0.2552 \n",
      "\n",
      "Epoch: [96/100], Step: [800/6250], Loss: 0.1173 \n",
      "\n",
      "Epoch: [96/100], Step: [900/6250], Loss: 0.2961 \n",
      "\n",
      "Epoch: [96/100], Step: [1000/6250], Loss: 0.3490 \n",
      "\n",
      "Epoch: [96/100], Step: [1100/6250], Loss: 0.3338 \n",
      "\n",
      "Epoch: [96/100], Step: [1200/6250], Loss: 0.2414 \n",
      "\n",
      "Epoch: [96/100], Step: [1300/6250], Loss: 0.3297 \n",
      "\n",
      "Epoch: [96/100], Step: [1400/6250], Loss: 0.5155 \n",
      "\n",
      "Epoch: [96/100], Step: [1500/6250], Loss: 1.2412 \n",
      "\n",
      "Epoch: [96/100], Step: [1600/6250], Loss: 0.2475 \n",
      "\n",
      "Epoch: [96/100], Step: [1700/6250], Loss: 0.3839 \n",
      "\n",
      "Epoch: [96/100], Step: [1800/6250], Loss: 0.2985 \n",
      "\n",
      "Epoch: [96/100], Step: [1900/6250], Loss: 0.1795 \n",
      "\n",
      "Epoch: [96/100], Step: [2000/6250], Loss: 0.3305 \n",
      "\n",
      "Epoch: [96/100], Step: [2100/6250], Loss: 0.2252 \n",
      "\n",
      "Epoch: [96/100], Step: [2200/6250], Loss: 0.1737 \n",
      "\n",
      "Epoch: [96/100], Step: [2300/6250], Loss: 0.0915 \n",
      "\n",
      "Epoch: [96/100], Step: [2400/6250], Loss: 0.2797 \n",
      "\n",
      "Epoch: [96/100], Step: [2500/6250], Loss: 0.6837 \n",
      "\n",
      "Epoch: [96/100], Step: [2600/6250], Loss: 0.4582 \n",
      "\n",
      "Epoch: [96/100], Step: [2700/6250], Loss: 0.0778 \n",
      "\n",
      "Epoch: [96/100], Step: [2800/6250], Loss: 0.3577 \n",
      "\n",
      "Epoch: [96/100], Step: [2900/6250], Loss: 0.4617 \n",
      "\n",
      "Epoch: [96/100], Step: [3000/6250], Loss: 0.9353 \n",
      "\n",
      "Epoch: [96/100], Step: [3100/6250], Loss: 0.2248 \n",
      "\n",
      "Epoch: [96/100], Step: [3200/6250], Loss: 0.3249 \n",
      "\n",
      "Epoch: [96/100], Step: [3300/6250], Loss: 0.5865 \n",
      "\n",
      "Epoch: [96/100], Step: [3400/6250], Loss: 0.1079 \n",
      "\n",
      "Epoch: [96/100], Step: [3500/6250], Loss: 0.3026 \n",
      "\n",
      "Epoch: [96/100], Step: [3600/6250], Loss: 0.1367 \n",
      "\n",
      "Epoch: [96/100], Step: [3700/6250], Loss: 0.3426 \n",
      "\n",
      "Epoch: [96/100], Step: [3800/6250], Loss: 0.4347 \n",
      "\n",
      "Epoch: [96/100], Step: [3900/6250], Loss: 0.5370 \n",
      "\n",
      "Epoch: [96/100], Step: [4000/6250], Loss: 0.2312 \n",
      "\n",
      "Epoch: [96/100], Step: [4100/6250], Loss: 0.3294 \n",
      "\n",
      "Epoch: [96/100], Step: [4200/6250], Loss: 0.1316 \n",
      "\n",
      "Epoch: [96/100], Step: [4300/6250], Loss: 0.4997 \n",
      "\n",
      "Epoch: [96/100], Step: [4400/6250], Loss: 0.1506 \n",
      "\n",
      "Epoch: [96/100], Step: [4500/6250], Loss: 0.2176 \n",
      "\n",
      "Epoch: [96/100], Step: [4600/6250], Loss: 0.0270 \n",
      "\n",
      "Epoch: [96/100], Step: [4700/6250], Loss: 0.2173 \n",
      "\n",
      "Epoch: [96/100], Step: [4800/6250], Loss: 0.0372 \n",
      "\n",
      "Epoch: [96/100], Step: [4900/6250], Loss: 1.2243 \n",
      "\n",
      "Epoch: [96/100], Step: [5000/6250], Loss: 0.7192 \n",
      "\n",
      "Epoch: [96/100], Step: [5100/6250], Loss: 0.6110 \n",
      "\n",
      "Epoch: [96/100], Step: [5200/6250], Loss: 0.6121 \n",
      "\n",
      "Epoch: [96/100], Step: [5300/6250], Loss: 0.1023 \n",
      "\n",
      "Epoch: [96/100], Step: [5400/6250], Loss: 0.2468 \n",
      "\n",
      "Epoch: [96/100], Step: [5500/6250], Loss: 0.6428 \n",
      "\n",
      "Epoch: [96/100], Step: [5600/6250], Loss: 0.5207 \n",
      "\n",
      "Epoch: [96/100], Step: [5700/6250], Loss: 0.6977 \n",
      "\n",
      "Epoch: [96/100], Step: [5800/6250], Loss: 0.0942 \n",
      "\n",
      "Epoch: [96/100], Step: [5900/6250], Loss: 1.1630 \n",
      "\n",
      "Epoch: [96/100], Step: [6000/6250], Loss: 0.4167 \n",
      "\n",
      "Epoch: [96/100], Step: [6100/6250], Loss: 0.2096 \n",
      "\n",
      "Epoch: [96/100], Step: [6200/6250], Loss: 0.0424 \n",
      "\n",
      "Epoch: [97/100], Step: [100/6250], Loss: 0.1849 \n",
      "\n",
      "Epoch: [97/100], Step: [200/6250], Loss: 0.2950 \n",
      "\n",
      "Epoch: [97/100], Step: [300/6250], Loss: 0.1687 \n",
      "\n",
      "Epoch: [97/100], Step: [400/6250], Loss: 0.1644 \n",
      "\n",
      "Epoch: [97/100], Step: [500/6250], Loss: 0.4128 \n",
      "\n",
      "Epoch: [97/100], Step: [600/6250], Loss: 0.4576 \n",
      "\n",
      "Epoch: [97/100], Step: [700/6250], Loss: 0.5447 \n",
      "\n",
      "Epoch: [97/100], Step: [800/6250], Loss: 0.4168 \n",
      "\n",
      "Epoch: [97/100], Step: [900/6250], Loss: 0.5321 \n",
      "\n",
      "Epoch: [97/100], Step: [1000/6250], Loss: 0.1885 \n",
      "\n",
      "Epoch: [97/100], Step: [1100/6250], Loss: 0.3505 \n",
      "\n",
      "Epoch: [97/100], Step: [1200/6250], Loss: 0.2834 \n",
      "\n",
      "Epoch: [97/100], Step: [1300/6250], Loss: 0.1942 \n",
      "\n",
      "Epoch: [97/100], Step: [1400/6250], Loss: 0.1911 \n",
      "\n",
      "Epoch: [97/100], Step: [1500/6250], Loss: 1.0246 \n",
      "\n",
      "Epoch: [97/100], Step: [1600/6250], Loss: 0.3500 \n",
      "\n",
      "Epoch: [97/100], Step: [1700/6250], Loss: 0.6527 \n",
      "\n",
      "Epoch: [97/100], Step: [1800/6250], Loss: 0.7499 \n",
      "\n",
      "Epoch: [97/100], Step: [1900/6250], Loss: 0.0025 \n",
      "\n",
      "Epoch: [97/100], Step: [2000/6250], Loss: 0.3878 \n",
      "\n",
      "Epoch: [97/100], Step: [2100/6250], Loss: 0.6583 \n",
      "\n",
      "Epoch: [97/100], Step: [2200/6250], Loss: 0.2580 \n",
      "\n",
      "Epoch: [97/100], Step: [2300/6250], Loss: 0.4643 \n",
      "\n",
      "Epoch: [97/100], Step: [2400/6250], Loss: 0.1026 \n",
      "\n",
      "Epoch: [97/100], Step: [2500/6250], Loss: 0.3827 \n",
      "\n",
      "Epoch: [97/100], Step: [2600/6250], Loss: 0.7613 \n",
      "\n",
      "Epoch: [97/100], Step: [2700/6250], Loss: 0.1014 \n",
      "\n",
      "Epoch: [97/100], Step: [2800/6250], Loss: 0.2556 \n",
      "\n",
      "Epoch: [97/100], Step: [2900/6250], Loss: 0.4700 \n",
      "\n",
      "Epoch: [97/100], Step: [3000/6250], Loss: 0.3629 \n",
      "\n",
      "Epoch: [97/100], Step: [3100/6250], Loss: 0.4382 \n",
      "\n",
      "Epoch: [97/100], Step: [3200/6250], Loss: 0.1052 \n",
      "\n",
      "Epoch: [97/100], Step: [3300/6250], Loss: 0.3873 \n",
      "\n",
      "Epoch: [97/100], Step: [3400/6250], Loss: 0.3089 \n",
      "\n",
      "Epoch: [97/100], Step: [3500/6250], Loss: 0.3529 \n",
      "\n",
      "Epoch: [97/100], Step: [3600/6250], Loss: 0.3649 \n",
      "\n",
      "Epoch: [97/100], Step: [3700/6250], Loss: 0.2424 \n",
      "\n",
      "Epoch: [97/100], Step: [3800/6250], Loss: 0.3506 \n",
      "\n",
      "Epoch: [97/100], Step: [3900/6250], Loss: 0.3414 \n",
      "\n",
      "Epoch: [97/100], Step: [4000/6250], Loss: 0.5075 \n",
      "\n",
      "Epoch: [97/100], Step: [4100/6250], Loss: 0.3652 \n",
      "\n",
      "Epoch: [97/100], Step: [4200/6250], Loss: 0.0975 \n",
      "\n",
      "Epoch: [97/100], Step: [4300/6250], Loss: 0.0564 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [97/100], Step: [4400/6250], Loss: 0.4416 \n",
      "\n",
      "Epoch: [97/100], Step: [4500/6250], Loss: 1.0313 \n",
      "\n",
      "Epoch: [97/100], Step: [4600/6250], Loss: 0.4098 \n",
      "\n",
      "Epoch: [97/100], Step: [4700/6250], Loss: 0.4013 \n",
      "\n",
      "Epoch: [97/100], Step: [4800/6250], Loss: 0.9566 \n",
      "\n",
      "Epoch: [97/100], Step: [4900/6250], Loss: 0.1827 \n",
      "\n",
      "Epoch: [97/100], Step: [5000/6250], Loss: 0.1558 \n",
      "\n",
      "Epoch: [97/100], Step: [5100/6250], Loss: 0.1110 \n",
      "\n",
      "Epoch: [97/100], Step: [5200/6250], Loss: 0.2934 \n",
      "\n",
      "Epoch: [97/100], Step: [5300/6250], Loss: 0.1189 \n",
      "\n",
      "Epoch: [97/100], Step: [5400/6250], Loss: 0.3540 \n",
      "\n",
      "Epoch: [97/100], Step: [5500/6250], Loss: 0.1897 \n",
      "\n",
      "Epoch: [97/100], Step: [5600/6250], Loss: 0.2990 \n",
      "\n",
      "Epoch: [97/100], Step: [5700/6250], Loss: 0.3643 \n",
      "\n",
      "Epoch: [97/100], Step: [5800/6250], Loss: 0.5100 \n",
      "\n",
      "Epoch: [97/100], Step: [5900/6250], Loss: 0.1742 \n",
      "\n",
      "Epoch: [97/100], Step: [6000/6250], Loss: 0.2901 \n",
      "\n",
      "Epoch: [97/100], Step: [6100/6250], Loss: 1.0661 \n",
      "\n",
      "Epoch: [97/100], Step: [6200/6250], Loss: 0.5383 \n",
      "\n",
      "Epoch: [98/100], Step: [100/6250], Loss: 0.1293 \n",
      "\n",
      "Epoch: [98/100], Step: [200/6250], Loss: 0.3886 \n",
      "\n",
      "Epoch: [98/100], Step: [300/6250], Loss: 0.6733 \n",
      "\n",
      "Epoch: [98/100], Step: [400/6250], Loss: 0.3041 \n",
      "\n",
      "Epoch: [98/100], Step: [500/6250], Loss: 0.2469 \n",
      "\n",
      "Epoch: [98/100], Step: [600/6250], Loss: 0.4344 \n",
      "\n",
      "Epoch: [98/100], Step: [700/6250], Loss: 0.0609 \n",
      "\n",
      "Epoch: [98/100], Step: [800/6250], Loss: 0.3424 \n",
      "\n",
      "Epoch: [98/100], Step: [900/6250], Loss: 0.0587 \n",
      "\n",
      "Epoch: [98/100], Step: [1000/6250], Loss: 0.2660 \n",
      "\n",
      "Epoch: [98/100], Step: [1100/6250], Loss: 0.1622 \n",
      "\n",
      "Epoch: [98/100], Step: [1200/6250], Loss: 0.6753 \n",
      "\n",
      "Epoch: [98/100], Step: [1300/6250], Loss: 0.2741 \n",
      "\n",
      "Epoch: [98/100], Step: [1400/6250], Loss: 0.4990 \n",
      "\n",
      "Epoch: [98/100], Step: [1500/6250], Loss: 0.1168 \n",
      "\n",
      "Epoch: [98/100], Step: [1600/6250], Loss: 0.4670 \n",
      "\n",
      "Epoch: [98/100], Step: [1700/6250], Loss: 0.3557 \n",
      "\n",
      "Epoch: [98/100], Step: [1800/6250], Loss: 0.4717 \n",
      "\n",
      "Epoch: [98/100], Step: [1900/6250], Loss: 0.1841 \n",
      "\n",
      "Epoch: [98/100], Step: [2000/6250], Loss: 0.3059 \n",
      "\n",
      "Epoch: [98/100], Step: [2100/6250], Loss: 0.3297 \n",
      "\n",
      "Epoch: [98/100], Step: [2200/6250], Loss: 0.9401 \n",
      "\n",
      "Epoch: [98/100], Step: [2300/6250], Loss: 1.3216 \n",
      "\n",
      "Epoch: [98/100], Step: [2400/6250], Loss: 0.1011 \n",
      "\n",
      "Epoch: [98/100], Step: [2500/6250], Loss: 0.3780 \n",
      "\n",
      "Epoch: [98/100], Step: [2600/6250], Loss: 0.2435 \n",
      "\n",
      "Epoch: [98/100], Step: [2700/6250], Loss: 0.5550 \n",
      "\n",
      "Epoch: [98/100], Step: [2800/6250], Loss: 0.4061 \n",
      "\n",
      "Epoch: [98/100], Step: [2900/6250], Loss: 0.5528 \n",
      "\n",
      "Epoch: [98/100], Step: [3000/6250], Loss: 0.2868 \n",
      "\n",
      "Epoch: [98/100], Step: [3100/6250], Loss: 0.1143 \n",
      "\n",
      "Epoch: [98/100], Step: [3200/6250], Loss: 0.4120 \n",
      "\n",
      "Epoch: [98/100], Step: [3300/6250], Loss: 0.1420 \n",
      "\n",
      "Epoch: [98/100], Step: [3400/6250], Loss: 0.2323 \n",
      "\n",
      "Epoch: [98/100], Step: [3500/6250], Loss: 0.3469 \n",
      "\n",
      "Epoch: [98/100], Step: [3600/6250], Loss: 0.4445 \n",
      "\n",
      "Epoch: [98/100], Step: [3700/6250], Loss: 1.1501 \n",
      "\n",
      "Epoch: [98/100], Step: [3800/6250], Loss: 0.1564 \n",
      "\n",
      "Epoch: [98/100], Step: [3900/6250], Loss: 0.2215 \n",
      "\n",
      "Epoch: [98/100], Step: [4000/6250], Loss: 0.5246 \n",
      "\n",
      "Epoch: [98/100], Step: [4100/6250], Loss: 0.0684 \n",
      "\n",
      "Epoch: [98/100], Step: [4200/6250], Loss: 0.0235 \n",
      "\n",
      "Epoch: [98/100], Step: [4300/6250], Loss: 0.3041 \n",
      "\n",
      "Epoch: [98/100], Step: [4400/6250], Loss: 0.6860 \n",
      "\n",
      "Epoch: [98/100], Step: [4500/6250], Loss: 0.3620 \n",
      "\n",
      "Epoch: [98/100], Step: [4600/6250], Loss: 0.1350 \n",
      "\n",
      "Epoch: [98/100], Step: [4700/6250], Loss: 0.1522 \n",
      "\n",
      "Epoch: [98/100], Step: [4800/6250], Loss: 0.3121 \n",
      "\n",
      "Epoch: [98/100], Step: [4900/6250], Loss: 0.6318 \n",
      "\n",
      "Epoch: [98/100], Step: [5000/6250], Loss: 0.2731 \n",
      "\n",
      "Epoch: [98/100], Step: [5100/6250], Loss: 0.2687 \n",
      "\n",
      "Epoch: [98/100], Step: [5200/6250], Loss: 0.4764 \n",
      "\n",
      "Epoch: [98/100], Step: [5300/6250], Loss: 0.5097 \n",
      "\n",
      "Epoch: [98/100], Step: [5400/6250], Loss: 0.2487 \n",
      "\n",
      "Epoch: [98/100], Step: [5500/6250], Loss: 0.6394 \n",
      "\n",
      "Epoch: [98/100], Step: [5600/6250], Loss: 0.7661 \n",
      "\n",
      "Epoch: [98/100], Step: [5700/6250], Loss: 0.1286 \n",
      "\n",
      "Epoch: [98/100], Step: [5800/6250], Loss: 0.2877 \n",
      "\n",
      "Epoch: [98/100], Step: [5900/6250], Loss: 0.3532 \n",
      "\n",
      "Epoch: [98/100], Step: [6000/6250], Loss: 0.6115 \n",
      "\n",
      "Epoch: [98/100], Step: [6100/6250], Loss: 0.1148 \n",
      "\n",
      "Epoch: [98/100], Step: [6200/6250], Loss: 0.3055 \n",
      "\n",
      "Epoch: [99/100], Step: [100/6250], Loss: 0.0024 \n",
      "\n",
      "Epoch: [99/100], Step: [200/6250], Loss: 0.1564 \n",
      "\n",
      "Epoch: [99/100], Step: [300/6250], Loss: 0.2954 \n",
      "\n",
      "Epoch: [99/100], Step: [400/6250], Loss: 0.2065 \n",
      "\n",
      "Epoch: [99/100], Step: [500/6250], Loss: 0.5332 \n",
      "\n",
      "Epoch: [99/100], Step: [600/6250], Loss: 0.3311 \n",
      "\n",
      "Epoch: [99/100], Step: [700/6250], Loss: 0.1018 \n",
      "\n",
      "Epoch: [99/100], Step: [800/6250], Loss: 0.1555 \n",
      "\n",
      "Epoch: [99/100], Step: [900/6250], Loss: 0.0747 \n",
      "\n",
      "Epoch: [99/100], Step: [1000/6250], Loss: 0.4827 \n",
      "\n",
      "Epoch: [99/100], Step: [1100/6250], Loss: 1.0556 \n",
      "\n",
      "Epoch: [99/100], Step: [1200/6250], Loss: 0.3042 \n",
      "\n",
      "Epoch: [99/100], Step: [1300/6250], Loss: 1.0165 \n",
      "\n",
      "Epoch: [99/100], Step: [1400/6250], Loss: 0.3777 \n",
      "\n",
      "Epoch: [99/100], Step: [1500/6250], Loss: 1.0189 \n",
      "\n",
      "Epoch: [99/100], Step: [1600/6250], Loss: 0.6073 \n",
      "\n",
      "Epoch: [99/100], Step: [1700/6250], Loss: 0.1649 \n",
      "\n",
      "Epoch: [99/100], Step: [1800/6250], Loss: 0.3393 \n",
      "\n",
      "Epoch: [99/100], Step: [1900/6250], Loss: 0.1371 \n",
      "\n",
      "Epoch: [99/100], Step: [2000/6250], Loss: 0.3439 \n",
      "\n",
      "Epoch: [99/100], Step: [2100/6250], Loss: 0.1192 \n",
      "\n",
      "Epoch: [99/100], Step: [2200/6250], Loss: 0.6227 \n",
      "\n",
      "Epoch: [99/100], Step: [2300/6250], Loss: 0.3626 \n",
      "\n",
      "Epoch: [99/100], Step: [2400/6250], Loss: 0.8894 \n",
      "\n",
      "Epoch: [99/100], Step: [2500/6250], Loss: 1.1705 \n",
      "\n",
      "Epoch: [99/100], Step: [2600/6250], Loss: 0.2483 \n",
      "\n",
      "Epoch: [99/100], Step: [2700/6250], Loss: 0.3864 \n",
      "\n",
      "Epoch: [99/100], Step: [2800/6250], Loss: 0.4479 \n",
      "\n",
      "Epoch: [99/100], Step: [2900/6250], Loss: 0.5958 \n",
      "\n",
      "Epoch: [99/100], Step: [3000/6250], Loss: 0.4693 \n",
      "\n",
      "Epoch: [99/100], Step: [3100/6250], Loss: 0.2445 \n",
      "\n",
      "Epoch: [99/100], Step: [3200/6250], Loss: 0.1622 \n",
      "\n",
      "Epoch: [99/100], Step: [3300/6250], Loss: 0.0788 \n",
      "\n",
      "Epoch: [99/100], Step: [3400/6250], Loss: 0.5139 \n",
      "\n",
      "Epoch: [99/100], Step: [3500/6250], Loss: 0.3215 \n",
      "\n",
      "Epoch: [99/100], Step: [3600/6250], Loss: 0.8226 \n",
      "\n",
      "Epoch: [99/100], Step: [3700/6250], Loss: 0.4530 \n",
      "\n",
      "Epoch: [99/100], Step: [3800/6250], Loss: 0.6500 \n",
      "\n",
      "Epoch: [99/100], Step: [3900/6250], Loss: 0.2712 \n",
      "\n",
      "Epoch: [99/100], Step: [4000/6250], Loss: 0.3019 \n",
      "\n",
      "Epoch: [99/100], Step: [4100/6250], Loss: 0.1845 \n",
      "\n",
      "Epoch: [99/100], Step: [4200/6250], Loss: 0.6588 \n",
      "\n",
      "Epoch: [99/100], Step: [4300/6250], Loss: 1.5309 \n",
      "\n",
      "Epoch: [99/100], Step: [4400/6250], Loss: 0.9821 \n",
      "\n",
      "Epoch: [99/100], Step: [4500/6250], Loss: 0.6085 \n",
      "\n",
      "Epoch: [99/100], Step: [4600/6250], Loss: 0.5905 \n",
      "\n",
      "Epoch: [99/100], Step: [4700/6250], Loss: 0.5259 \n",
      "\n",
      "Epoch: [99/100], Step: [4800/6250], Loss: 0.2151 \n",
      "\n",
      "Epoch: [99/100], Step: [4900/6250], Loss: 0.8121 \n",
      "\n",
      "Epoch: [99/100], Step: [5000/6250], Loss: 0.1385 \n",
      "\n",
      "Epoch: [99/100], Step: [5100/6250], Loss: 0.1954 \n",
      "\n",
      "Epoch: [99/100], Step: [5200/6250], Loss: 0.6311 \n",
      "\n",
      "Epoch: [99/100], Step: [5300/6250], Loss: 0.1159 \n",
      "\n",
      "Epoch: [99/100], Step: [5400/6250], Loss: 0.5531 \n",
      "\n",
      "Epoch: [99/100], Step: [5500/6250], Loss: 0.4880 \n",
      "\n",
      "Epoch: [99/100], Step: [5600/6250], Loss: 0.4420 \n",
      "\n",
      "Epoch: [99/100], Step: [5700/6250], Loss: 0.7262 \n",
      "\n",
      "Epoch: [99/100], Step: [5800/6250], Loss: 0.0871 \n",
      "\n",
      "Epoch: [99/100], Step: [5900/6250], Loss: 0.2376 \n",
      "\n",
      "Epoch: [99/100], Step: [6000/6250], Loss: 0.4424 \n",
      "\n",
      "Epoch: [99/100], Step: [6100/6250], Loss: 0.2196 \n",
      "\n",
      "Epoch: [99/100], Step: [6200/6250], Loss: 0.2718 \n",
      "\n",
      "Epoch: [100/100], Step: [100/6250], Loss: 0.4408 \n",
      "\n",
      "Epoch: [100/100], Step: [200/6250], Loss: 0.3976 \n",
      "\n",
      "Epoch: [100/100], Step: [300/6250], Loss: 0.1242 \n",
      "\n",
      "Epoch: [100/100], Step: [400/6250], Loss: 0.1293 \n",
      "\n",
      "Epoch: [100/100], Step: [500/6250], Loss: 0.0542 \n",
      "\n",
      "Epoch: [100/100], Step: [600/6250], Loss: 0.1050 \n",
      "\n",
      "Epoch: [100/100], Step: [700/6250], Loss: 0.3936 \n",
      "\n",
      "Epoch: [100/100], Step: [800/6250], Loss: 0.1537 \n",
      "\n",
      "Epoch: [100/100], Step: [900/6250], Loss: 0.0960 \n",
      "\n",
      "Epoch: [100/100], Step: [1000/6250], Loss: 0.3260 \n",
      "\n",
      "Epoch: [100/100], Step: [1100/6250], Loss: 0.6962 \n",
      "\n",
      "Epoch: [100/100], Step: [1200/6250], Loss: 0.3867 \n",
      "\n",
      "Epoch: [100/100], Step: [1300/6250], Loss: 0.2588 \n",
      "\n",
      "Epoch: [100/100], Step: [1400/6250], Loss: 0.0544 \n",
      "\n",
      "Epoch: [100/100], Step: [1500/6250], Loss: 0.2196 \n",
      "\n",
      "Epoch: [100/100], Step: [1600/6250], Loss: 0.3160 \n",
      "\n",
      "Epoch: [100/100], Step: [1700/6250], Loss: 0.0358 \n",
      "\n",
      "Epoch: [100/100], Step: [1800/6250], Loss: 0.3923 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [100/100], Step: [1900/6250], Loss: 0.2447 \n",
      "\n",
      "Epoch: [100/100], Step: [2000/6250], Loss: 0.0705 \n",
      "\n",
      "Epoch: [100/100], Step: [2100/6250], Loss: 0.3151 \n",
      "\n",
      "Epoch: [100/100], Step: [2200/6250], Loss: 0.2655 \n",
      "\n",
      "Epoch: [100/100], Step: [2300/6250], Loss: 0.2523 \n",
      "\n",
      "Epoch: [100/100], Step: [2400/6250], Loss: 0.1084 \n",
      "\n",
      "Epoch: [100/100], Step: [2500/6250], Loss: 0.1819 \n",
      "\n",
      "Epoch: [100/100], Step: [2600/6250], Loss: 0.2391 \n",
      "\n",
      "Epoch: [100/100], Step: [2700/6250], Loss: 0.3095 \n",
      "\n",
      "Epoch: [100/100], Step: [2800/6250], Loss: 1.3424 \n",
      "\n",
      "Epoch: [100/100], Step: [2900/6250], Loss: 0.5475 \n",
      "\n",
      "Epoch: [100/100], Step: [3000/6250], Loss: 0.4896 \n",
      "\n",
      "Epoch: [100/100], Step: [3100/6250], Loss: 0.4228 \n",
      "\n",
      "Epoch: [100/100], Step: [3200/6250], Loss: 0.3196 \n",
      "\n",
      "Epoch: [100/100], Step: [3300/6250], Loss: 0.4489 \n",
      "\n",
      "Epoch: [100/100], Step: [3400/6250], Loss: 0.6739 \n",
      "\n",
      "Epoch: [100/100], Step: [3500/6250], Loss: 0.3964 \n",
      "\n",
      "Epoch: [100/100], Step: [3600/6250], Loss: 0.7331 \n",
      "\n",
      "Epoch: [100/100], Step: [3700/6250], Loss: 0.4966 \n",
      "\n",
      "Epoch: [100/100], Step: [3800/6250], Loss: 0.8588 \n",
      "\n",
      "Epoch: [100/100], Step: [3900/6250], Loss: 0.8458 \n",
      "\n",
      "Epoch: [100/100], Step: [4000/6250], Loss: 0.2545 \n",
      "\n",
      "Epoch: [100/100], Step: [4100/6250], Loss: 0.3856 \n",
      "\n",
      "Epoch: [100/100], Step: [4200/6250], Loss: 0.3558 \n",
      "\n",
      "Epoch: [100/100], Step: [4300/6250], Loss: 0.1733 \n",
      "\n",
      "Epoch: [100/100], Step: [4400/6250], Loss: 0.2940 \n",
      "\n",
      "Epoch: [100/100], Step: [4500/6250], Loss: 0.4082 \n",
      "\n",
      "Epoch: [100/100], Step: [4600/6250], Loss: 0.0933 \n",
      "\n",
      "Epoch: [100/100], Step: [4700/6250], Loss: 0.4462 \n",
      "\n",
      "Epoch: [100/100], Step: [4800/6250], Loss: 0.2720 \n",
      "\n",
      "Epoch: [100/100], Step: [4900/6250], Loss: 0.3830 \n",
      "\n",
      "Epoch: [100/100], Step: [5000/6250], Loss: 0.6008 \n",
      "\n",
      "Epoch: [100/100], Step: [5100/6250], Loss: 0.5658 \n",
      "\n",
      "Epoch: [100/100], Step: [5200/6250], Loss: 0.5906 \n",
      "\n",
      "Epoch: [100/100], Step: [5300/6250], Loss: 0.0608 \n",
      "\n",
      "Epoch: [100/100], Step: [5400/6250], Loss: 0.3464 \n",
      "\n",
      "Epoch: [100/100], Step: [5500/6250], Loss: 0.1763 \n",
      "\n",
      "Epoch: [100/100], Step: [5600/6250], Loss: 0.5214 \n",
      "\n",
      "Epoch: [100/100], Step: [5700/6250], Loss: 0.7976 \n",
      "\n",
      "Epoch: [100/100], Step: [5800/6250], Loss: 0.1644 \n",
      "\n",
      "Epoch: [100/100], Step: [5900/6250], Loss: 0.5842 \n",
      "\n",
      "Epoch: [100/100], Step: [6000/6250], Loss: 0.1878 \n",
      "\n",
      "Epoch: [100/100], Step: [6100/6250], Loss: 0.0616 \n",
      "\n",
      "Epoch: [100/100], Step: [6200/6250], Loss: 0.4306 \n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "n_total_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # origin shape: [4, 3, 32, 32] = 4(because batch_size=4), 3, 1024\n",
    "        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        #backward & optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch: [{epoch+1}/{num_epochs}], Step: [{i+1}/{n_total_steps}], Loss: {loss.item():.4f} \\n')\n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be010e5",
   "metadata": {},
   "source": [
    "## Test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f8b2c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 64.8 %\n",
      "Accuracy of plane: 70.7 %\n",
      "Accuracy of car: 73.3 %\n",
      "Accuracy of bird: 48.1 %\n",
      "Accuracy of cat: 47.4 %\n",
      "Accuracy of deer: 64.9 %\n",
      "Accuracy of dog: 43.4 %\n",
      "Accuracy of frog: 72.6 %\n",
      "Accuracy of horse: 64.8 %\n",
      "Accuracy of ship: 68.9 %\n",
      "Accuracy of truck: 78.0 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # max returns (value, index)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "            \n",
    "    acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "    print(f'Accuracy of the network: {acc} %') \n",
    "    \n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
